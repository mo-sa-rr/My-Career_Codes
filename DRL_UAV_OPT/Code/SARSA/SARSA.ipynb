{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b048e30-68a8-4f87-8066-9883c314d489",
   "metadata": {
    "id": "L2xjHP_d3owr"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# all array inputs must be of the type np.array\n",
    "\n",
    "class my_env:\n",
    "    #def __init__(self, uav_number, user_number, size, user_loc, noise, height, transmit_pow, safe_dist): # initializes environment\n",
    "    def __init__(self):\n",
    "        self.uav_number = 2\n",
    "        self.user_number = 5\n",
    "        self.size = np.array([10,10])\n",
    "        self.user_loc = np.array([[-5,-5,5,5,0],[-5,5,-5,5,0]])\n",
    "        self.safe_dist = 5\n",
    "        self.noise = 0.01\n",
    "        self.height = 7\n",
    "        self.transmit_pow = 1\n",
    "        self.observation_space = 2*self.uav_number + self.user_number\n",
    "\n",
    "        ### Parameters\n",
    "        self.actions = 5**(self.uav_number) # 0: 10 units Left , 1: 10 units up , 2: 10 units right, 3: 10 units down, 4: stay\n",
    "        self.user_profile = 1*np.ones(self.user_number)\n",
    "        ###\n",
    "\n",
    "    def my_reward(self, uav_loc, scheduling, user_prof): # calculate reward\n",
    "        num_agents = np.shape(uav_loc)[1]\n",
    "        num_user = np.shape(self.user_loc)[1]\n",
    "\n",
    "        pref = np.zeros((num_agents,num_user))\n",
    "        pref_rate = np.zeros((num_agents,num_user))\n",
    "        for i in range(np.shape(pref)[0]):\n",
    "            for j in range(np.shape(pref)[1]):\n",
    "                interf = 0\n",
    "                for k in range(np.shape(pref)[0]):\n",
    "                    if k != i:\n",
    "                        interf = interf + self.transmit_pow/(self.height**2 + np.linalg.norm(uav_loc[:,k]-self.user_loc[:,j]))\n",
    "                pref[i,j] = user_prof[j]*np.log2(1 + self.transmit_pow/(self.height**2 + np.linalg.norm(uav_loc[:,i]-self.user_loc[:,j]))/(interf+self.noise))\n",
    "                #pref[i,j] = np.log2(1 + self.transmit_pow/(self.height**2 + np.linalg.norm(uav_loc[:,i]-self.user_loc[:,j]))/(interf+self.noise))\n",
    "\n",
    "\n",
    "        ####### ---- penalty\n",
    "        penalty = 0\n",
    "\n",
    "        for i in range(np.shape(pref)[0]):\n",
    "            for k in range(np.shape(pref)[0]):\n",
    "                if k != i:\n",
    "                    penalty = penalty + (np.linalg.norm(uav_loc[:,k]-uav_loc[:,i]) < self.safe_dist)\n",
    "\n",
    "        # reward = np.sum(np.multiply(scheduling,pref)) - np.log2(1 + self.transmit_pow/(self.height**2)/self.noise )*penalty/2\n",
    "        reward = np.sum(np.multiply(scheduling,pref)) - 1000*penalty/2\n",
    "\n",
    "        if penalty != 0:\n",
    "            done =  True\n",
    "        else: \n",
    "            done = False\n",
    "        \n",
    "        return reward , done\n",
    "\n",
    "\n",
    "    def next_state(self, action1, uav_loc, user_prof, scheduling):\n",
    "        if action1<5:\n",
    "            action = np.base_repr(action1,base=5,padding = 1)\n",
    "        else :\n",
    "            action = np.base_repr(action1,base=5,padding = 0)\n",
    "\n",
    "        for i in range(len(action)):\n",
    "            if action[i] == \"0\":\n",
    "\n",
    "                uav_loc[:,i] = uav_loc[:,i] + (-2*np.array([1,0]))\n",
    "                uav_loc[0,i] = uav_loc[0,i] + (uav_loc[0,i]<-self.size[0]/2)*(-self.size[0]/2-uav_loc[0,i])\n",
    "\n",
    "            elif action[i] == \"1\":\n",
    "\n",
    "                uav_loc[:,i] = uav_loc[:,i] + (2*np.array([0,1]))\n",
    "                uav_loc[1,i] = uav_loc[1,i] + (uav_loc[1,i]>self.size[1]/2)*(self.size[1]/2-uav_loc[1,i])\n",
    "\n",
    "            elif action[i] == \"2\":\n",
    "\n",
    "                uav_loc[:,i] = uav_loc[:,i] + (2*np.array([1,0]))\n",
    "                uav_loc[0,i] = uav_loc[0,i] + (uav_loc[0,i]>self.size[0]/2)*(self.size[0]/2-uav_loc[0,i])\n",
    "\n",
    "            elif action[i] == \"3\":\n",
    "\n",
    "                uav_loc[:,i] = uav_loc[:,i] + (-2*np.array([0,1]))\n",
    "                uav_loc[1,i] = uav_loc[1,i] + (uav_loc[1,i]<-self.size[1]/2)*(-self.size[1]/2-uav_loc[1,i])\n",
    "\n",
    "            else :\n",
    "                pass\n",
    "\n",
    "        #user_prof = user_prof + (0.1 * ~(np.sum(scheduling,axis=0)>0))\n",
    "        # user_prof = user_prof - (np.min(user_prof)>5)*5\n",
    "        user_prof = 1/(0.9/user_prof + 0.1*np.sum(scheduling,axis=0))\n",
    "\n",
    "        return np.hstack((uav_loc.flatten() , user_prof))\n",
    "\n",
    "    def init_state(self):\n",
    "\n",
    "        while True:\n",
    "            a = np.random.uniform(-self.size[0]/2,self.size[0]/2,size = (1,self.uav_number))\n",
    "            b = np.random.uniform(-self.size[1]/2,self.size[1]/2,size = (1,self.uav_number))\n",
    "            c = np.vstack((a,b))\n",
    "            if np.linalg.norm(c[:,0]-c[:,1])>self.safe_dist:\n",
    "                break\n",
    "        \n",
    " \n",
    "\n",
    "        return np.hstack((a.flatten(),b.flatten(),self.user_profile))\n",
    "\n",
    "\n",
    "\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def schedule(user_prof,user_loc,UAV_loc,transmit_pow,noise,height):\n",
    "\n",
    "\n",
    "    num_agents = np.shape(UAV_loc)[1]\n",
    "    num_user = np.shape(user_loc)[1]\n",
    "\n",
    "    A = cp.Variable((num_agents,num_user))\n",
    "\n",
    "    pref = np.zeros((num_agents,num_user))\n",
    "    for i in range(np.shape(pref)[0]):\n",
    "        for j in range(np.shape(pref)[1]):\n",
    "            interf = 0\n",
    "            for k in range(np.shape(pref)[0]):\n",
    "                if k != i:\n",
    "                    interf = interf + transmit_pow/(height**2 + np.linalg.norm(UAV_loc[:,k]-user_loc[:,j]))\n",
    "            pref[i,j] = user_prof[j]*np.log2(1 + transmit_pow/(height**2 + np.linalg.norm(UAV_loc[:,i]-user_loc[:,j]))/(interf+noise))\n",
    "\n",
    "    objective = cp.Minimize(-1*cp.sum(cp.multiply(A,pref)))\n",
    "\n",
    "    constraints = [A>=0,A<=1]\n",
    "    constraints.append(cp.sum(A,axis = 0) <= 1)\n",
    "    constraints.append(cp.sum(A,axis = 1) <= 1)\n",
    "\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "\n",
    "    problem.solve()\n",
    "\n",
    "    return np.round(A.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45385770-d2f3-477f-b8db-a0263840f408",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QuqbYBR-2_UO",
    "outputId": "b1ef074b-7fb2-48e6-d8ad-db96e4078d59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Digikala\\anaconda3\\envs\\my_temp\\quad_RL\\final\\DQN\\SARSA\n",
      "SARSA.ipynb\n",
      "Untitled.ipynb\n",
      "code.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "155bbf88-e0dd-405c-87dc-a40a331f78f7",
   "metadata": {
    "id": "de6f3779-5d33-436f-a918-5ac4dd091357"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import random\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcd8c574-66f5-4b93-82e4-55109e854242",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dcee31e6-d718-4372-be76-0cce78b2b24b",
    "outputId": "45094f64-dca2-48d9-bc92-ca38200c9981"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "ALPHA = 0.001  # Learning rate\n",
    "\n",
    "MEMORY_SIZE = 1  # Size of experience replay memory\n",
    "\n",
    "\n",
    "\n",
    "# Experience replay memory\n",
    "memory = deque(maxlen=MEMORY_SIZE)\n",
    "\n",
    "# Check for GPU\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE)\n",
    "DEVICE = \"cpu\"\n",
    "\n",
    "\n",
    "# Define the Q-network using\n",
    "\n",
    "def weight_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 1024)\n",
    "        self.fc4 = nn.Linear(1024, output_dim)\n",
    "\n",
    "    # def forward(self, state):\n",
    "    #     x = torch.relu(self.fc1(state))\n",
    "    #     x = torch.relu(self.fc2(x))\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = torch.relu(self.fc1(state))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        return self.fc4(x)  # Output Q-values for each action\n",
    "\n",
    "# Initialize environment, model, and optimizer\n",
    "quad_env = my_env()\n",
    "input_dim =quad_env.observation_space  # State space dimension\n",
    "output_dim = quad_env.actions  # Action space size\n",
    "\n",
    "q_net = QNetwork(input_dim, output_dim).to(DEVICE)\n",
    "q_net.apply(weight_init)\n",
    "target_net = copy.deepcopy(q_net)\n",
    "optimizer = optim.Adam(q_net.parameters(), lr=ALPHA)\n",
    "#loss_fn = nn.SmoothL1Loss()\n",
    "loss_fn = nn.MSELoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304aeefd-a139-40a0-a9de-da339511bff3",
   "metadata": {
    "id": "f71fe30c-cd4c-4822-b17b-7a62079fc3cc"
   },
   "source": [
    "## function defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69d9d2d4-6d4a-4e9f-9ef7-9d644b1066ed",
   "metadata": {
    "id": "dbe8ceb3-db69-4de0-9ad9-119d0feeb95c"
   },
   "outputs": [],
   "source": [
    "# Function to select an action using epsilon-greedy policy\n",
    "def select_action(state, epsilon):\n",
    "    if random.random() < epsilon:\n",
    "        return random.randint(0, quad_env.actions-1)  # Exploration: random action\n",
    "    else:\n",
    "        state = torch.FloatTensor(state).to(DEVICE)  # Convert state to tensor\n",
    "        q_values = q_net(state)\n",
    "        return torch.argmax(q_values).item()  # Exploitation: action with highest Q-value\n",
    "\n",
    "def weight_change(model1,model2):\n",
    "    weight_diff = 0\n",
    "    for param1, param2 in zip(model1.parameters(), model2.parameters()):\n",
    "        weight_diff += torch.sum(torch.abs(param1 - param2)).item()\n",
    "    return weight_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb22964e-f7ea-4ec7-9fdb-ed7b616d1524",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "id": "7804389a-98d8-4ce4-adde-420d703767ce",
    "outputId": "b685d1a8-fecc-4e69-e614-4d2870de9af6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 10/10000, Eps Reward: -981.9492026744878, Epsilon: 0.988559330361785, weights: 100.39025352988392, elapsed: 0.028217907746632895 minutes\n",
      "episode 20/10000, Eps Reward: -990.0117258097225, Epsilon: 0.9772495496453408, weights: 181.55479526054114, elapsed: 0.047684526443481444 minutes\n",
      "episode 30/10000, Eps Reward: -981.0200562341012, Epsilon: 0.9660691603937541, weights: 69.59032011870295, elapsed: 0.0785547137260437 minutes\n",
      "episode 40/10000, Eps Reward: -966.355287475647, Epsilon: 0.9550166822820216, weights: 156.29925145907328, elapsed: 0.12202176650365194 minutes\n",
      "episode 50/10000, Eps Reward: -961.8674315275046, Epsilon: 0.9440906519210489, weights: 66.2390385037288, elapsed: 0.17261496384938557 minutes\n",
      "episode 60/10000, Eps Reward: -950.2922219157396, Epsilon: 0.9332896226638931, weights: 42.67351899202913, elapsed: 0.2363112250963847 minutes\n",
      "episode 70/10000, Eps Reward: -955.5676225501886, Epsilon: 0.9226121644142213, weights: 76.1766600117553, elapsed: 0.3033102035522461 minutes\n",
      "episode 80/10000, Eps Reward: -969.9022219058148, Epsilon: 0.9120568634369598, weights: 38.06717679975554, elapsed: 0.35647728443145754 minutes\n",
      "episode 90/10000, Eps Reward: -973.6527906887874, Epsilon: 0.9016223221711109, weights: 33.46216340153478, elapsed: 0.40455443064371743 minutes\n",
      "episode 100/10000, Eps Reward: -964.3162105148937, Epsilon: 0.8913071590447111, weights: 21.492843531013932, elapsed: 0.4639727115631104 minutes\n",
      "episode 110/10000, Eps Reward: -981.4933806215018, Epsilon: 0.8811100082919047, weights: 36.23388377088122, elapsed: 0.5028947432835896 minutes\n",
      "episode 120/10000, Eps Reward: -980.9018649266515, Epsilon: 0.8710295197721121, weights: 12.804353254381567, elapsed: 0.5406038284301757 minutes\n",
      "episode 130/10000, Eps Reward: -947.4499022565373, Epsilon: 0.8610643587912663, weights: 34.75678718998097, elapsed: 0.6179969469706218 minutes\n",
      "episode 140/10000, Eps Reward: -986.2123349237427, Epsilon: 0.8512132059250941, weights: 51.93140471121296, elapsed: 0.6447601954142252 minutes\n",
      "episode 150/10000, Eps Reward: -982.3193950643551, Epsilon: 0.8414747568444195, weights: 53.02948532928713, elapsed: 0.6788877964019775 minutes\n",
      "episode 160/10000, Eps Reward: -961.759817363772, Epsilon: 0.8318477221424653, weights: 58.47919642878696, elapsed: 0.7402550260225932 minutes\n",
      "episode 170/10000, Eps Reward: -970.2748619083022, Epsilon: 0.8223308271641319, weights: 9.234639253118075, elapsed: 0.7905693332354228 minutes\n",
      "episode 180/10000, Eps Reward: -955.2444349594116, Epsilon: 0.812922811837227, weights: 8.191892164293677, elapsed: 0.8608583768208822 minutes\n",
      "episode 190/10000, Eps Reward: -981.0811604029388, Epsilon: 0.8036224305056286, weights: 53.68992416933179, elapsed: 0.8985141634941101 minutes\n",
      "episode 200/10000, Eps Reward: -978.1835740866954, Epsilon: 0.7944284517643544, weights: 13.407392165390775, elapsed: 0.9401873310407003 minutes\n",
      "episode 210/10000, Eps Reward: -970.1417848859898, Epsilon: 0.7853396582965199, weights: 41.008440802805126, elapsed: 0.9932261387507121 minutes\n",
      "episode 220/10000, Eps Reward: -984.8026083479812, Epsilon: 0.7763548467121608, weights: 29.93057301500812, elapsed: 1.0227666695912678 minutes\n",
      "episode 230/10000, Eps Reward: -959.9425964559811, Epsilon: 0.7674728273889002, weights: 19.44537098892033, elapsed: 1.081096092859904 minutes\n",
      "episode 240/10000, Eps Reward: -973.8540343469006, Epsilon: 0.7586924243144371, weights: 4.563758288742974, elapsed: 1.1303852836290995 minutes\n",
      "episode 250/10000, Eps Reward: -864.2986494582113, Epsilon: 0.7500124749308392, weights: 15.46688473969698, elapsed: 1.3099133451779683 minutes\n",
      "episode 260/10000, Eps Reward: -984.1535880672084, Epsilon: 0.7414318299806156, weights: 25.50468785967678, elapsed: 1.3406431714693705 minutes\n",
      "episode 270/10000, Eps Reward: -977.8694685526892, Epsilon: 0.7329493533545505, weights: 72.8168164063245, elapsed: 1.380752448240916 minutes\n",
      "episode 280/10000, Eps Reward: -942.4472149106732, Epsilon: 0.7245639219412776, weights: 37.58987123519182, elapsed: 1.460932767391205 minutes\n",
      "episode 290/10000, Eps Reward: -920.2315996557738, Epsilon: 0.7162744254785781, weights: 36.3703909823671, elapsed: 1.5648019512494404 minutes\n",
      "episode 300/10000, Eps Reward: -961.3870875076376, Epsilon: 0.7080797664063756, weights: 21.627581911161542, elapsed: 1.628735113143921 minutes\n",
      "episode 310/10000, Eps Reward: -952.6225798918306, Epsilon: 0.699978859721416, weights: 50.43055116571486, elapsed: 1.7017728288968403 minutes\n",
      "episode 320/10000, Eps Reward: -928.5446861621525, Epsilon: 0.6919706328336088, weights: 33.18877022154629, elapsed: 1.7999906023343404 minutes\n",
      "episode 330/10000, Eps Reward: -853.1762078827265, Epsilon: 0.6840540254240131, weights: 122.99269451759756, elapsed: 1.9808092832565307 minutes\n",
      "episode 340/10000, Eps Reward: -935.7185115605887, Epsilon: 0.6762279893044459, weights: 148.21353520080447, elapsed: 2.0672363956769306 minutes\n",
      "episode 350/10000, Eps Reward: -980.4301516753301, Epsilon: 0.6684914882786995, weights: 39.55723411217332, elapsed: 2.101097031434377 minutes\n",
      "episode 360/10000, Eps Reward: -968.5302949368834, Epsilon: 0.6608434980053443, weights: 35.2446328625083, elapsed: 2.1526424288749695 minutes\n",
      "episode 370/10000, Eps Reward: -946.8480385194218, Epsilon: 0.6532830058621028, weights: 46.49667403101921, elapsed: 2.2304794987042746 minutes\n",
      "episode 380/10000, Eps Reward: -976.2699485181411, Epsilon: 0.6458090108117747, weights: 7.929807584732771, elapsed: 2.271596376101176 minutes\n",
      "episode 390/10000, Eps Reward: -973.7487901403034, Epsilon: 0.6384205232696947, weights: 20.597291376441717, elapsed: 2.3156082232793174 minutes\n",
      "episode 400/10000, Eps Reward: -969.5527825074608, Epsilon: 0.6311165649727097, weights: 22.978472081013024, elapsed: 2.367673468589783 minutes\n",
      "episode 410/10000, Eps Reward: -943.1747925389038, Epsilon: 0.623896168849652, weights: 39.56492950581014, elapsed: 2.4538673241933187 minutes\n",
      "episode 420/10000, Eps Reward: -909.4001669797256, Epsilon: 0.6167583788932951, weights: 26.276502637192607, elapsed: 2.57489560842514 minutes\n",
      "episode 430/10000, Eps Reward: -964.2224881646996, Epsilon: 0.609702250033776, weights: 32.804795702919364, elapsed: 2.6368534485499064 minutes\n",
      "episode 440/10000, Eps Reward: -980.9017404002203, Epsilon: 0.6027268480134631, weights: 39.54486929625273, elapsed: 2.676945924758911 minutes\n",
      "episode 450/10000, Eps Reward: -907.8933444162758, Epsilon: 0.5958312492632584, weights: 104.67554550990462, elapsed: 2.8042455077171327 minutes\n",
      "episode 460/10000, Eps Reward: -946.675380262964, Epsilon: 0.5890145407803127, weights: 121.47709955088794, elapsed: 2.879496475060781 minutes\n",
      "episode 470/10000, Eps Reward: -964.542416060873, Epsilon: 0.5822758200071402, weights: 76.76974098011851, elapsed: 2.9393559734026593 minutes\n",
      "episode 480/10000, Eps Reward: -936.7475811635362, Epsilon: 0.5756141947121178, weights: 221.2669756859541, elapsed: 3.0213600754737855 minutes\n",
      "episode 490/10000, Eps Reward: -944.7109610294514, Epsilon: 0.5690287828713493, weights: 70.82013134472072, elapsed: 3.097391585508982 minutes\n",
      "episode 500/10000, Eps Reward: -964.0109658106583, Epsilon: 0.5625187125518827, weights: 47.13246145937592, elapsed: 3.1579912583033245 minutes\n",
      "episode 510/10000, Eps Reward: -972.9174477387445, Epsilon: 0.5560831217962626, weights: 49.563183419406414, elapsed: 3.203553513685862 minutes\n",
      "episode 520/10000, Eps Reward: -971.0004997971535, Epsilon: 0.5497211585084044, weights: 34.77492988482118, elapsed: 3.2527610341707867 minutes\n",
      "episode 530/10000, Eps Reward: -966.406280704559, Epsilon: 0.5434319803407729, weights: 30.333017989993095, elapsed: 3.3098223368326822 minutes\n",
      "episode 540/10000, Eps Reward: -908.8865206031253, Epsilon: 0.5372147545828531, weights: 62.31599461566657, elapsed: 3.4371214310328164 minutes\n",
      "episode 550/10000, Eps Reward: -943.9904148354742, Epsilon: 0.531068658050896, weights: 18.667479091323912, elapsed: 3.520427683989207 minutes\n",
      "episode 560/10000, Eps Reward: -972.6821444666726, Epsilon: 0.5249928769789257, weights: 38.87756593292579, elapsed: 3.568588105837504 minutes\n",
      "episode 570/10000, Eps Reward: -861.9796882590745, Epsilon: 0.518986606910994, weights: 44.915280806832016, elapsed: 3.744066560268402 minutes\n",
      "episode 580/10000, Eps Reward: -856.0501878452978, Epsilon: 0.5130490525946672, weights: 47.86682935152203, elapsed: 3.92469322681427 minutes\n",
      "episode 590/10000, Eps Reward: -951.494951715276, Epsilon: 0.5071794278757324, weights: 38.562885883962736, elapsed: 4.0030097206433615 minutes\n",
      "episode 600/10000, Eps Reward: -969.3478927678741, Epsilon: 0.5013769555941073, weights: 25.03182682581246, elapsed: 4.05585302511851 minutes\n",
      "episode 610/10000, Eps Reward: -982.2302054794518, Epsilon: 0.49564086748094127, weights: 80.7332779057324, elapsed: 4.086227365334829 minutes\n",
      "episode 620/10000, Eps Reward: -946.1914967564846, Epsilon: 0.4899704040568935, weights: 17.624561040196568, elapsed: 4.1668748219807945 minutes\n",
      "episode 630/10000, Eps Reward: -965.1446431335919, Epsilon: 0.48436481453157587, weights: 53.46514164283872, elapsed: 4.220989322662353 minutes\n",
      "episode 640/10000, Eps Reward: -952.6779314081539, Epsilon: 0.4788233567041449, weights: 23.039439229294658, elapsed: 4.285291254520416 minutes\n",
      "episode 650/10000, Eps Reward: -899.952413001841, Epsilon: 0.4733452968650316, weights: 48.516434367746115, elapsed: 4.412852573394775 minutes\n",
      "episode 660/10000, Eps Reward: -930.8668429341426, Epsilon: 0.46792990969879605, weights: 28.773441318422556, elapsed: 4.5058044989903765 minutes\n",
      "episode 670/10000, Eps Reward: -958.0359794377434, Epsilon: 0.46257647818809233, weights: 64.20838179439306, elapsed: 4.562801071008047 minutes\n",
      "episode 680/10000, Eps Reward: -956.6827410016376, Epsilon: 0.4572842935187334, weights: 48.344130255281925, elapsed: 4.622435092926025 minutes\n",
      "episode 690/10000, Eps Reward: -937.0020049609317, Epsilon: 0.45205265498584113, weights: 25.10885827243328, elapsed: 4.707407033443451 minutes\n",
      "episode 700/10000, Eps Reward: -903.4312035043729, Epsilon: 0.4468808699010701, weights: 78.05802039802074, elapsed: 4.828095078468323 minutes\n",
      "episode 710/10000, Eps Reward: -977.7308557389433, Epsilon: 0.4417682535008938, weights: 28.81960608251393, elapsed: 4.867401421070099 minutes\n",
      "episode 720/10000, Eps Reward: -907.1115227621685, Epsilon: 0.4367141288559389, weights: 113.13877332024276, elapsed: 4.991320975621542 minutes\n",
      "episode 730/10000, Eps Reward: -928.671731106015, Epsilon: 0.43171782678135734, weights: 87.16203835979104, elapsed: 5.08399529059728 minutes\n",
      "episode 740/10000, Eps Reward: -991.2804448429655, Epsilon: 0.4267786857482238, weights: 42.90750980749726, elapsed: 5.104821864763895 minutes\n",
      "episode 750/10000, Eps Reward: -957.022651488454, Epsilon: 0.42189605179594686, weights: 23.669053921476007, elapsed: 5.166442374388377 minutes\n",
      "episode 760/10000, Eps Reward: -931.0480741102594, Epsilon: 0.41706927844568215, weights: 29.923305246978998, elapsed: 5.267528339227041 minutes\n",
      "episode 770/10000, Eps Reward: -923.7401084464448, Epsilon: 0.4122977266147364, weights: 19.90822972729802, elapsed: 5.367493037382761 minutes\n",
      "episode 780/10000, Eps Reward: -926.3028781831948, Epsilon: 0.40758076453195, weights: 34.08364533819258, elapsed: 5.467737050851186 minutes\n",
      "episode 790/10000, Eps Reward: -977.4788813658752, Epsilon: 0.402917767654049, weights: 69.44056169129908, elapsed: 5.50593512058258 minutes\n",
      "episode 800/10000, Eps Reward: -926.5138485509058, Epsilon: 0.398308118582952, weights: 12.63415499869734, elapsed: 5.611440912882487 minutes\n",
      "episode 810/10000, Eps Reward: -973.6646139426308, Epsilon: 0.39375120698402555, weights: 18.51344613172114, elapsed: 5.658085906505585 minutes\n",
      "episode 820/10000, Eps Reward: -968.5385975504145, Epsilon: 0.38924642950527283, weights: 77.50186071079224, elapsed: 5.7093575914700825 minutes\n",
      "episode 830/10000, Eps Reward: -927.9752851340054, Epsilon: 0.38479318969744825, weights: 60.65081723919138, elapsed: 5.804342198371887 minutes\n",
      "episode 840/10000, Eps Reward: -939.086172826743, Epsilon: 0.3803908979350848, weights: 43.109431338496506, elapsed: 5.8894729574521385 minutes\n",
      "episode 850/10000, Eps Reward: -962.8663117710408, Epsilon: 0.3760389713384255, weights: 85.88547138404101, elapsed: 5.949347154299418 minutes\n",
      "episode 860/10000, Eps Reward: -898.2055145927519, Epsilon: 0.3717368336962485, weights: 54.93830120470375, elapsed: 6.078731242815653 minutes\n",
      "episode 870/10000, Eps Reward: -946.8911351212348, Epsilon: 0.36748391538957365, weights: 36.933069413527846, elapsed: 6.155266761779785 minutes\n",
      "episode 880/10000, Eps Reward: -911.4213041820947, Epsilon: 0.3632796533162438, weights: 68.5802076952532, elapsed: 6.2664427598317465 minutes\n",
      "episode 890/10000, Eps Reward: -927.3589374200861, Epsilon: 0.3591234908163674, weights: 38.21000914648175, elapsed: 6.361447385946909 minutes\n",
      "episode 900/10000, Eps Reward: -928.8614558320975, Epsilon: 0.3550148775986148, weights: 29.563668401911855, elapsed: 6.455964450041453 minutes\n",
      "episode 910/10000, Eps Reward: -952.9778979081318, Epsilon: 0.35095326966735774, weights: 13.329411792568862, elapsed: 6.5301577091217045 minutes\n",
      "episode 920/10000, Eps Reward: -949.8411753376677, Epsilon: 0.3469381292506421, weights: 24.408329544239677, elapsed: 6.610077619552612 minutes\n",
      "episode 930/10000, Eps Reward: -957.0518600125586, Epsilon: 0.34296892472898516, weights: 30.47066204994917, elapsed: 6.680885994434357 minutes\n",
      "episode 940/10000, Eps Reward: -854.6378152498904, Epsilon: 0.339045130564987, weights: 42.03283838182688, elapsed: 6.853745090961456 minutes\n",
      "episode 950/10000, Eps Reward: -929.2635963001836, Epsilon: 0.3351662272337476, weights: 58.31755346059799, elapsed: 6.947202463944753 minutes\n",
      "episode 960/10000, Eps Reward: -958.801290761711, Epsilon: 0.3313317011540795, weights: 36.001640209928155, elapsed: 7.006298391024272 minutes\n",
      "episode 970/10000, Eps Reward: -968.1264473502988, Epsilon: 0.327541044620508, weights: 120.77409513667226, elapsed: 7.058104900519053 minutes\n",
      "episode 980/10000, Eps Reward: -914.284425213006, Epsilon: 0.32379375573604896, weights: 54.36461625248194, elapsed: 7.174772310256958 minutes\n",
      "episode 990/10000, Eps Reward: -963.3224934456314, Epsilon: 0.320089338345756, weights: 14.342043950222433, elapsed: 7.2335824251174925 minutes\n",
      "episode 1000/10000, Eps Reward: -976.9699326673248, Epsilon: 0.3164273019710274, weights: 20.56650418229401, elapsed: 7.2767993648846945 minutes\n",
      "episode 1010/10000, Eps Reward: -913.7884992956448, Epsilon: 0.3128071617446651, weights: 25.963470567017794, elapsed: 7.3960263212521875 minutes\n",
      "episode 1020/10000, Eps Reward: -941.8554599088122, Epsilon: 0.3092284383466767, weights: 16.808506902307272, elapsed: 7.472824847698211 minutes\n",
      "episode 1030/10000, Eps Reward: -958.6588273748579, Epsilon: 0.3056906579408113, weights: 6.732793991453946, elapsed: 7.541032032171885 minutes\n",
      "episode 1040/10000, Eps Reward: -979.8822240858493, Epsilon: 0.30219335211182197, weights: 39.577212577685714, elapsed: 7.579038802782694 minutes\n",
      "episode 1050/10000, Eps Reward: -981.719073232514, Epsilon: 0.29873605780344586, weights: 17.47242403868586, elapsed: 7.613141731421153 minutes\n",
      "episode 1060/10000, Eps Reward: -950.5609626065095, Epsilon: 0.295318317257094, weights: 26.64579419977963, elapsed: 7.685252849260966 minutes\n",
      "episode 1070/10000, Eps Reward: -985.2838607917149, Epsilon: 0.2919396779512421, weights: 15.99571864400059, elapsed: 7.713106473286946 minutes\n",
      "episode 1080/10000, Eps Reward: -934.9303114137472, Epsilon: 0.28859969254151513, weights: 20.72378239221871, elapsed: 7.801879851023356 minutes\n",
      "episode 1090/10000, Eps Reward: -898.5037680980329, Epsilon: 0.2852979188014572, weights: 14.512806074693799, elapsed: 7.927115515867869 minutes\n",
      "episode 1100/10000, Eps Reward: -936.1808969445025, Epsilon: 0.2820339195639795, weights: 85.2681740988046, elapsed: 8.020555365085603 minutes\n",
      "episode 1110/10000, Eps Reward: -928.5738089380641, Epsilon: 0.27880726266347705, weights: 36.76978882611729, elapsed: 8.121841855843861 minutes\n",
      "episode 1120/10000, Eps Reward: -900.2470472238878, Epsilon: 0.27561752087860925, weights: 88.8251710999757, elapsed: 8.249404394626618 minutes\n",
      "episode 1130/10000, Eps Reward: -937.0559553825882, Epsilon: 0.27246427187573324, weights: 58.717697131447494, elapsed: 8.340256567796072 minutes\n",
      "episode 1140/10000, Eps Reward: -924.9009163456745, Epsilon: 0.2693470981529862, weights: 37.87641171179712, elapsed: 8.443086751302083 minutes\n",
      "episode 1150/10000, Eps Reward: -971.1308416977508, Epsilon: 0.2662655869850061, weights: 20.044450713321567, elapsed: 8.488904492060344 minutes\n",
      "episode 1160/10000, Eps Reward: -963.7273990116298, Epsilon: 0.26321933036828526, weights: 20.16854966338724, elapsed: 8.546956658363342 minutes\n",
      "episode 1170/10000, Eps Reward: -723.1395983714135, Epsilon: 0.2602079249671496, weights: 106.92030857875943, elapsed: 8.757583475112915 minutes\n",
      "episode 1180/10000, Eps Reward: -943.8975359934318, Epsilon: 0.25723097206035517, weights: 17.566588141955435, elapsed: 8.840625894069671 minutes\n",
      "episode 1190/10000, Eps Reward: -895.1753670748524, Epsilon: 0.2542880774882957, weights: 9.367470249533653, elapsed: 8.97756089369456 minutes\n",
      "episode 1200/10000, Eps Reward: -884.7422732151748, Epsilon: 0.25137885160081536, weights: 72.20453492738307, elapsed: 9.119700801372527 minutes\n",
      "episode 1210/10000, Eps Reward: -901.2746953950953, Epsilon: 0.24850290920561657, weights: 89.0736948736012, elapsed: 9.24439605474472 minutes\n",
      "episode 1220/10000, Eps Reward: -965.4502905643054, Epsilon: 0.2456598695172598, weights: 25.44670923985541, elapsed: 9.302190204461416 minutes\n",
      "episode 1230/10000, Eps Reward: -965.6771381901668, Epsilon: 0.24284935610674582, weights: 54.50578225124627, elapsed: 9.357301902770995 minutes\n",
      "episode 1240/10000, Eps Reward: -912.7988135990527, Epsilon: 0.24007099685167538, weights: 23.373363118618727, elapsed: 9.470900011062621 minutes\n",
      "episode 1250/10000, Eps Reward: -946.6237496885226, Epsilon: 0.2373244238869784, weights: 6.628891795873642, elapsed: 9.549240712324778 minutes\n",
      "episode 1260/10000, Eps Reward: -857.3479132789358, Epsilon: 0.2346092735562078, weights: 24.559247041121125, elapsed: 9.732529417673748 minutes\n",
      "episode 1270/10000, Eps Reward: -966.1127087569575, Epsilon: 0.23192518636338968, weights: 28.020504606887698, elapsed: 9.784337286154429 minutes\n",
      "episode 1280/10000, Eps Reward: -968.8258248048365, Epsilon: 0.22927180692542473, weights: 39.102768171578646, elapsed: 9.835099295775096 minutes\n",
      "episode 1290/10000, Eps Reward: -938.2766684740939, Epsilon: 0.22664878392503437, weights: 34.56192066334188, elapsed: 9.920226569970449 minutes\n",
      "episode 1300/10000, Eps Reward: -843.199274152809, Epsilon: 0.22405577006424496, weights: 24.822403885424137, elapsed: 10.113392122586568 minutes\n",
      "episode 1310/10000, Eps Reward: -797.8226839034571, Epsilon: 0.2214924220184041, weights: 4.7286626836284995, elapsed: 10.248239727814992 minutes\n",
      "episode 1320/10000, Eps Reward: -903.5568807570995, Epsilon: 0.21895840039072345, weights: 27.791034611640498, elapsed: 10.382326551278432 minutes\n",
      "episode 1330/10000, Eps Reward: -961.7162701059681, Epsilon: 0.21645336966734122, weights: 29.300639431690797, elapsed: 10.443765930334727 minutes\n",
      "episode 1340/10000, Eps Reward: -962.2820439233246, Epsilon: 0.21397699817289872, weights: 52.94451482128352, elapsed: 10.50363998413086 minutes\n",
      "episode 1350/10000, Eps Reward: -988.3423012958052, Epsilon: 0.21152895802662566, weights: 11.702886612154543, elapsed: 10.52939594189326 minutes\n",
      "episode 1360/10000, Eps Reward: -894.1602918971126, Epsilon: 0.2091089250989272, weights: 19.927736866287887, elapsed: 10.668775975704193 minutes\n",
      "episode 1370/10000, Eps Reward: -954.798770512963, Epsilon: 0.20671657896846818, weights: 20.539253352209926, elapsed: 10.738198741277058 minutes\n",
      "episode 1380/10000, Eps Reward: -932.1536888829245, Epsilon: 0.20435160287974796, weights: 32.08405267447233, elapsed: 10.832956965764364 minutes\n",
      "episode 1390/10000, Eps Reward: -916.1667169181843, Epsilon: 0.2020136837011611, weights: 76.30057757766917, elapsed: 10.93682712316513 minutes\n",
      "episode 1400/10000, Eps Reward: -764.3909535873188, Epsilon: 0.19970251188353727, weights: 9.172960772644728, elapsed: 11.102136766910553 minutes\n",
      "episode 1410/10000, Eps Reward: -942.7643660519603, Epsilon: 0.19741778141915603, weights: 76.36249011196196, elapsed: 11.183898158868153 minutes\n",
      "episode 1420/10000, Eps Reward: -801.8279749814598, Epsilon: 0.19515918980123015, weights: 106.10934160277247, elapsed: 11.305472230911255 minutes\n",
      "episode 1430/10000, Eps Reward: -847.1663537184191, Epsilon: 0.1929264379838526, weights: 17.193700162693858, elapsed: 11.496033084392547 minutes\n",
      "episode 1440/10000, Eps Reward: -908.3810203310974, Epsilon: 0.19071923034240174, weights: 40.492661205120385, elapsed: 11.619167053699494 minutes\n",
      "episode 1450/10000, Eps Reward: -917.7755497608962, Epsilon: 0.1885372746343997, weights: 17.06275560799986, elapsed: 11.732148285706838 minutes\n",
      "episode 1460/10000, Eps Reward: -978.2402891729789, Epsilon: 0.18638028196081816, weights: 72.4080127067864, elapsed: 11.77119991381963 minutes\n",
      "episode 1470/10000, Eps Reward: -903.4822673448891, Epsilon: 0.18424796672782712, weights: 19.7468995526433, elapsed: 11.905884691079457 minutes\n",
      "episode 1480/10000, Eps Reward: -941.8248313345972, Epsilon: 0.18214004660898125, weights: 38.83180873095989, elapsed: 11.98623062769572 minutes\n",
      "episode 1490/10000, Eps Reward: -902.3098630940119, Epsilon: 0.18005624250783886, weights: 31.087223609909415, elapsed: 12.10469864209493 minutes\n",
      "episode 1500/10000, Eps Reward: -730.4901452484656, Epsilon: 0.1779962785210084, weights: 34.17772635817528, elapsed: 12.308274098237355 minutes\n",
      "episode 1510/10000, Eps Reward: -763.725012489429, Epsilon: 0.17595988190161785, weights: 9.758103052619845, elapsed: 12.470720569292704 minutes\n",
      "episode 1520/10000, Eps Reward: -919.0375800807475, Epsilon: 0.17394678302320213, weights: 16.217789779417217, elapsed: 12.582920968532562 minutes\n",
      "episode 1530/10000, Eps Reward: -798.7065168950326, Epsilon: 0.17195671534400342, weights: 46.83215959649533, elapsed: 12.71100467046102 minutes\n",
      "episode 1540/10000, Eps Reward: -960.4105835533304, Epsilon: 0.16998941537168014, weights: 14.554612969979644, elapsed: 12.770894968509674 minutes\n",
      "episode 1550/10000, Eps Reward: -899.2280142138519, Epsilon: 0.16804462262841943, weights: 21.509415289387107, elapsed: 12.902361722787221 minutes\n",
      "episode 1560/10000, Eps Reward: -888.1695294308253, Epsilon: 0.1661220796164492, weights: 50.33741668984294, elapsed: 13.04433977206548 minutes\n",
      "episode 1570/10000, Eps Reward: -900.6986531314844, Epsilon: 0.1642215317839442, weights: 16.180639282800257, elapsed: 13.173071936766307 minutes\n",
      "episode 1580/10000, Eps Reward: -915.0137298200119, Epsilon: 0.16234272749132242, weights: 48.72085690870881, elapsed: 13.277497112751007 minutes\n",
      "episode 1590/10000, Eps Reward: -901.878106577897, Epsilon: 0.16048541797792745, weights: 63.56443606317043, elapsed: 13.398587914307912 minutes\n",
      "episode 1600/10000, Eps Reward: -848.3973348618285, Epsilon: 0.15864935732909116, weights: 44.18235961999744, elapsed: 13.57833896478017 minutes\n",
      "episode 1610/10000, Eps Reward: -803.198154377681, Epsilon: 0.15683430244357394, weights: 26.968797659501433, elapsed: 13.818214388688405 minutes\n",
      "episode 1620/10000, Eps Reward: -990.3458997839737, Epsilon: 0.1550400130013771, weights: 79.9160297466442, elapsed: 13.83928565979004 minutes\n",
      "episode 1630/10000, Eps Reward: -956.4760396179606, Epsilon: 0.1532662514319238, weights: 128.3969568060711, elapsed: 13.901782516638438 minutes\n",
      "episode 1640/10000, Eps Reward: -986.1481414022667, Epsilon: 0.15151278288260356, weights: 88.50244930572808, elapsed: 13.926496287186941 minutes\n",
      "episode 1650/10000, Eps Reward: -712.1407468283106, Epsilon: 0.14977937518767712, weights: 24.011843878775835, elapsed: 14.146238803863525 minutes\n",
      "episode 1660/10000, Eps Reward: -882.0611757820873, Epsilon: 0.14806579883753662, weights: 9.513513505458832, elapsed: 14.289931106567384 minutes\n",
      "episode 1670/10000, Eps Reward: -971.1442647144111, Epsilon: 0.14637182694831793, weights: 65.29670779127628, elapsed: 14.336789925893148 minutes\n",
      "episode 1680/10000, Eps Reward: -920.4136342262755, Epsilon: 0.14469723523186026, weights: 19.744735861197114, elapsed: 14.44196388721466 minutes\n",
      "episode 1690/10000, Eps Reward: -939.6634454046192, Epsilon: 0.1430418019660095, weights: 22.974341372027993, elapsed: 14.525285454591115 minutes\n",
      "episode 1700/10000, Eps Reward: -986.373341624311, Epsilon: 0.14140530796526146, weights: 29.14346084650606, elapsed: 14.55468535820643 minutes\n",
      "episode 1710/10000, Eps Reward: -896.8833720154837, Epsilon: 0.13978753655174084, weights: 56.55576882045716, elapsed: 14.68695114850998 minutes\n",
      "episode 1720/10000, Eps Reward: -926.0456758247743, Epsilon: 0.13818827352651247, weights: 25.99978564120829, elapsed: 14.78144999742508 minutes\n",
      "episode 1730/10000, Eps Reward: -933.778727636736, Epsilon: 0.13660730714122035, weights: 5.221175431273878, elapsed: 14.871981231371562 minutes\n",
      "episode 1740/10000, Eps Reward: -870.8292847456657, Epsilon: 0.1350444280700515, weights: 31.997486437205225, elapsed: 15.03213304678599 minutes\n",
      "episode 1750/10000, Eps Reward: -901.0978473526023, Epsilon: 0.13349942938202033, weights: 7.338300253730267, elapsed: 15.15528247753779 minutes\n",
      "episode 1760/10000, Eps Reward: -600.0068543936868, Epsilon: 0.13197210651357044, weights: 22.531202713027596, elapsed: 15.503184592723846 minutes\n",
      "episode 1770/10000, Eps Reward: -945.6443011994027, Epsilon: 0.13046225724148938, weights: 7.763987357728183, elapsed: 15.583017714818318 minutes\n",
      "episode 1780/10000, Eps Reward: -916.1478858845505, Epsilon: 0.1289696816561337, weights: 20.177630783990026, elapsed: 15.692877113819122 minutes\n",
      "episode 1790/10000, Eps Reward: -932.4714142419549, Epsilon: 0.12749418213496014, weights: 43.74975819326937, elapsed: 15.787115474541983 minutes\n",
      "episode 1800/10000, Eps Reward: -957.1519897521964, Epsilon: 0.12603556331635965, weights: 31.008557505207136, elapsed: 15.849335304896037 minutes\n",
      "episode 1810/10000, Eps Reward: -843.3958863215512, Epsilon: 0.12459363207379089, weights: 18.9479651756119, elapsed: 16.040415064493814 minutes\n",
      "episode 1820/10000, Eps Reward: -844.991642798442, Epsilon: 0.12316819749020934, weights: 16.451961661223322, elapsed: 16.231515324115755 minutes\n",
      "episode 1830/10000, Eps Reward: -918.3974166287699, Epsilon: 0.12175907083278943, weights: 16.152571552433074, elapsed: 16.33616760969162 minutes\n",
      "episode 1840/10000, Eps Reward: -915.1644330976729, Epsilon: 0.1203660655279355, weights: 67.30505496822298, elapsed: 16.449932277202606 minutes\n",
      "episode 1850/10000, Eps Reward: -993.2870293760168, Epsilon: 0.11898899713657866, weights: 21.613473282195628, elapsed: 16.466331160068513 minutes\n",
      "episode 1860/10000, Eps Reward: -959.8028214655451, Epsilon: 0.11762768332975655, weights: 29.27886256761849, elapsed: 16.52412802775701 minutes\n",
      "episode 1870/10000, Eps Reward: -926.0860724850867, Epsilon: 0.11628194386447226, weights: 11.779815785586834, elapsed: 16.625912487506866 minutes\n",
      "episode 1880/10000, Eps Reward: -685.376245591884, Epsilon: 0.11495160055982938, weights: 20.21102586342022, elapsed: 16.881034672260284 minutes\n",
      "episode 1890/10000, Eps Reward: -877.4368836403222, Epsilon: 0.11363647727344031, weights: 39.699120885226876, elapsed: 17.032303829987843 minutes\n",
      "episode 1900/10000, Eps Reward: -731.8410726755723, Epsilon: 0.11233639987810436, weights: 15.489733949303627, elapsed: 17.2332786599795 minutes\n",
      "episode 1910/10000, Eps Reward: -955.1030038772072, Epsilon: 0.11105119623875258, weights: 57.872821751981974, elapsed: 17.297316773732504 minutes\n",
      "episode 1920/10000, Eps Reward: -771.9756415444025, Epsilon: 0.10978069618965641, weights: 62.352462351787835, elapsed: 17.45612071355184 minutes\n",
      "episode 1930/10000, Eps Reward: -903.1476225355418, Epsilon: 0.10852473151189732, weights: 19.76100242463872, elapsed: 17.57951505978902 minutes\n",
      "episode 1940/10000, Eps Reward: -680.1224379803601, Epsilon: 0.10728313591109373, weights: 111.29689338803291, elapsed: 17.834654756387074 minutes\n",
      "episode 1950/10000, Eps Reward: -966.639240324063, Epsilon: 0.10605574499538319, weights: 59.62001751177013, elapsed: 17.885156778494515 minutes\n",
      "episode 1960/10000, Eps Reward: -781.9683457856117, Epsilon: 0.10484239625365623, weights: 39.03403262840584, elapsed: 18.024175481001535 minutes\n",
      "episode 1970/10000, Eps Reward: -976.1305845026438, Epsilon: 0.10364292903403932, weights: 31.41921258997172, elapsed: 18.06738691329956 minutes\n",
      "episode 1980/10000, Eps Reward: -945.8123238619755, Epsilon: 0.1024571845226239, weights: 17.54026786983013, elapsed: 18.144185094038644 minutes\n",
      "episode 1990/10000, Eps Reward: -837.793136386333, Epsilon: 0.10128500572243895, weights: 16.093351991847157, elapsed: 18.346198586622872 minutes\n",
      "episode 2000/10000, Eps Reward: -950.9209386898103, Epsilon: 0.10012623743266384, weights: 16.339789278805256, elapsed: 18.419872256120048 minutes\n",
      "episode 2010/10000, Eps Reward: -925.2935606874314, Epsilon: 0.09898072622807927, weights: 45.51588293584064, elapsed: 18.529209633668263 minutes\n",
      "episode 2020/10000, Eps Reward: -740.5026249213932, Epsilon: 0.09784832043875323, weights: 9.389780888915993, elapsed: 18.723156627019247 minutes\n",
      "episode 2030/10000, Eps Reward: -967.7445980207834, Epsilon: 0.09672887012995926, weights: 17.210716236382723, elapsed: 18.77107302347819 minutes\n",
      "episode 2040/10000, Eps Reward: -953.47478677943, Epsilon: 0.09562222708232461, weights: 28.430016407743096, elapsed: 18.840588223934173 minutes\n",
      "episode 2050/10000, Eps Reward: -982.6535753196025, Epsilon: 0.09452824477220538, weights: 30.944129576906562, elapsed: 18.874752453962962 minutes\n",
      "episode 2060/10000, Eps Reward: -979.7676212326742, Epsilon: 0.09344677835228626, weights: 84.75453812815249, elapsed: 18.909829469521842 minutes\n",
      "episode 2070/10000, Eps Reward: -967.629781074165, Epsilon: 0.09237768463240227, weights: 27.39359322260134, elapsed: 18.95981256167094 minutes\n",
      "episode 2080/10000, Eps Reward: -789.119097146104, Epsilon: 0.09132082206057975, weights: 27.625498285517097, elapsed: 19.09258052110672 minutes\n",
      "episode 2090/10000, Eps Reward: -865.2092972506741, Epsilon: 0.09027605070429445, weights: 23.77694778330624, elapsed: 19.260230894883474 minutes\n",
      "episode 2100/10000, Eps Reward: -822.5355367247233, Epsilon: 0.0892432322319439, weights: 7.97908791154623, elapsed: 19.483871336778005 minutes\n",
      "episode 2110/10000, Eps Reward: -606.3091462067222, Epsilon: 0.08822222989453175, weights: 24.397064809687436, elapsed: 19.71190084616343 minutes\n",
      "episode 2120/10000, Eps Reward: -774.3523946550638, Epsilon: 0.08721290850756179, weights: 34.4150470495224, elapsed: 19.982141053676607 minutes\n",
      "episode 2130/10000, Eps Reward: -979.9751377008413, Epsilon: 0.08621513443313891, weights: 57.28515247814357, elapsed: 20.01780425310135 minutes\n",
      "episode 2140/10000, Eps Reward: -859.1489072431625, Epsilon: 0.0852287755622751, weights: 33.608201055787504, elapsed: 20.196423228581747 minutes\n",
      "episode 2150/10000, Eps Reward: -914.7464874025829, Epsilon: 0.08425370129739754, weights: 1.2715291469357908, elapsed: 20.309392762184142 minutes\n",
      "episode 2160/10000, Eps Reward: -841.6880076584144, Epsilon: 0.08328978253505716, weights: 7.609970453195274, elapsed: 20.51452811161677 minutes\n",
      "episode 2170/10000, Eps Reward: -897.868296924529, Epsilon: 0.08233689164883481, weights: 53.47743263281882, elapsed: 20.649211939175924 minutes\n",
      "episode 2180/10000, Eps Reward: -983.173445770015, Epsilon: 0.08139490247244299, weights: 65.76340783014894, elapsed: 20.683223203818002 minutes\n",
      "episode 2190/10000, Eps Reward: -954.2844441272127, Epsilon: 0.08046369028302104, weights: 43.349466029554605, elapsed: 20.7488254070282 minutes\n",
      "episode 2200/10000, Eps Reward: -652.1134220432813, Epsilon: 0.07954313178462137, weights: 29.51219852268696, elapsed: 21.04085090557734 minutes\n",
      "episode 2210/10000, Eps Reward: -914.1115567515675, Epsilon: 0.07863310509188452, weights: 22.608045306056738, elapsed: 21.15443400144577 minutes\n",
      "episode 2220/10000, Eps Reward: -922.4796134954388, Epsilon: 0.07773348971390122, weights: 54.534593090415, elapsed: 21.263512818018594 minutes\n",
      "episode 2230/10000, Eps Reward: -870.664247485962, Epsilon: 0.07684416653825892, weights: 109.55575515143573, elapsed: 21.42595767180125 minutes\n",
      "episode 2240/10000, Eps Reward: -960.8651892900623, Epsilon: 0.07596501781527072, weights: 31.299600617960095, elapsed: 21.486354907353718 minutes\n",
      "episode 2250/10000, Eps Reward: -746.5701179387079, Epsilon: 0.07509592714238508, weights: 20.35741671640426, elapsed: 21.680559146404267 minutes\n",
      "episode 2260/10000, Eps Reward: -888.1409840671877, Epsilon: 0.0742367794487736, weights: 40.72963044419885, elapsed: 21.825320184230804 minutes\n",
      "episode 2270/10000, Eps Reward: -908.8654072684018, Epsilon: 0.07338746098009515, weights: 32.88872515410185, elapsed: 21.94559154113134 minutes\n",
      "episode 2280/10000, Eps Reward: -927.6587307281943, Epsilon: 0.07254785928343449, weights: 41.98721540719271, elapsed: 22.048159607251485 minutes\n",
      "episode 2290/10000, Eps Reward: -964.8339786524817, Epsilon: 0.07171786319241302, weights: 15.33556574396789, elapsed: 22.10517336130142 minutes\n",
      "episode 2300/10000, Eps Reward: -754.7048935511511, Epsilon: 0.07089736281246993, weights: 54.96791848540306, elapsed: 22.288705027103425 minutes\n",
      "episode 2310/10000, Eps Reward: -722.6106837760651, Epsilon: 0.07008624950631179, weights: 31.3392288479954, elapsed: 22.512847514947257 minutes\n",
      "episode 2320/10000, Eps Reward: -965.4180163214405, Epsilon: 0.06928441587952858, weights: 27.931748571805656, elapsed: 22.570120147864024 minutes\n",
      "episode 2330/10000, Eps Reward: -964.1321192761164, Epsilon: 0.06849175576637419, weights: 9.981386776082218, elapsed: 22.63286011616389 minutes\n",
      "episode 2340/10000, Eps Reward: -927.4857933474523, Epsilon: 0.0677081642157098, weights: 8.423571653664112, elapsed: 22.736469785372417 minutes\n",
      "episode 2350/10000, Eps Reward: -924.8381491151974, Epsilon: 0.06693353747710788, weights: 15.433382153511047, elapsed: 22.846605583031973 minutes\n",
      "episode 2360/10000, Eps Reward: -821.7354885160206, Epsilon: 0.06616777298711521, weights: 6.817781599238515, elapsed: 23.08012086947759 minutes\n",
      "episode 2370/10000, Eps Reward: -945.5600474807441, Epsilon: 0.06541076935567322, weights: 13.882444666698575, elapsed: 23.15692726771037 minutes\n",
      "episode 2380/10000, Eps Reward: -856.3815394471774, Epsilon: 0.06466242635269351, weights: 23.08993039280176, elapsed: 23.345654916763305 minutes\n",
      "episode 2390/10000, Eps Reward: -989.9934963795098, Epsilon: 0.06392264489478694, weights: 40.721565533429384, elapsed: 23.37116802930832 minutes\n",
      "episode 2400/10000, Eps Reward: -995.4108676472299, Epsilon: 0.06319132703214475, weights: 21.79306273162365, elapsed: 23.383924599488576 minutes\n",
      "episode 2410/10000, Eps Reward: -901.4636241042978, Epsilon: 0.06246837593556958, weights: 46.339960454031825, elapsed: 23.515129085381826 minutes\n",
      "episode 2420/10000, Eps Reward: -799.4554072484163, Epsilon: 0.06175369588365491, weights: 19.020888907834888, elapsed: 23.64895553191503 minutes\n",
      "episode 2430/10000, Eps Reward: -641.9077867541728, Epsilon: 0.061047192250111224, weights: 89.08654216863215, elapsed: 23.984519271055856 minutes\n",
      "episode 2440/10000, Eps Reward: -586.572174397969, Epsilon: 0.0603487714912371, weights: 1.01536506973207, elapsed: 24.261879309018454 minutes\n",
      "episode 2450/10000, Eps Reward: -845.9921950628293, Epsilon: 0.059658341133533736, weights: 71.81011882610619, elapsed: 24.465365155537924 minutes\n",
      "episode 2460/10000, Eps Reward: -930.5276039402943, Epsilon: 0.05897580976146106, weights: 18.087279967963696, elapsed: 24.568699383735655 minutes\n",
      "episode 2470/10000, Eps Reward: -784.7835123937793, Epsilon: 0.05830108700533397, weights: 16.641823686659336, elapsed: 24.72257145643234 minutes\n",
      "episode 2480/10000, Eps Reward: -980.221514116748, Epsilon: 0.05763408352935713, weights: 9.694000373594463, elapsed: 24.766565040747324 minutes\n",
      "episode 2490/10000, Eps Reward: -994.0520975483589, Epsilon: 0.056974711019796474, weights: 55.05320336483419, elapsed: 24.783485444386802 minutes\n",
      "episode 2500/10000, Eps Reward: -840.0099005674181, Epsilon: 0.05632288217328622, weights: 6.694305032491684, elapsed: 25.00789108276367 minutes\n",
      "episode 2510/10000, Eps Reward: -865.9812978373802, Epsilon: 0.05567851068526956, weights: 17.040280391462147, elapsed: 25.203624868392943 minutes\n",
      "episode 2520/10000, Eps Reward: -955.827615991682, Epsilon: 0.05504151123857156, weights: 54.10462687537074, elapsed: 25.282553764184318 minutes\n",
      "episode 2530/10000, Eps Reward: -948.1960179976204, Epsilon: 0.05441179949210297, weights: 30.6812213473022, elapsed: 25.362475089232127 minutes\n",
      "episode 2540/10000, Eps Reward: -988.5862545450971, Epsilon: 0.053789292069693025, weights: 44.67897618934512, elapsed: 25.388491507371267 minutes\n",
      "episode 2550/10000, Eps Reward: -987.1035249857956, Epsilon: 0.053173906549050215, weights: 31.495339658111334, elapsed: 25.418704998493194 minutes\n",
      "episode 2560/10000, Eps Reward: -928.3464727754529, Epsilon: 0.05256556145084922, weights: 9.165646197274327, elapsed: 25.527523203690848 minutes\n",
      "episode 2570/10000, Eps Reward: -925.7849569517766, Epsilon: 0.05196417622794278, weights: 28.80769808962941, elapsed: 25.632174309094747 minutes\n",
      "episode 2580/10000, Eps Reward: -917.227994137566, Epsilon: 0.051369671254696894, weights: 13.085972879081964, elapsed: 25.75843672355016 minutes\n",
      "episode 2590/10000, Eps Reward: -705.9633457628677, Epsilon: 0.05078196781644821, weights: 53.16475720703602, elapsed: 26.00967127084732 minutes\n",
      "episode 2600/10000, Eps Reward: -908.1647067573556, Epsilon: 0.050200988099081766, weights: 33.416880866512656, elapsed: 26.14868630170822 minutes\n",
      "episode 2610/10000, Eps Reward: -897.0951839919805, Epsilon: 0.04962665517872822, weights: 16.28673672536388, elapsed: 26.293950446446736 minutes\n",
      "episode 2620/10000, Eps Reward: -927.1343183715728, Epsilon: 0.04905889301157878, weights: 15.23054482601583, elapsed: 26.407936795552573 minutes\n",
      "episode 2630/10000, Eps Reward: -871.9478243502905, Epsilon: 0.048497626423816775, weights: 22.020226508378983, elapsed: 26.58161044915517 minutes\n",
      "episode 2640/10000, Eps Reward: -953.5141129702718, Epsilon: 0.047942781101664333, weights: 21.032528081908822, elapsed: 26.66025125583013 minutes\n",
      "episode 2650/10000, Eps Reward: -997.3214567615123, Epsilon: 0.04739428358154294, weights: 32.6350454762578, elapsed: 26.66877725919088 minutes\n",
      "episode 2660/10000, Eps Reward: -986.8957558273196, Epsilon: 0.04685206124034663, weights: 34.275602345820516, elapsed: 26.69745879570643 minutes\n",
      "episode 2670/10000, Eps Reward: -852.1120058198223, Epsilon: 0.04631604228582642, weights: 36.08149519236758, elapsed: 26.907637270291648 minutes\n",
      "episode 2680/10000, Eps Reward: -448.38620940081745, Epsilon: 0.045786155747084674, weights: 0.28689867816865444, elapsed: 27.240146577358246 minutes\n",
      "episode 2690/10000, Eps Reward: -874.2778373281044, Epsilon: 0.045262331465178426, weights: 30.72346927365288, elapsed: 27.42041038274765 minutes\n",
      "episode 2700/10000, Eps Reward: -941.9026179786957, Epsilon: 0.044744500083829936, weights: 35.24670861149207, elapsed: 27.50865949789683 minutes\n",
      "episode 2710/10000, Eps Reward: -869.9362319565735, Epsilon: 0.04423259304024377, weights: 64.888342843391, elapsed: 27.688120679060617 minutes\n",
      "episode 2720/10000, Eps Reward: -636.1491019644434, Epsilon: 0.043726542556028744, weights: 52.175685899332166, elapsed: 27.91270557641983 minutes\n",
      "episode 2730/10000, Eps Reward: -452.1911583870609, Epsilon: 0.043226281628223874, weights: 45.03344874829054, elapsed: 28.243701326847077 minutes\n",
      "episode 2740/10000, Eps Reward: -748.2365736612969, Epsilon: 0.042731744020426926, weights: 12.148164596874267, elapsed: 28.453151082992555 minutes\n",
      "episode 2750/10000, Eps Reward: -496.0649832181318, Epsilon: 0.04224286425402446, weights: 37.252152195665985, elapsed: 28.854072872797648 minutes\n",
      "episode 2760/10000, Eps Reward: -896.9619814638163, Epsilon: 0.0417595775995222, weights: 49.04695696616545, elapsed: 29.015737414360046 minutes\n",
      "episode 2770/10000, Eps Reward: -764.8140080129081, Epsilon: 0.04128182006797467, weights: 20.439638320356607, elapsed: 29.207080495357513 minutes\n",
      "episode 2780/10000, Eps Reward: -976.0057637120381, Epsilon: 0.04080952840251274, weights: 34.93682812154293, elapsed: 29.253954553604125 minutes\n",
      "episode 2790/10000, Eps Reward: -703.2808058431383, Epsilon: 0.04034264006996824, weights: 94.6867999471724, elapsed: 29.523915727933247 minutes\n",
      "episode 2800/10000, Eps Reward: -942.2950393086228, Epsilon: 0.03988109325259433, weights: 11.85162663180381, elapsed: 29.621539974212645 minutes\n",
      "episode 2810/10000, Eps Reward: -913.2819349462383, Epsilon: 0.03942482683988056, weights: 12.151555204764009, elapsed: 29.752744277318318 minutes\n",
      "episode 2820/10000, Eps Reward: -793.6700345527026, Epsilon: 0.03897378042046166, weights: 0.1735347956418991, elapsed: 29.907959695657095 minutes\n",
      "episode 2830/10000, Eps Reward: -823.3916741705531, Epsilon: 0.03852789427411883, weights: 18.099801584146917, elapsed: 30.156533948580424 minutes\n",
      "episode 2840/10000, Eps Reward: -986.8898772922541, Epsilon: 0.038087109363872565, weights: 30.309756327420473, elapsed: 30.187759721279143 minutes\n",
      "episode 2850/10000, Eps Reward: -837.3020363034391, Epsilon: 0.037651367328165944, weights: 18.03231132309884, elapsed: 30.437166329224905 minutes\n",
      "episode 2860/10000, Eps Reward: -707.2102518841295, Epsilon: 0.037220610473137315, weights: 32.640034140087664, elapsed: 30.717539950211844 minutes\n",
      "episode 2870/10000, Eps Reward: -826.9770446290324, Epsilon: 0.03679478176498148, weights: 10.569085763767362, elapsed: 30.979238430658977 minutes\n",
      "episode 2880/10000, Eps Reward: -914.9971308468088, Epsilon: 0.036373824822398114, weights: 19.75433912873268, elapsed: 31.115079812208812 minutes\n",
      "episode 2890/10000, Eps Reward: -779.8844873272291, Epsilon: 0.035957683909126764, weights: 31.862319611012936, elapsed: 31.294706869125367 minutes\n",
      "episode 2900/10000, Eps Reward: -786.5486425315621, Epsilon: 0.035546303926567095, weights: 17.77890237234533, elapsed: 31.46392153898875 minutes\n",
      "episode 2910/10000, Eps Reward: -954.394860212371, Epsilon: 0.035139630406483664, weights: 29.044763260986656, elapsed: 31.54722531636556 minutes\n",
      "episode 2920/10000, Eps Reward: -944.309960431621, Epsilon: 0.03473760950379412, weights: 16.004814561456442, elapsed: 31.64927460749944 minutes\n",
      "episode 2930/10000, Eps Reward: -727.2145751648126, Epsilon: 0.034340187989439906, weights: 36.287252283189446, elapsed: 31.910664216677347 minutes\n",
      "episode 2940/10000, Eps Reward: -667.3133863089589, Epsilon: 0.03394731324333853, weights: 30.74412772618234, elapsed: 32.25327861706416 minutes\n",
      "episode 2950/10000, Eps Reward: -839.4279561341839, Epsilon: 0.033558933247416496, weights: 6.673260140232742, elapsed: 32.504470972220105 minutes\n",
      "episode 2960/10000, Eps Reward: -960.2646591974604, Epsilon: 0.0331749965787219, weights: 22.167112211231142, elapsed: 32.57998349666595 minutes\n",
      "episode 2970/10000, Eps Reward: -880.429395924741, Epsilon: 0.03279545240261584, weights: 48.39354207506403, elapsed: 32.769504809379576 minutes\n",
      "episode 2980/10000, Eps Reward: -807.1744830468682, Epsilon: 0.0324202504660417, weights: 47.449303256347775, elapsed: 32.91781782706578 minutes\n",
      "episode 2990/10000, Eps Reward: -859.3755414043917, Epsilon: 0.032049341090871535, weights: 35.50776406005025, elapsed: 33.13578589359919 minutes\n",
      "episode 3000/10000, Eps Reward: -916.2643733818546, Epsilon: 0.03168267516732841, weights: 61.09237725287676, elapsed: 33.2761390487353 minutes\n",
      "episode 3010/10000, Eps Reward: -647.4434981197285, Epsilon: 0.03132020414748412, weights: 26.857900297269225, elapsed: 33.66400912602742 minutes\n",
      "episode 3020/10000, Eps Reward: -975.9026884626135, Epsilon: 0.030961880038831303, weights: 13.749531378503889, elapsed: 33.71946113506953 minutes\n",
      "episode 3030/10000, Eps Reward: -740.9211627711026, Epsilon: 0.030607655397928993, weights: 25.22532442584634, elapsed: 33.975624899069466 minutes\n",
      "episode 3040/10000, Eps Reward: -803.2479750230589, Epsilon: 0.03025748332412096, weights: 35.3065157905221, elapsed: 34.137026743094125 minutes\n",
      "episode 3050/10000, Eps Reward: -782.4512343573396, Epsilon: 0.029911317453325897, weights: 5.614483842626214, elapsed: 34.47963777383168 minutes\n",
      "episode 3060/10000, Eps Reward: -932.3961939940306, Epsilon: 0.029569111951898618, weights: 15.003750570118427, elapsed: 34.60796217123667 minutes\n",
      "episode 3070/10000, Eps Reward: -762.0141632576475, Epsilon: 0.02923082151056155, weights: 0.4977863971143961, elapsed: 34.829517833391826 minutes\n",
      "episode 3080/10000, Eps Reward: -641.480802512237, Epsilon: 0.028896401338405594, weights: 30.144552633166313, elapsed: 35.236169668038684 minutes\n",
      "episode 3090/10000, Eps Reward: -437.0456748882408, Epsilon: 0.028565807156959624, weights: 40.535336731001735, elapsed: 35.643585968017575 minutes\n",
      "episode 3100/10000, Eps Reward: -718.3195816584877, Epsilon: 0.028238995194327897, weights: 10.152203481644392, elapsed: 35.94790748357773 minutes\n",
      "episode 3110/10000, Eps Reward: -571.7955193919671, Epsilon: 0.027915922179394446, weights: 46.5555280148983, elapsed: 36.470405693848924 minutes\n",
      "episode 3120/10000, Eps Reward: -541.6373480776458, Epsilon: 0.027596545336093882, weights: 20.40028547681868, elapsed: 36.87549469868342 minutes\n",
      "episode 3130/10000, Eps Reward: -447.21750183655774, Epsilon: 0.02728082237774761, weights: 20.29276785068214, elapsed: 37.43242724339167 minutes\n",
      "episode 3140/10000, Eps Reward: -231.30102839265427, Epsilon: 0.02696871150146498, weights: 0.3491743002086878, elapsed: 38.00846471389135 minutes\n",
      "episode 3150/10000, Eps Reward: -379.8991112528961, Epsilon: 0.026660171382608393, weights: 17.361780801787972, elapsed: 38.67205859422684 minutes\n",
      "episode 3160/10000, Eps Reward: 102.25974140255849, Epsilon: 0.026355161169321777, weights: 0.5701101291924715, elapsed: 39.60507386128108 minutes\n",
      "episode 3170/10000, Eps Reward: 31.009629772276547, Epsilon: 0.026053640477121665, weights: 0.1849528702441603, elapsed: 40.43945202032725 minutes\n",
      "episode 3180/10000, Eps Reward: -474.3204272283821, Epsilon: 0.025755569383550093, weights: 23.00014956528321, elapsed: 40.96925006310145 minutes\n",
      "episode 3190/10000, Eps Reward: -622.1237711185621, Epsilon: 0.02546090842288877, weights: 19.083986267680302, elapsed: 41.263161567846936 minutes\n",
      "episode 3200/10000, Eps Reward: -617.3254590248362, Epsilon: 0.025169618580933653, weights: 25.2482528090477, elapsed: 41.559936447938284 minutes\n",
      "episode 3210/10000, Eps Reward: -769.2172887755795, Epsilon: 0.024881661289829313, weights: 27.090794330462813, elapsed: 41.7813754717509 minutes\n",
      "episode 3220/10000, Eps Reward: -405.3458291126718, Epsilon: 0.024596998422962417, weights: 67.43730407953262, elapsed: 42.25607448418935 minutes\n",
      "episode 3230/10000, Eps Reward: -759.4920874711827, Epsilon: 0.024315592289913614, weights: 62.175421465188265, elapsed: 42.6528572956721 minutes\n",
      "episode 3240/10000, Eps Reward: -754.7386776650185, Epsilon: 0.024037405631467182, weights: 31.883407462388277, elapsed: 42.893895677725475 minutes\n",
      "episode 3250/10000, Eps Reward: -556.9057414264043, Epsilon: 0.0237624016146778, weights: 31.696101190522313, elapsed: 43.28873476187388 minutes\n",
      "episode 3260/10000, Eps Reward: -906.1924266187647, Epsilon: 0.023490543827993683, weights: 48.48010703548789, elapsed: 43.469793697198234 minutes\n",
      "episode 3270/10000, Eps Reward: -579.8416525848014, Epsilon: 0.023221796276435606, weights: 14.361393729224801, elapsed: 43.833698852856955 minutes\n",
      "episode 3280/10000, Eps Reward: -233.70226037353433, Epsilon: 0.02295612337683098, weights: 34.71732494980097, elapsed: 44.40930523872375 minutes\n",
      "episode 3290/10000, Eps Reward: -236.2553095778091, Epsilon: 0.022693489953102556, weights: 56.174628246575594, elapsed: 44.9872514128685 minutes\n",
      "episode 3300/10000, Eps Reward: -443.6696477016332, Epsilon: 0.022433861231610962, weights: 0.08879083837382495, elapsed: 45.40247569878896 minutes\n",
      "episode 3310/10000, Eps Reward: -603.2385232683166, Epsilon: 0.022177202836550544, weights: 0.48547420324757695, elapsed: 45.883318567276 minutes\n",
      "episode 3320/10000, Eps Reward: -734.4676238785262, Epsilon: 0.021923480785397888, weights: 41.48490847926587, elapsed: 46.159268347422284 minutes\n",
      "episode 3330/10000, Eps Reward: -906.7715884272329, Epsilon: 0.021672661484412395, weights: 59.76831846125424, elapsed: 46.323275144894914 minutes\n",
      "episode 3340/10000, Eps Reward: -754.2987106396542, Epsilon: 0.021424711724188365, weights: 18.30282862484455, elapsed: 46.56996414264043 minutes\n",
      "episode 3350/10000, Eps Reward: -744.5593233908304, Epsilon: 0.021179598675257937, weights: 52.67005529161543, elapsed: 46.83145575126012 minutes\n",
      "episode 3360/10000, Eps Reward: 66.40334398210895, Epsilon: 0.020937289883744336, weights: 38.28743962198496, elapsed: 47.55700734853745 minutes\n",
      "episode 3370/10000, Eps Reward: -873.618285403994, Epsilon: 0.02069775326706488, weights: 47.844701170921326, elapsed: 47.775686009724936 minutes\n",
      "episode 3380/10000, Eps Reward: -590.5760576285733, Epsilon: 0.0204609571096831, weights: 0.22267152229323983, elapsed: 48.10656120379766 minutes\n",
      "episode 3390/10000, Eps Reward: -424.8354057800604, Epsilon: 0.020226870058909534, weights: 60.481259846361354, elapsed: 48.550439937909445 minutes\n",
      "episode 3400/10000, Eps Reward: -276.97908583618516, Epsilon: 0.01999546112075045, weights: 0.756877897772938, elapsed: 49.2291167140007 minutes\n",
      "episode 3410/10000, Eps Reward: -807.9231181725452, Epsilon: 0.019766699655804174, weights: 12.573301693424582, elapsed: 49.55793028672536 minutes\n",
      "episode 3420/10000, Eps Reward: -262.80488453820243, Epsilon: 0.019540555375204303, weights: 37.27165833860636, elapsed: 50.09578419526418 minutes\n",
      "episode 3430/10000, Eps Reward: -804.4364652095857, Epsilon: 0.019316998336609346, weights: 3.2170469427946955, elapsed: 50.427704362074536 minutes\n",
      "episode 3440/10000, Eps Reward: -996.610302105476, Epsilon: 0.019095998940238255, weights: 24.88661588798277, elapsed: 50.43993042310079 minutes\n",
      "episode 3450/10000, Eps Reward: -957.2126066885914, Epsilon: 0.018877527924951284, weights: 14.796225787140429, elapsed: 50.5219465136528 minutes\n",
      "episode 3460/10000, Eps Reward: -758.5705901306753, Epsilon: 0.018661556364375737, weights: 8.169409483671188, elapsed: 50.76250267823537 minutes\n",
      "episode 3470/10000, Eps Reward: -764.4905783236042, Epsilon: 0.01844805566307599, weights: 42.763384263031185, elapsed: 50.98482434352239 minutes\n",
      "episode 3480/10000, Eps Reward: -718.5022010829047, Epsilon: 0.018236997552767347, weights: 3.28682769369334, elapsed: 51.290712503592175 minutes\n",
      "episode 3490/10000, Eps Reward: -838.2343135115801, Epsilon: 0.018028354088573197, weights: 20.49834534758702, elapsed: 51.56329343318939 minutes\n",
      "episode 3500/10000, Eps Reward: -693.3401464757752, Epsilon: 0.017822097645325073, weights: 14.945841513574123, elapsed: 51.90562543869019 minutes\n",
      "episode 3510/10000, Eps Reward: -815.0725437649487, Epsilon: 0.017618200913904904, weights: 19.961168006062508, elapsed: 52.054813794294994 minutes\n",
      "episode 3520/10000, Eps Reward: -955.2981781910563, Epsilon: 0.01741663689762922, weights: 59.6918050237, elapsed: 52.14877240260442 minutes\n",
      "episode 3530/10000, Eps Reward: -498.3476720410951, Epsilon: 0.017217378908674696, weights: 0.29577595414593816, elapsed: 52.63404262860616 minutes\n",
      "episode 3540/10000, Eps Reward: -566.9229392010085, Epsilon: 0.01702040056454458, weights: 1.440897791646421, elapsed: 53.01490277051926 minutes\n",
      "episode 3550/10000, Eps Reward: -975.449664732923, Epsilon: 0.016825675784575538, weights: 11.98797704000026, elapsed: 53.075578439235684 minutes\n",
      "episode 3560/10000, Eps Reward: -401.8798496999855, Epsilon: 0.016633178786484498, weights: 10.104843282606453, elapsed: 53.56503948370616 minutes\n",
      "episode 3570/10000, Eps Reward: -102.38543338627265, Epsilon: 0.01644288408295497, weights: 0.03700639749877155, elapsed: 54.18823879957199 minutes\n",
      "episode 3580/10000, Eps Reward: -105.6435128608044, Epsilon: 0.016254766478262423, weights: 4.786121052922681, elapsed: 54.803152561187744 minutes\n",
      "episode 3590/10000, Eps Reward: -75.85116554161672, Epsilon: 0.01606880106493829, weights: 0.5651933281915262, elapsed: 55.46803390582402 minutes\n",
      "episode 3600/10000, Eps Reward: 131.96967933527384, Epsilon: 0.01588496322047214, weights: 27.300697112455964, elapsed: 56.294594780604044 minutes\n",
      "episode 3610/10000, Eps Reward: -781.7068491004472, Epsilon: 0.015703228604051527, weights: 24.444060506299138, elapsed: 56.49738831520081 minutes\n",
      "episode 3620/10000, Eps Reward: -603.9440305453285, Epsilon: 0.015523573153339206, weights: 0.47772878827527165, elapsed: 56.97693392833074 minutes\n",
      "episode 3630/10000, Eps Reward: -593.0093239095119, Epsilon: 0.015345973081287191, weights: 20.722174153663218, elapsed: 57.3166779478391 minutes\n",
      "episode 3640/10000, Eps Reward: -421.6112889392219, Epsilon: 0.015170404872987243, weights: 14.489416441880167, elapsed: 57.75767930746078 minutes\n",
      "episode 3650/10000, Eps Reward: -668.6047400143743, Epsilon: 0.014996845282557429, weights: 30.367014018818736, elapsed: 58.12736015319824 minutes\n",
      "episode 3660/10000, Eps Reward: -525.5499370886266, Epsilon: 0.014825271330064269, weights: 22.73986384831369, elapsed: 58.56445212761561 minutes\n",
      "episode 3670/10000, Eps Reward: -209.70636273042837, Epsilon: 0.014655660298480104, weights: 0.02563416352495551, elapsed: 59.18587299187978 minutes\n",
      "episode 3680/10000, Eps Reward: -673.5276414673702, Epsilon: 0.01448798973067529, weights: 10.990005983272567, elapsed: 59.56100840965907 minutes\n",
      "episode 3690/10000, Eps Reward: -90.28085622750012, Epsilon: 0.014322237426444786, weights: 0.07689474447397515, elapsed: 60.199611179033916 minutes\n",
      "episode 3700/10000, Eps Reward: 125.35384201374575, Epsilon: 0.014158381439568754, weights: 0.19538378482684493, elapsed: 61.02929497559865 minutes\n",
      "episode 3710/10000, Eps Reward: 18.8102707564247, Epsilon: 0.013996400074906814, weights: 0.09833966987207532, elapsed: 61.83828367392222 minutes\n",
      "episode 3720/10000, Eps Reward: 102.59243394016039, Epsilon: 0.01383627188552552, weights: 40.98100812360644, elapsed: 62.65679781039556 minutes\n",
      "episode 3730/10000, Eps Reward: -222.2683770314301, Epsilon: 0.013677975669858705, weights: 4.209610365331173, elapsed: 64.10424104531606 minutes\n",
      "episode 3740/10000, Eps Reward: -236.87849332967016, Epsilon: 0.013521490468900308, weights: 0.3387167211622, elapsed: 65.50581849018732 minutes\n",
      "episode 3750/10000, Eps Reward: 250.5693022791539, Epsilon: 0.013366795563429347, weights: 17.618795845657587, elapsed: 67.99751958052317 minutes\n",
      "episode 3760/10000, Eps Reward: -111.73806244750713, Epsilon: 0.013213870471266596, weights: 67.06331992521882, elapsed: 69.93513606389364 minutes\n",
      "episode 3770/10000, Eps Reward: 265.67310846660575, Epsilon: 0.013062694944562673, weights: 0.266784836538136, elapsed: 72.16210975646973 minutes\n",
      "episode 3780/10000, Eps Reward: 20.27568033001961, Epsilon: 0.012913248967117149, weights: 35.0593496337533, elapsed: 74.20770231485366 minutes\n",
      "episode 3790/10000, Eps Reward: -788.0551773855971, Epsilon: 0.012765512751728339, weights: 76.46198284067214, elapsed: 74.68310785293579 minutes\n",
      "episode 3800/10000, Eps Reward: 163.36009565683005, Epsilon: 0.012619466737573394, weights: 14.957382518798113, elapsed: 76.89904431899389 minutes\n",
      "episode 3810/10000, Eps Reward: -284.32667892199163, Epsilon: 0.012475091587618373, weights: 0.41248289309442043, elapsed: 86.52712939580282 minutes\n",
      "episode 3820/10000, Eps Reward: -310.0096690365766, Epsilon: 0.012332368186057959, weights: 0.11701096082106233, elapsed: 87.15748331149419 minutes\n",
      "episode 3830/10000, Eps Reward: -556.8464711950515, Epsilon: 0.01219127763578444, weights: 16.259687522426248, elapsed: 87.54539039532344 minutes\n",
      "episode 3840/10000, Eps Reward: 315.1570282418969, Epsilon: 0.012051801255885671, weights: 1.01115345582366, elapsed: 89.3454246322314 minutes\n",
      "episode 3850/10000, Eps Reward: 347.30907462671246, Epsilon: 0.01191392057917166, weights: 0.23562445514835417, elapsed: 143.4173717021942 minutes\n",
      "episode 3860/10000, Eps Reward: -121.42619834099926, Epsilon: 0.011777617349729427, weights: 24.619353719055653, elapsed: 144.1477786739667 minutes\n",
      "episode 3870/10000, Eps Reward: -91.37787418949532, Epsilon: 0.011642873520505864, weights: 0.09857770154485479, elapsed: 144.76978053649268 minutes\n",
      "episode 3880/10000, Eps Reward: -601.9502777801682, Epsilon: 0.011509671250918235, weights: 0.07265369454398751, elapsed: 145.07384512821832 minutes\n",
      "episode 3890/10000, Eps Reward: -481.8744050180193, Epsilon: 0.01137799290449202, weights: 9.856499817222357, elapsed: 145.55469626188278 minutes\n",
      "episode 3900/10000, Eps Reward: -348.0658624655641, Epsilon: 0.011247821046525776, weights: 0.8089310452342033, elapsed: 146.10191682974497 minutes\n",
      "episode 3910/10000, Eps Reward: -412.1507607279288, Epsilon: 0.011119138441782712, weights: 27.93064383789897, elapsed: 146.5452733596166 minutes\n",
      "episode 3920/10000, Eps Reward: -441.4023351501366, Epsilon: 0.0109919280522087, weights: 10.249588857404888, elapsed: 147.0935288310051 minutes\n",
      "episode 3930/10000, Eps Reward: -364.87385339537616, Epsilon: 0.010866173034676357, weights: 0.01297725093900226, elapsed: 147.61107818285623 minutes\n",
      "episode 3940/10000, Eps Reward: -400.6216112384006, Epsilon: 0.010741856738754945, weights: 13.722731817513704, elapsed: 148.23024193048477 minutes\n",
      "episode 3950/10000, Eps Reward: -563.2386818704377, Epsilon: 0.01061896270450582, weights: 4.4770085252821445, elapsed: 148.59510934352875 minutes\n",
      "episode 3960/10000, Eps Reward: -34.274498157080885, Epsilon: 0.010497474660303045, weights: 12.081698384135962, elapsed: 149.3050720691681 minutes\n",
      "episode 3970/10000, Eps Reward: -270.15740126838807, Epsilon: 0.010377376520678987, weights: 34.06328599154949, elapsed: 149.81298932234446 minutes\n",
      "episode 3980/10000, Eps Reward: 426.3282313394776, Epsilon: 0.01025865238419453, weights: 0.1135601345449686, elapsed: 150.74550385872524 minutes\n",
      "episode 3990/10000, Eps Reward: -54.58495148971109, Epsilon: 0.010141286531333674, weights: 23.694629596546292, elapsed: 151.4161522547404 minutes\n",
      "episode 4000/10000, Eps Reward: -585.7746532367689, Epsilon: 0.010025263422422208, weights: 58.29620715230703, elapsed: 151.74726608991622 minutes\n",
      "episode 4010/10000, Eps Reward: -338.51292758870676, Epsilon: 0.009910567695570197, weights: 11.766916973516345, elapsed: 152.31219685077667 minutes\n",
      "episode 4020/10000, Eps Reward: -500.65982306708213, Epsilon: 0.00979718416463801, weights: 19.93061277270317, elapsed: 152.78443480730056 minutes\n",
      "episode 4030/10000, Eps Reward: -160.3309732208132, Epsilon: 0.009685097817225635, weights: 12.445505540817976, elapsed: 153.46521188020705 minutes\n",
      "episode 4040/10000, Eps Reward: -279.2895937865905, Epsilon: 0.009574293812684957, weights: 16.01126243919134, elapsed: 154.11579230626424 minutes\n",
      "episode 4050/10000, Eps Reward: -432.91342027122727, Epsilon: 0.009464757480154823, weights: 19.052306961268187, elapsed: 154.52511005401612 minutes\n",
      "episode 4060/10000, Eps Reward: -113.99295433344155, Epsilon: 0.009356474316618553, weights: 15.947761572897434, elapsed: 155.2724492629369 minutes\n",
      "episode 4070/10000, Eps Reward: -10.21696821707726, Epsilon: 0.009249429984983678, weights: 6.359407674521208, elapsed: 156.01726488669712 minutes\n",
      "episode 4080/10000, Eps Reward: -95.06241047543189, Epsilon: 0.00914361031218368, weights: 39.51655078306794, elapsed: 156.6384268760681 minutes\n",
      "episode 4090/10000, Eps Reward: -16.57049729867807, Epsilon: 0.009039001287301411, weights: 33.35448282957077, elapsed: 157.37127054929732 minutes\n",
      "episode 4100/10000, Eps Reward: -426.59305095188375, Epsilon: 0.008935589059713995, weights: 10.643389273434877, elapsed: 157.79222276210785 minutes\n",
      "episode 4110/10000, Eps Reward: -536.1517702348375, Epsilon: 0.00883335993725896, weights: 16.290001168847084, elapsed: 158.21631489992143 minutes\n",
      "episode 4120/10000, Eps Reward: -751.4865133753271, Epsilon: 0.008732300384421337, weights: 48.87492245621979, elapsed: 158.44907358090083 minutes\n",
      "episode 4130/10000, Eps Reward: -990.0286013826301, Epsilon: 0.008632397020541515, weights: 31.141380090266466, elapsed: 158.47924475272495 minutes\n",
      "episode 4140/10000, Eps Reward: -911.6448294459293, Epsilon: 0.008533636618043586, weights: 36.64800637960434, elapsed: 158.62477138837178 minutes\n",
      "episode 4150/10000, Eps Reward: -920.4589176709394, Epsilon: 0.008436006100683976, weights: 15.54519178532064, elapsed: 158.7755002617836 minutes\n",
      "episode 4160/10000, Eps Reward: -584.422409291011, Epsilon: 0.008339492541820084, weights: 18.687676060944796, elapsed: 159.11212282975515 minutes\n",
      "episode 4170/10000, Eps Reward: -620.00272642809, Epsilon: 0.008244083162698762, weights: 17.06112153083086, elapsed: 159.40213048855463 minutes\n",
      "episode 4180/10000, Eps Reward: -919.9866877160836, Epsilon: 0.008149765330764353, weights: 22.668750427663326, elapsed: 159.53726682662963 minutes\n",
      "episode 4190/10000, Eps Reward: -817.6032226430042, Epsilon: 0.008056526557986098, weights: 19.404423017054796, elapsed: 159.67547403971355 minutes\n",
      "episode 4200/10000, Eps Reward: -639.5464060347899, Epsilon: 0.007964354499204676, weights: 9.711042121052742, elapsed: 159.925408299764 minutes\n",
      "episode 4210/10000, Eps Reward: -951.4928997483676, Epsilon: 0.007873236950497646, weights: 16.643825570121408, elapsed: 160.0196459889412 minutes\n",
      "episode 4220/10000, Eps Reward: -521.7854888843178, Epsilon: 0.007783161847563616, weights: 9.225742984563112, elapsed: 160.4601744333903 minutes\n",
      "episode 4230/10000, Eps Reward: -895.0070936841281, Epsilon: 0.007694117264124883, weights: 8.256958559155464, elapsed: 160.6329820672671 minutes\n",
      "episode 4240/10000, Eps Reward: -927.2813928886968, Epsilon: 0.0076060914103483444, weights: 7.089791444130242, elapsed: 160.75457192262013 minutes\n",
      "episode 4250/10000, Eps Reward: -214.34256691411275, Epsilon: 0.007519072631284485, weights: 0.6379663227126002, elapsed: 161.33668524821599 minutes\n",
      "episode 4260/10000, Eps Reward: -252.75085879782077, Epsilon: 0.007433049405324216, weights: 3.261383108794689, elapsed: 161.86255036989849 minutes\n",
      "episode 4270/10000, Eps Reward: -796.8373269321635, Epsilon: 0.007348010342673371, weights: 11.731375385075808, elapsed: 162.03462424675624 minutes\n",
      "episode 4280/10000, Eps Reward: -925.5276403037667, Epsilon: 0.007263944183844659, weights: 10.155579749494791, elapsed: 162.16869376103082 minutes\n",
      "episode 4290/10000, Eps Reward: -792.7638811945741, Epsilon: 0.00718083979816686, weights: 26.20681256055832, elapsed: 162.34156971375148 minutes\n",
      "episode 4300/10000, Eps Reward: 239.8809616176953, Epsilon: 0.007098686182311086, weights: 30.12683743983507, elapsed: 163.15615571339924 minutes\n",
      "episode 4310/10000, Eps Reward: -592.489319821722, Epsilon: 0.007017472458833904, weights: 15.690949123352766, elapsed: 163.5000507235527 minutes\n",
      "episode 4320/10000, Eps Reward: -186.4314009308665, Epsilon: 0.0069371878747371135, weights: 7.263212701305747, elapsed: 164.1303234775861 minutes\n",
      "episode 4330/10000, Eps Reward: -749.6875699884232, Epsilon: 0.006857821800044016, weights: 6.846147528849542, elapsed: 164.38336194753646 minutes\n",
      "episode 4340/10000, Eps Reward: -806.234139006455, Epsilon: 0.006779363726391965, weights: 15.393106396310031, elapsed: 164.53851938645045 minutes\n",
      "episode 4350/10000, Eps Reward: -728.8211779452197, Epsilon: 0.006701803265641017, weights: 26.81946363672614, elapsed: 164.81214008331298 minutes\n",
      "episode 4360/10000, Eps Reward: -735.1242647806296, Epsilon: 0.006625130148498509, weights: 4.387832069769502, elapsed: 165.07559481461843 minutes\n",
      "episode 4370/10000, Eps Reward: -965.0897915919635, Epsilon: 0.006549334223159361, weights: 24.168222188949585, elapsed: 165.1505688826243 minutes\n",
      "episode 4380/10000, Eps Reward: -269.1188922233222, Epsilon: 0.00647440545396194, weights: 15.546246079728007, elapsed: 165.66146869659423 minutes\n",
      "episode 4390/10000, Eps Reward: -497.1145804544849, Epsilon: 0.006400333920059304, weights: 21.896637603640556, elapsed: 166.14139737685522 minutes\n",
      "episode 4400/10000, Eps Reward: -608.8976243822602, Epsilon: 0.006327109814105645, weights: 25.45330710709095, elapsed: 166.44259858528773 minutes\n",
      "episode 4410/10000, Eps Reward: -796.7944742326985, Epsilon: 0.006254723440957754, weights: 31.41211429797113, elapsed: 166.6156967639923 minutes\n",
      "episode 4420/10000, Eps Reward: 274.66265103104064, Epsilon: 0.006183165216391359, weights: 0.4431136595085263, elapsed: 167.4961812098821 minutes\n",
      "episode 4430/10000, Eps Reward: -798.0652082835494, Epsilon: 0.006112425665832124, weights: 24.336167484521866, elapsed: 167.66513704458873 minutes\n",
      "episode 4440/10000, Eps Reward: -627.8635337699551, Epsilon: 0.006042495423101193, weights: 13.897423755377531, elapsed: 167.94447000821432 minutes\n",
      "episode 4450/10000, Eps Reward: -640.1187457402381, Epsilon: 0.005973365229175067, weights: 37.634794764220715, elapsed: 168.19231912295024 minutes\n",
      "episode 4460/10000, Eps Reward: -767.05429946121, Epsilon: 0.005905025930959675, weights: 9.755345975980163, elapsed: 168.40370553731918 minutes\n",
      "episode 4470/10000, Eps Reward: -562.474074376092, Epsilon: 0.005837468480078472, weights: 7.862991502508521, elapsed: 168.77287102937697 minutes\n",
      "episode 4480/10000, Eps Reward: -777.8202276747237, Epsilon: 0.005770683931674401, weights: 33.530134711414576, elapsed: 168.97226463953655 minutes\n",
      "episode 4490/10000, Eps Reward: -213.5371537095479, Epsilon: 0.005704663443225558, weights: 0.26749560539610684, elapsed: 169.56140674352645 minutes\n",
      "episode 4500/10000, Eps Reward: -451.05251385549974, Epsilon: 0.005639398273374414, weights: 40.789509531110525, elapsed: 169.93785718282064 minutes\n",
      "episode 4510/10000, Eps Reward: -287.70112652539694, Epsilon: 0.005574879780770417, weights: 0.10042246337980032, elapsed: 170.42838603258133 minutes\n",
      "episode 4520/10000, Eps Reward: -808.4795474413675, Epsilon: 0.005511099422925859, weights: 10.18697240576148, elapsed: 170.58635339736938 minutes\n",
      "episode 4530/10000, Eps Reward: -285.304303697458, Epsilon: 0.005448048755084808, weights: 31.53774332255125, elapsed: 171.22131545941036 minutes\n",
      "episode 4540/10000, Eps Reward: 65.03618616256958, Epsilon: 0.0053857194291049935, weights: 55.24959735572338, elapsed: 171.92471975485483 minutes\n",
      "episode 4550/10000, Eps Reward: -287.98604493568575, Epsilon: 0.005324103192352488, weights: 28.43293621391058, elapsed: 172.39600174029667 minutes\n",
      "episode 4560/10000, Eps Reward: -70.74535135157564, Epsilon: 0.00526319188660902, weights: 7.613615524023771, elapsed: 173.2136422276497 minutes\n",
      "episode 4570/10000, Eps Reward: -984.5288499052638, Epsilon: 0.005202977446991794, weights: 13.793801778927445, elapsed: 173.2521740913391 minutes\n",
      "episode 4580/10000, Eps Reward: -403.3060813246851, Epsilon: 0.005143451900885678, weights: 19.529672365635633, elapsed: 173.70214308897656 minutes\n",
      "episode 4590/10000, Eps Reward: -597.3026829550992, Epsilon: 0.005084607366887597, weights: 0.014458604389801621, elapsed: 174.02068231105804 minutes\n",
      "episode 4600/10000, Eps Reward: -994.8413385930584, Epsilon: 0.005026436053763003, weights: 11.622442925348878, elapsed: 174.03888626098632 minutes\n",
      "episode 4610/10000, Eps Reward: -799.676214949207, Epsilon: 0.0049689302594142885, weights: 6.14289028570056, elapsed: 174.20629572470983 minutes\n",
      "episode 4620/10000, Eps Reward: -932.7819702651998, Epsilon: 0.0049120823698609985, weights: 8.19455839972943, elapsed: 174.33281488815945 minutes\n",
      "episode 4630/10000, Eps Reward: -783.1556645034235, Epsilon: 0.004855884858231718, weights: 19.426172621548176, elapsed: 174.52815751632053 minutes\n",
      "episode 4640/10000, Eps Reward: -418.65858419733456, Epsilon: 0.004800330283767478, weights: 0.052992448676377535, elapsed: 174.96464907725652 minutes\n",
      "episode 4650/10000, Eps Reward: -25.331179827330242, Epsilon: 0.004745411290836575, weights: 11.731272459030151, elapsed: 175.6899446407954 minutes\n",
      "episode 4660/10000, Eps Reward: -521.4042352657544, Epsilon: 0.004691120607960658, weights: 0.061050115153193474, elapsed: 176.1129939675331 minutes\n",
      "episode 4670/10000, Eps Reward: -408.78687176702545, Epsilon: 0.00463745104685196, weights: 0.4892901415005326, elapsed: 176.55945962667465 minutes\n",
      "episode 4680/10000, Eps Reward: -433.55853508095896, Epsilon: 0.004584395501461532, weights: 28.818310476839542, elapsed: 176.96949163277944 minutes\n",
      "episode 4690/10000, Eps Reward: -631.8198526574612, Epsilon: 0.004531946947038394, weights: 12.176580928266048, elapsed: 177.23711016575496 minutes\n",
      "episode 4700/10000, Eps Reward: -764.7831986114456, Epsilon: 0.00448009843919941, weights: 15.06594848446548, elapsed: 177.45657146374384 minutes\n",
      "episode 4710/10000, Eps Reward: -955.6883214947377, Epsilon: 0.004428843113009848, weights: 11.55141057446599, elapsed: 177.54429965019227 minutes\n",
      "episode 4720/10000, Eps Reward: -107.3439118315282, Epsilon: 0.00437817418207442, weights: 0.013595313299447298, elapsed: 178.14333291848502 minutes\n",
      "episode 4730/10000, Eps Reward: -633.6411115344282, Epsilon: 0.0043280849376387456, weights: 15.738555632531643, elapsed: 178.40563684304556 minutes\n",
      "episode 4740/10000, Eps Reward: -621.3702794635399, Epsilon: 0.004278568747701087, weights: 3.3675726633518934, elapsed: 178.68847755591074 minutes\n",
      "episode 4750/10000, Eps Reward: -100.78372001518233, Epsilon: 0.004229619056134248, weights: 10.758158475160599, elapsed: 179.30337678988775 minutes\n",
      "episode 4760/10000, Eps Reward: -735.8619157573991, Epsilon: 0.004181229381817516, weights: 23.634464436210692, elapsed: 179.56554136276245 minutes\n",
      "episode 4770/10000, Eps Reward: -287.3065074386199, Epsilon: 0.004133393317778545, weights: 0.08828284789342433, elapsed: 180.0388202468554 minutes\n",
      "episode 4780/10000, Eps Reward: -398.4031112961717, Epsilon: 0.004086104530345035, weights: 0.025471534812822938, elapsed: 180.50012171268463 minutes\n",
      "episode 4790/10000, Eps Reward: -994.7988071191991, Epsilon: 0.0040393567583061445, weights: 31.57066086633131, elapsed: 180.51808429956435 minutes\n",
      "episode 4800/10000, Eps Reward: -248.7878776677404, Epsilon: 0.003993143812083473, weights: 17.821464993292466, elapsed: 181.0629697918892 minutes\n",
      "episode 4810/10000, Eps Reward: -414.0637863665444, Epsilon: 0.003947459572911544, weights: 30.28250888735056, elapsed: 181.51309726635614 minutes\n",
      "episode 4820/10000, Eps Reward: -786.9151300021944, Epsilon: 0.003902297992027655, weights: 20.48690925166011, elapsed: 181.70498408476513 minutes\n",
      "episode 4830/10000, Eps Reward: -582.4004260074082, Epsilon: 0.003857653089870997, weights: 1.4354038536548615, elapsed: 182.05199448267618 minutes\n",
      "episode 4840/10000, Eps Reward: -493.40902935701143, Epsilon: 0.003813518955290944, weights: 0.04494700627401471, elapsed: 182.5299562851588 minutes\n",
      "episode 4850/10000, Eps Reward: -746.33292999982, Epsilon: 0.0037698897447643897, weights: 46.01601809775457, elapsed: 182.78524006605147 minutes\n",
      "episode 4860/10000, Eps Reward: -748.3536202399881, Epsilon: 0.0037267596816220466, weights: 21.020644074305892, elapsed: 183.03006545305252 minutes\n",
      "episode 4870/10000, Eps Reward: -615.5465592478521, Epsilon: 0.00368412305528359, weights: 25.445931263267994, elapsed: 183.3316429535548 minutes\n",
      "episode 4880/10000, Eps Reward: -639.4462891852265, Epsilon: 0.003641974220501559, weights: 35.72318026050925, elapsed: 183.59057322740554 minutes\n",
      "episode 4890/10000, Eps Reward: -830.0991276138117, Epsilon: 0.0036003075966139055, weights: 11.358318507671356, elapsed: 183.8719890832901 minutes\n",
      "episode 4900/10000, Eps Reward: -779.3149634887741, Epsilon: 0.0035591176668050904, weights: 9.071547016501427, elapsed: 184.08285208940507 minutes\n",
      "episode 4910/10000, Eps Reward: -793.5182145173682, Epsilon: 0.0035183989773756395, weights: 12.380701720714569, elapsed: 184.27289559841157 minutes\n",
      "episode 4920/10000, Eps Reward: -944.4562181323168, Epsilon: 0.003478146137020052, weights: 6.752412353642285, elapsed: 184.37183655103047 minutes\n",
      "episode 4930/10000, Eps Reward: -816.3660652404712, Epsilon: 0.0034383538161129727, weights: 6.024213757365942, elapsed: 184.51241206328075 minutes\n",
      "episode 4940/10000, Eps Reward: -448.3785404958985, Epsilon: 0.0033990167460035284, weights: 0.07146746688522398, elapsed: 184.90628985563913 minutes\n",
      "episode 4950/10000, Eps Reward: -39.427199197124445, Epsilon: 0.003360129718317742, weights: 0.15831946954131126, elapsed: 185.60372784932454 minutes\n",
      "episode 4960/10000, Eps Reward: -288.66357589065876, Epsilon: 0.003321687584268921, weights: 37.274363823235035, elapsed: 186.07598207791645 minutes\n",
      "episode 4970/10000, Eps Reward: -638.981018478937, Epsilon: 0.00328368525397594, weights: 15.3935483135283, elapsed: 186.32902136643727 minutes\n",
      "episode 4980/10000, Eps Reward: -444.24571984983396, Epsilon: 0.0032461176957893235, weights: 0.11831400444498286, elapsed: 186.72367941935858 minutes\n",
      "episode 4990/10000, Eps Reward: -946.949171613616, Epsilon: 0.003208979935625034, weights: 37.52329616993666, elapsed: 186.81687752008438 minutes\n",
      "episode 5000/10000, Eps Reward: -852.6026847485825, Epsilon: 0.003172267056305888, weights: 10.391662220470607, elapsed: 187.06186530192693 minutes\n",
      "episode 5010/10000, Eps Reward: -642.8091294610402, Epsilon: 0.0031359741969104998, weights: 16.471695923246443, elapsed: 187.31698515812556 minutes\n",
      "episode 5020/10000, Eps Reward: -606.6473818304461, Epsilon: 0.00310009655212968, weights: 10.793021969497204, elapsed: 187.62833776871364 minutes\n",
      "episode 5030/10000, Eps Reward: -449.76031041653334, Epsilon: 0.0030646293716301955, weights: 27.107803816907108, elapsed: 188.03530409733455 minutes\n",
      "episode 5040/10000, Eps Reward: 248.4191247674471, Epsilon: 0.003029567959425804, weights: 3.8957649413496256, elapsed: 188.87222438255947 minutes\n",
      "episode 5050/10000, Eps Reward: -655.4574831392054, Epsilon: 0.0029949076732554924, weights: 21.938925110735, elapsed: 189.2569915533066 minutes\n",
      "episode 5060/10000, Eps Reward: -766.6418595853745, Epsilon: 0.002960643923968822, weights: 10.941299272701144, elapsed: 189.47958745956421 minutes\n",
      "episode 5070/10000, Eps Reward: -511.5903634841684, Epsilon: 0.0029267721749183058, weights: 14.806315205991268, elapsed: 189.9375076651573 minutes\n",
      "episode 5080/10000, Eps Reward: -108.65827078236399, Epsilon: 0.002893287941358746, weights: 0.01937441562768072, elapsed: 190.53732114632925 minutes\n",
      "episode 5090/10000, Eps Reward: 616.1653477164347, Epsilon: 0.00286018678985343, weights: 0.10749261302407831, elapsed: 191.61978520949683 minutes\n",
      "episode 5100/10000, Eps Reward: 67.36599257758795, Epsilon: 0.00282746433768713, weights: 77.86665943264961, elapsed: 192.33023904959362 minutes\n",
      "episode 5110/10000, Eps Reward: -266.07965987875775, Epsilon: 0.002795116252285817, weights: 0.04954398050904274, elapsed: 192.85351769924165 minutes\n",
      "episode 5120/10000, Eps Reward: 417.4983386156249, Epsilon: 0.0027631382506430094, weights: 36.61153882741928, elapsed: 193.79280267556507 minutes\n",
      "episode 5130/10000, Eps Reward: -52.939263034196415, Epsilon: 0.0027315260987526876, weights: 22.6936038415879, elapsed: 194.4748801112175 minutes\n",
      "episode 5140/10000, Eps Reward: -427.01583304222595, Epsilon: 0.002700275611048696, weights: 0.043892090616282076, elapsed: 194.8976626912753 minutes\n",
      "episode 5150/10000, Eps Reward: -641.9429916338636, Epsilon: 0.0026693826498505584, weights: 21.062007777392864, elapsed: 195.13977704048156 minutes\n",
      "episode 5160/10000, Eps Reward: -107.4290552262161, Epsilon: 0.0026388431248156358, weights: 23.893323991447687, elapsed: 195.74217813809713 minutes\n",
      "episode 5170/10000, Eps Reward: -97.07661690133396, Epsilon: 0.002608652992397545, weights: 0.07401654116983991, elapsed: 196.35578965743383 minutes\n",
      "episode 5180/10000, Eps Reward: -695.5859950763158, Epsilon: 0.002578808255310784, weights: 36.40025877952576, elapsed: 196.67417206764222 minutes\n",
      "episode 5190/10000, Eps Reward: -458.32521615433245, Epsilon: 0.0025493049620014725, weights: 0.08864414016716182, elapsed: 197.0432649374008 minutes\n",
      "episode 5200/10000, Eps Reward: -419.0858864315527, Epsilon: 0.0025201392061241514, weights: 0.3431150233373046, elapsed: 197.47921055952708 minutes\n",
      "episode 5210/10000, Eps Reward: -445.4477037315995, Epsilon: 0.0024913071260245713, weights: 20.9345739078708, elapsed: 197.8912261605263 minutes\n",
      "episode 5220/10000, Eps Reward: -276.50307687906593, Epsilon: 0.002462804904228394, weights: 0.07857750484254211, elapsed: 198.39654029210408 minutes\n",
      "episode 5230/10000, Eps Reward: -216.0585089722124, Epsilon: 0.002434628766935741, weights: 9.475857645273209, elapsed: 198.9760517080625 minutes\n",
      "episode 5240/10000, Eps Reward: -285.96291768736535, Epsilon: 0.0024067749835215346, weights: 25.653186406940222, elapsed: 199.4516902287801 minutes\n",
      "episode 5250/10000, Eps Reward: -285.9720727029386, Epsilon: 0.002379239866041545, weights: 0.3797612455673516, elapsed: 199.93017131090164 minutes\n",
      "episode 5260/10000, Eps Reward: -218.12236523571102, Epsilon: 0.002352019768744093, weights: 11.987147202715278, elapsed: 200.52035445372263 minutes\n",
      "episode 5270/10000, Eps Reward: -173.0634598397797, Epsilon: 0.0023251110875873414, weights: 19.406286901794374, elapsed: 201.17926522493363 minutes\n",
      "episode 5280/10000, Eps Reward: -87.11354798889894, Epsilon: 0.002298510259762104, weights: 8.247948835603893, elapsed: 201.80745582977931 minutes\n",
      "episode 5290/10000, Eps Reward: -452.9976742128268, Epsilon: 0.002272213763220118, weights: 31.730968644842505, elapsed: 202.19196069637934 minutes\n",
      "episode 5300/10000, Eps Reward: -589.29305423614, Epsilon: 0.0022462181162077118, weights: 11.187218211591244, elapsed: 202.53509051799773 minutes\n",
      "episode 5310/10000, Eps Reward: -445.5568213113832, Epsilon: 0.0022205198768048056, weights: 10.654870611149818, elapsed: 202.95448050498962 minutes\n",
      "episode 5320/10000, Eps Reward: -640.5380155006928, Epsilon: 0.002195115642469192, weights: 25.593446254730225, elapsed: 203.20726153850555 minutes\n",
      "episode 5330/10000, Eps Reward: -551.3162488021715, Epsilon: 0.0021700020495860244, weights: 13.369522793684155, elapsed: 203.59048181772232 minutes\n",
      "episode 5340/10000, Eps Reward: -809.1130880022237, Epsilon: 0.002145175773022461, weights: 12.453191846609116, elapsed: 203.74693744182588 minutes\n",
      "episode 5350/10000, Eps Reward: -436.4594166136952, Epsilon: 0.002120633525687409, weights: 10.745846455916762, elapsed: 204.15879605611164 minutes\n",
      "episode 5360/10000, Eps Reward: -397.2185411052758, Epsilon: 0.002096372058096297, weights: 0.129093156196177, elapsed: 204.6286909619967 minutes\n",
      "episode 5370/10000, Eps Reward: 136.32003790351328, Epsilon: 0.0020723881579408324, weights: 0.1257990887388587, elapsed: 205.4456168492635 minutes\n",
      "episode 5380/10000, Eps Reward: 282.19456653626224, Epsilon: 0.002048678649663683, weights: 13.994759183377028, elapsed: 206.32242410977682 minutes\n",
      "episode 5390/10000, Eps Reward: 117.49719825381871, Epsilon: 0.0020252403940380164, weights: 0.27150368224829435, elapsed: 207.10603026946384 minutes\n",
      "episode 5400/10000, Eps Reward: -334.96168950285403, Epsilon: 0.002002070287751859, weights: 19.881979272700846, elapsed: 207.66262997786205 minutes\n",
      "episode 5410/10000, Eps Reward: 65.25919670811211, Epsilon: 0.001979165262997204, weights: 0.06066395528614521, elapsed: 208.3827154517174 minutes\n",
      "episode 5420/10000, Eps Reward: 266.0975402042129, Epsilon: 0.0019565222870638224, weights: 31.0143828317523, elapsed: 209.23797327677408 minutes\n",
      "episode 5430/10000, Eps Reward: -225.57802213215186, Epsilon: 0.0019341383619377206, weights: 21.224991388618946, elapsed: 209.81558196147282 minutes\n",
      "episode 5440/10000, Eps Reward: -69.97241710698833, Epsilon: 0.001912010523904193, weights: 14.425106778740883, elapsed: 210.47579478422801 minutes\n",
      "episode 5450/10000, Eps Reward: -203.59249446042816, Epsilon: 0.0018901358431554153, weights: 0.002173048153053969, elapsed: 211.079234790802 minutes\n",
      "episode 5460/10000, Eps Reward: 70.70913281818068, Epsilon: 0.0018685114234025257, weights: 7.137342374771833, elapsed: 211.79496533870696 minutes\n",
      "episode 5470/10000, Eps Reward: -382.2384405619785, Epsilon: 0.0018471344014921464, weights: 26.2761855982244, elapsed: 212.31183138688405 minutes\n",
      "episode 5480/10000, Eps Reward: -451.8998938026375, Epsilon: 0.001826001947027293, weights: 29.12986079789698, elapsed: 212.69619032939275 minutes\n",
      "episode 5490/10000, Eps Reward: -457.67776134506187, Epsilon: 0.0018051112619926165, weights: 0.15489308792166412, elapsed: 213.08017321825028 minutes\n",
      "episode 5500/10000, Eps Reward: -224.25297226938065, Epsilon: 0.001784459580383938, weights: 10.751647967845201, elapsed: 213.71785568793615 minutes\n",
      "episode 5510/10000, Eps Reward: 245.1747598311027, Epsilon: 0.0017640441678420176, weights: 16.907062470912933, elapsed: 214.6758825381597 minutes\n",
      "episode 5520/10000, Eps Reward: -287.3842378362526, Epsilon: 0.0017438623212905175, weights: 0.5713206101208925, elapsed: 215.17115819851557 minutes\n",
      "episode 5530/10000, Eps Reward: 91.56251418907732, Epsilon: 0.0017239113685781023, weights: 0.0874718043487519, elapsed: 215.97050182024637 minutes\n",
      "episode 5540/10000, Eps Reward: -569.7543555857393, Epsilon: 0.0017041886681246376, weights: 21.67729556746781, elapsed: 216.41715917984644 minutes\n",
      "episode 5550/10000, Eps Reward: -81.01546511276149, Epsilon: 0.001684691608571434, weights: 14.313535923603922, elapsed: 217.14229617118835 minutes\n",
      "episode 5560/10000, Eps Reward: 598.6172754340256, Epsilon: 0.0016654176084354953, weights: 26.05566058680415, elapsed: 218.31349453926086 minutes\n",
      "episode 5570/10000, Eps Reward: -260.4275604968734, Epsilon: 0.0016463641157677192, weights: 0.05086217517964542, elapsed: 218.85362181663513 minutes\n",
      "episode 5580/10000, Eps Reward: -635.1699839372948, Epsilon: 0.0016275286078150087, weights: 27.28800244536251, elapsed: 219.1575042963028 minutes\n",
      "episode 5590/10000, Eps Reward: -279.88476572868274, Epsilon: 0.0016089085906862532, weights: 22.89131250139326, elapsed: 219.72247204383214 minutes\n",
      "episode 5600/10000, Eps Reward: -816.306425310517, Epsilon: 0.0015905015990221262, weights: 14.421265377663076, elapsed: 219.8849798957507 minutes\n",
      "episode 5610/10000, Eps Reward: -212.06037019274373, Epsilon: 0.0015723051956686614, weights: 34.8912262795493, elapsed: 220.50577876965204 minutes\n",
      "episode 5620/10000, Eps Reward: -260.969643254964, Epsilon: 0.0015543169713545673, weights: 0.049869161332026124, elapsed: 221.0407481511434 minutes\n",
      "episode 5630/10000, Eps Reward: 69.53516724280641, Epsilon: 0.0015365345443722294, weights: 14.620343229733407, elapsed: 221.83140490849811 minutes\n",
      "episode 5640/10000, Eps Reward: 67.9619185389515, Epsilon: 0.001518955560262362, weights: 15.987579848617315, elapsed: 222.6135633746783 minutes\n",
      "episode 5650/10000, Eps Reward: 69.91577205663314, Epsilon: 0.0015015776915022704, weights: 0.20237632654607296, elapsed: 223.45554493665696 minutes\n",
      "episode 5660/10000, Eps Reward: -438.5377860484465, Epsilon: 0.0014843986371976792, weights: 3.0496591171249747, elapsed: 223.91687477429707 minutes\n",
      "episode 5670/10000, Eps Reward: -579.1032293805141, Epsilon: 0.0014674161227780837, weights: 12.23205829039216, elapsed: 224.2926515221596 minutes\n",
      "episode 5680/10000, Eps Reward: -97.49017882674491, Epsilon: 0.0014506278996955894, weights: 0.04968022438697517, elapsed: 224.96492575804393 minutes\n",
      "episode 5690/10000, Eps Reward: 68.79618611837469, Epsilon: 0.0014340317451271946, weights: 0.35378342773765326, elapsed: 225.7543870250384 minutes\n",
      "episode 5700/10000, Eps Reward: 101.46225800421851, Epsilon: 0.0014176254616804812, weights: 15.273256666958332, elapsed: 226.59458303848902 minutes\n",
      "episode 5710/10000, Eps Reward: 68.84721277672621, Epsilon: 0.0014014068771026728, weights: 0.06273535487707704, elapsed: 227.36402400334677 minutes\n",
      "episode 5720/10000, Eps Reward: 420.21997289061403, Epsilon: 0.0013853738439930186, weights: 0.04268920631147921, elapsed: 228.35188923676807 minutes\n",
      "episode 5730/10000, Eps Reward: -388.399472236922, Epsilon: 0.0013695242395184706, weights: 16.518874283879995, elapsed: 228.88581099510193 minutes\n",
      "episode 5740/10000, Eps Reward: -98.89868442371979, Epsilon: 0.0013538559651326122, weights: 6.486864148871973, elapsed: 229.5888119896253 minutes\n",
      "episode 5750/10000, Eps Reward: -286.74638465662184, Epsilon: 0.0013383669462978037, weights: 18.644821664318442, elapsed: 230.15811234315237 minutes\n",
      "episode 5760/10000, Eps Reward: -287.9200922876488, Epsilon: 0.0013230551322105043, weights: 12.243044789880514, elapsed: 230.6995467821757 minutes\n",
      "episode 5770/10000, Eps Reward: 425.20987646221437, Epsilon: 0.0013079184955297391, weights: 0.07351574371568859, elapsed: 231.70448931455613 minutes\n",
      "episode 5780/10000, Eps Reward: -111.19269126823625, Epsilon: 0.0012929550321086724, weights: 7.902926211245358, elapsed: 232.29805761178335 minutes\n",
      "episode 5790/10000, Eps Reward: -111.38734656718118, Epsilon: 0.0012781627607292491, weights: 18.034905839711428, elapsed: 232.88978507121405 minutes\n",
      "episode 5800/10000, Eps Reward: 244.94273218244825, Epsilon: 0.001263539722839877, weights: 0.15655033942312002, elapsed: 233.7182746251424 minutes\n",
      "episode 5810/10000, Eps Reward: -108.96758954148717, Epsilon: 0.0012490839822961045, weights: 0.12568910466507077, elapsed: 234.32475288311642 minutes\n",
      "episode 5820/10000, Eps Reward: 422.4258783366604, Epsilon: 0.001234793625104269, weights: 0.24602584913372993, elapsed: 235.26325350205104 minutes\n",
      "episode 5830/10000, Eps Reward: -112.6838944876085, Epsilon: 0.0012206667591680776, weights: 16.294144578278065, elapsed: 235.85014241933823 minutes\n",
      "episode 5840/10000, Eps Reward: 116.16836757959018, Epsilon: 0.001206701514038085, weights: 0.0726655893959105, elapsed: 236.63704172372817 minutes\n",
      "episode 5850/10000, Eps Reward: -108.0907224991882, Epsilon: 0.0011928960406640417, weights: 9.694611724466085, elapsed: 237.23311558961868 minutes\n",
      "episode 5860/10000, Eps Reward: -110.18686454105571, Epsilon: 0.00117924851115007, weights: 9.985334424301982, elapsed: 237.82287518580753 minutes\n",
      "episode 5870/10000, Eps Reward: -101.87872387377766, Epsilon: 0.0011657571185126451, weights: 33.7341760545969, elapsed: 238.4489637176196 minutes\n",
      "episode 5880/10000, Eps Reward: -283.70207293500465, Epsilon: 0.0011524200764413445, weights: 28.396468011662364, elapsed: 238.9356875181198 minutes\n",
      "episode 5890/10000, Eps Reward: 65.28273176846167, Epsilon: 0.0011392356190623328, weights: 0.011386162776034325, elapsed: 239.6400028427442 minutes\n",
      "episode 5900/10000, Eps Reward: -278.5334333090028, Epsilon: 0.0011262020007045531, weights: 19.93506758287549, elapsed: 240.1427015622457 minutes\n",
      "episode 5910/10000, Eps Reward: -615.3422331802946, Epsilon: 0.001113317495668596, weights: 23.867631748318672, elapsed: 240.44781934022905 minutes\n",
      "episode 5920/10000, Eps Reward: -112.35452840741087, Epsilon: 0.0011005803979982072, weights: 0.2263877959921956, elapsed: 241.03486159245173 minutes\n",
      "episode 5930/10000, Eps Reward: 106.52191593092282, Epsilon: 0.0010879890212544146, weights: 0.12764154036995023, elapsed: 241.81221958001456 minutes\n",
      "episode 5940/10000, Eps Reward: -287.3690252025373, Epsilon: 0.0010755416982922382, weights: 10.382611233741045, elapsed: 242.2972318013509 minutes\n",
      "episode 5950/10000, Eps Reward: 420.4428240703484, Epsilon: 0.001063236781039952, weights: 0.008261177696113009, elapsed: 243.24340326388676 minutes\n",
      "episode 5960/10000, Eps Reward: -284.9111496584575, Epsilon: 0.001051072640280875, weights: 22.09603814408183, elapsed: 243.73113746643065 minutes\n",
      "episode 5970/10000, Eps Reward: -110.64396616879344, Epsilon: 0.0010390476654376553, weights: 7.136576438322663, elapsed: 244.3348580042521 minutes\n",
      "episode 5980/10000, Eps Reward: -287.42091899274294, Epsilon: 0.0010271602643590243, weights: 0.015230417426209897, elapsed: 244.82177562316258 minutes\n",
      "episode 5990/10000, Eps Reward: -223.46794509174583, Epsilon: 0.0010154088631089912, weights: 0.057871497236192226, elapsed: 245.45015958944956 minutes\n",
      "episode 6000/10000, Eps Reward: 271.6659746879268, Epsilon: 0.0010037919057584454, weights: 10.926096316426992, elapsed: 246.3501749197642 minutes\n",
      "episode 6010/10000, Eps Reward: -69.25279204956094, Epsilon: 0.000992307854179149, weights: 0.020963773014955223, elapsed: 247.03665703137716 minutes\n",
      "episode 6020/10000, Eps Reward: -624.356451638155, Epsilon: 0.0009809551878400796, weights: 23.68422682583332, elapsed: 247.31949270566304 minutes\n",
      "episode 6030/10000, Eps Reward: -101.98873657828418, Epsilon: 0.0009697324036061082, weights: 0.03336913650855422, elapsed: 247.9469071785609 minutes\n",
      "episode 6040/10000, Eps Reward: -68.82866123995906, Epsilon: 0.0009586380155389788, weights: 9.970321230590343, elapsed: 248.6191420475642 minutes\n",
      "episode 6050/10000, Eps Reward: -596.5233745067119, Epsilon: 0.0009476705547005634, weights: 16.479041006416082, elapsed: 248.93881492614747 minutes\n",
      "episode 6060/10000, Eps Reward: -89.84929199538269, Epsilon: 0.0009368285689583703, weights: 0.050641597365029156, elapsed: 249.5693544824918 minutes\n",
      "episode 6070/10000, Eps Reward: 83.65263655591569, Epsilon: 0.000926110622793276, weights: 0.00030344066180987284, elapsed: 250.30950618187586 minutes\n",
      "episode 6080/10000, Eps Reward: 101.09713015664663, Epsilon: 0.0009155152971094566, weights: 0.09564228123053908, elapsed: 251.0736328125 minutes\n",
      "episode 6090/10000, Eps Reward: 84.10938433956663, Epsilon: 0.000905041189046495, weights: 0.03690883214585483, elapsed: 251.82375273307164 minutes\n",
      "episode 6100/10000, Eps Reward: -22.199269897731984, Epsilon: 0.0008946869117936369, weights: 13.338817916810513, elapsed: 252.55827416976294 minutes\n",
      "episode 6110/10000, Eps Reward: -400.26035021565355, Epsilon: 0.0008844510944061712, weights: 28.30632723821327, elapsed: 253.03179974953335 minutes\n",
      "episode 6120/10000, Eps Reward: -109.90495388757454, Epsilon: 0.0008743323816239126, weights: 9.317982155829668, elapsed: 253.6423854748408 minutes\n",
      "episode 6130/10000, Eps Reward: 241.72638175924808, Epsilon: 0.0008643294336917596, weights: 0.2882864736020565, elapsed: 254.4668159445127 minutes\n",
      "episode 6140/10000, Eps Reward: -389.1445418081054, Epsilon: 0.0008544409261823069, weights: 0.14213003171607852, elapsed: 254.95232948859532 minutes\n",
      "episode 6150/10000, Eps Reward: -85.6207128610835, Epsilon: 0.0008446655498204846, weights: 0.0042376051569590345, elapsed: 255.6026489774386 minutes\n",
      "episode 6160/10000, Eps Reward: 260.5747058159408, Epsilon: 0.0008350020103102073, weights: 0.5035994805512019, elapsed: 256.4625322143237 minutes\n",
      "episode 6170/10000, Eps Reward: 241.52499426208306, Epsilon: 0.0008254490281630029, weights: 0.328468180145137, elapsed: 257.28232309023537 minutes\n",
      "episode 6180/10000, Eps Reward: 67.67421654814346, Epsilon: 0.0008160053385286045, weights: 70.68786145746708, elapsed: 258.005535419782 minutes\n",
      "episode 6190/10000, Eps Reward: 593.3130135968488, Epsilon: 0.000806669691027479, weights: 12.571046691387892, elapsed: 259.06639054218925 minutes\n",
      "episode 6200/10000, Eps Reward: 239.11256553603175, Epsilon: 0.0007974408495852727, weights: 0.7621692409738898, elapsed: 259.8890536983808 minutes\n",
      "episode 6210/10000, Eps Reward: -42.42573675868222, Epsilon: 0.0007883175922691504, weights: 0.1064961759839207, elapsed: 260.60080262025195 minutes\n",
      "episode 6220/10000, Eps Reward: -284.2441667164668, Epsilon: 0.000779298711126006, weights: 0.36093563574831933, elapsed: 261.0858125607173 minutes\n",
      "episode 6230/10000, Eps Reward: 250.02826125681585, Epsilon: 0.0007703830120225264, weights: 0.0780713465064764, elapsed: 261.9443961024284 minutes\n",
      "episode 6240/10000, Eps Reward: 420.16437798812194, Epsilon: 0.0007615693144870838, weights: 0.0807484039105475, elapsed: 262.8925305287043 minutes\n",
      "episode 6250/10000, Eps Reward: 91.36579279102536, Epsilon: 0.0007528564515534354, weights: 7.527004342526197, elapsed: 263.6501205722491 minutes\n",
      "episode 6260/10000, Eps Reward: 69.77090494977571, Epsilon: 0.0007442432696062138, weights: 0.559466368984431, elapsed: 264.35656467676165 minutes\n",
      "episode 6270/10000, Eps Reward: 67.97587560346469, Epsilon: 0.000735728628228184, weights: 21.374224863946438, elapsed: 265.0592976808548 minutes\n",
      "episode 6280/10000, Eps Reward: -104.76849183142511, Epsilon: 0.0007273114000492485, weights: 0.049954183865338564, elapsed: 265.6536455074946 minutes\n",
      "episode 6290/10000, Eps Reward: -89.0741250153897, Epsilon: 0.0007189904705971775, weights: 0.1689226283924654, elapsed: 266.27947394053143 minutes\n",
      "episode 6300/10000, Eps Reward: -463.202222168028, Epsilon: 0.0007107647381500505, weights: 17.729740157723427, elapsed: 266.64501197338103 minutes\n",
      "episode 6310/10000, Eps Reward: -109.46069914972841, Epsilon: 0.0007026331135903836, weights: 18.098935455083847, elapsed: 267.2474001010259 minutes\n",
      "episode 6320/10000, Eps Reward: 242.7605812793694, Epsilon: 0.0006945945202609257, weights: 25.275875441730022, elapsed: 268.0802025238673 minutes\n",
      "episode 6330/10000, Eps Reward: 68.66901677438825, Epsilon: 0.0006866478938221061, weights: 0.06320329918526113, elapsed: 268.8023724754651 minutes\n",
      "episode 6340/10000, Eps Reward: -104.49154803620804, Epsilon: 0.0006787921821111112, weights: 17.63249095529318, elapsed: 269.4014057675997 minutes\n",
      "episode 6350/10000, Eps Reward: -282.9109863619102, Epsilon: 0.0006710263450025749, weights: 16.026437655091286, elapsed: 269.8845775365829 minutes\n",
      "episode 6360/10000, Eps Reward: -107.5102610234876, Epsilon: 0.0006633493542708616, weights: 0.03214261814719066, elapsed: 270.47476095755894 minutes\n",
      "episode 6370/10000, Eps Reward: 418.05490121188166, Epsilon: 0.0006557601934539253, weights: 0.12562890513800085, elapsed: 271.4179479956627 minutes\n",
      "episode 6380/10000, Eps Reward: -288.29869576850103, Epsilon: 0.0006482578577187272, weights: 5.290431885048747, elapsed: 271.8961708386739 minutes\n",
      "episode 6390/10000, Eps Reward: 117.89935045641842, Epsilon: 0.0006408413537281904, weights: 22.57972945459187, elapsed: 272.7060920834541 minutes\n",
      "episode 6400/10000, Eps Reward: 66.66475648983821, Epsilon: 0.0006335096995096798, weights: 0.010011464939452708, elapsed: 273.4384107708931 minutes\n",
      "episode 6410/10000, Eps Reward: -623.6613649712438, Epsilon: 0.0006262619243249849, weights: 33.62140556238592, elapsed: 273.7385695497195 minutes\n",
      "episode 6420/10000, Eps Reward: 112.70977619870783, Epsilon: 0.00061909706854179, weights: 6.076151143759489, elapsed: 274.52660241524376 minutes\n",
      "episode 6430/10000, Eps Reward: -458.1753691037437, Epsilon: 0.000612014183506616, weights: 20.148032683879137, elapsed: 274.9152718464533 minutes\n",
      "episode 6440/10000, Eps Reward: -284.8628843951461, Epsilon: 0.0006050123314192149, weights: 0.004893536388408393, elapsed: 275.410513707002 minutes\n",
      "episode 6450/10000, Eps Reward: -457.504500984853, Epsilon: 0.0005980905852084016, weights: 17.45105630159378, elapsed: 275.78845069805783 minutes\n",
      "episode 6460/10000, Eps Reward: -280.6430408701958, Epsilon: 0.0005912480284093057, weights: 7.853309290483594, elapsed: 276.28749997615813 minutes\n",
      "episode 6470/10000, Eps Reward: -112.44586591620427, Epsilon: 0.0005844837550420288, weights: 0.07835427997633815, elapsed: 276.88991822799045 minutes\n",
      "episode 6480/10000, Eps Reward: -271.61273851896146, Epsilon: 0.0005777968694916897, weights: 9.678649465553463, elapsed: 277.402551249663 minutes\n",
      "episode 6490/10000, Eps Reward: -101.66396156234121, Epsilon: 0.0005711864863898405, weights: 11.662986160255969, elapsed: 278.01724599202475 minutes\n",
      "episode 6500/10000, Eps Reward: 246.1711271958822, Epsilon: 0.0005646517304972417, weights: 14.42960162088275, elapsed: 278.8515291531881 minutes\n",
      "episode 6510/10000, Eps Reward: 69.341654727612, Epsilon: 0.0005581917365879764, weights: 17.396005775779486, elapsed: 279.5724012176196 minutes\n",
      "episode 6520/10000, Eps Reward: -285.3952654616393, Epsilon: 0.0005518056493348919, weights: 26.510041013360023, elapsed: 280.0493360598882 minutes\n",
      "episode 6530/10000, Eps Reward: -637.2621035209991, Epsilon: 0.0005454926231963507, weights: 11.047713346779346, elapsed: 280.3065426786741 minutes\n",
      "episode 6540/10000, Eps Reward: -621.7344025841705, Epsilon: 0.0005392518223042779, weights: 15.069049522280693, elapsed: 280.59498485326765 minutes\n",
      "episode 6550/10000, Eps Reward: -111.71604771555084, Epsilon: 0.0005330824203534893, weights: 0.11987693677656353, elapsed: 281.18100208441416 minutes\n",
      "episode 6560/10000, Eps Reward: -620.7381037884363, Epsilon: 0.0005269836004922849, weights: 2.7865057112649083, elapsed: 281.46868342955906 minutes\n",
      "episode 6570/10000, Eps Reward: -796.1250650809095, Epsilon: 0.0005209545552142957, weights: 11.015101293101907, elapsed: 281.64989114602406 minutes\n",
      "episode 6580/10000, Eps Reward: -632.1201938823622, Epsilon: 0.0005149944862515657, weights: 5.038047011941671, elapsed: 281.9237431248029 minutes\n",
      "episode 6590/10000, Eps Reward: -109.9936794427557, Epsilon: 0.0005091026044688594, weights: 5.257085893303156, elapsed: 282.5199081937472 minutes\n",
      "episode 6600/10000, Eps Reward: -234.37270081262858, Epsilon: 0.0005032781297591765, weights: 23.640090085566044, elapsed: 283.0960401892662 minutes\n",
      "episode 6610/10000, Eps Reward: 604.7313152659857, Epsilon: 0.0004975202909404631, weights: 0.06795933924149722, elapsed: 284.172770357132 minutes\n",
      "episode 6620/10000, Eps Reward: 248.7338450882482, Epsilon: 0.0004918283256535046, weights: 32.44704721868038, elapsed: 285.0011528968811 minutes\n",
      "episode 6630/10000, Eps Reward: 422.41475755853844, Epsilon: 0.0004862014802609867, weights: 0.09251030650921166, elapsed: 285.94642516374586 minutes\n",
      "episode 6640/10000, Eps Reward: 76.76078380108852, Epsilon: 0.0004806390097477097, weights: 0.05450517265126109, elapsed: 286.68445041179655 minutes\n",
      "episode 6650/10000, Eps Reward: -737.2488626226875, Epsilon: 0.0004751401776219474, weights: 24.19905372709036, elapsed: 286.94193927844367 minutes\n",
      "episode 6660/10000, Eps Reward: -813.5184726780371, Epsilon: 0.000469704255817932, weights: 23.21627649664879, elapsed: 287.0879841287931 minutes\n",
      "episode 6670/10000, Eps Reward: -281.9538977985112, Epsilon: 0.0004643305245994555, weights: 0.145113960839808, elapsed: 287.57247228622435 minutes\n",
      "episode 6680/10000, Eps Reward: -782.9155301241364, Epsilon: 0.0004590182724645742, weights: 14.530288886278868, elapsed: 287.7609525084496 minutes\n",
      "episode 6690/10000, Eps Reward: -601.6284444164573, Epsilon: 0.0004537667960514028, weights: 0.06954968895297498, elapsed: 288.0882005016009 minutes\n",
      "episode 6700/10000, Eps Reward: -807.5128812363265, Epsilon: 0.0004485754000449874, weights: 41.35014605522156, elapsed: 288.2475209593773 minutes\n",
      "episode 6710/10000, Eps Reward: -62.09505284123137, Epsilon: 0.00044344339708524263, weights: 14.19707034341991, elapsed: 288.92047162850696 minutes\n",
      "episode 6720/10000, Eps Reward: -109.87065629328015, Epsilon: 0.0004383701076759426, weights: 3.8241335516795516, elapsed: 289.51534046729404 minutes\n",
      "episode 6730/10000, Eps Reward: -104.33273384909928, Epsilon: 0.0004333548600947534, weights: 10.68716280348599, elapsed: 290.1148371974627 minutes\n",
      "episode 6740/10000, Eps Reward: -286.21496597262046, Epsilon: 0.0004283969903042945, weights: 28.060251004993916, elapsed: 290.5900137225787 minutes\n",
      "episode 6750/10000, Eps Reward: 69.72407210752107, Epsilon: 0.00042349584186421747, weights: 0.11850853054784238, elapsed: 291.3050736427307 minutes\n",
      "episode 6760/10000, Eps Reward: -104.40742407769066, Epsilon: 0.0004186507658442912, weights: 15.640642996877432, elapsed: 291.9070332725843 minutes\n",
      "episode 6770/10000, Eps Reward: -387.0208474537551, Epsilon: 0.0004138611207384809, weights: 19.5028503164649, elapsed: 292.3904800335566 minutes\n",
      "episode 6780/10000, Eps Reward: -455.91591749956785, Epsilon: 0.0004091262723800106, weights: 0.037704385118559, elapsed: 292.7718612114588 minutes\n",
      "episode 6790/10000, Eps Reward: -107.25293751656258, Epsilon: 0.00040444559385739655, weights: 0.2746571513125673, elapsed: 293.3849524577459 minutes\n",
      "episode 6800/10000, Eps Reward: 75.01223810544262, Epsilon: 0.00039981846543144244, weights: 0.2725641499273479, elapsed: 294.1232625047366 minutes\n",
      "episode 6810/10000, Eps Reward: 602.9937833513383, Epsilon: 0.0003952442744531832, weights: 0.031656079343520105, elapsed: 295.19297100305556 minutes\n",
      "episode 6820/10000, Eps Reward: -109.18917011434988, Epsilon: 0.00039072241528276844, weights: 0.019262493879068643, elapsed: 295.7925250530243 minutes\n",
      "episode 6830/10000, Eps Reward: 69.28911774063533, Epsilon: 0.00038625228920927286, weights: 16.29759745299816, elapsed: 296.50272066195805 minutes\n",
      "episode 6840/10000, Eps Reward: -284.05707400602967, Epsilon: 0.0003818333043714254, weights: 29.868545688688755, elapsed: 296.99177095492684 minutes\n",
      "episode 6850/10000, Eps Reward: -284.29846657197294, Epsilon: 0.000377464875679244, weights: 6.605157008394599, elapsed: 297.47694095770515 minutes\n",
      "episode 6860/10000, Eps Reward: 246.87566963647637, Epsilon: 0.0003731464247365679, weights: 0.04110236844280735, elapsed: 298.3185467282931 minutes\n",
      "episode 6870/10000, Eps Reward: 67.14631188906843, Epsilon: 0.0003688773797644758, weights: 0.40912494948133826, elapsed: 299.03472972710927 minutes\n",
      "episode 6880/10000, Eps Reward: -286.1816190162157, Epsilon: 0.00036465717552558013, weights: 19.947887793183327, elapsed: 299.5210408210754 minutes\n",
      "episode 6890/10000, Eps Reward: 427.25804252754403, Epsilon: 0.00036048525324918737, weights: 0.02326878532767296, elapsed: 300.4735860904058 minutes\n",
      "episode 6900/10000, Eps Reward: -383.02954566851014, Epsilon: 0.0003563610605573152, weights: 0.008774255868047476, elapsed: 300.9679666320483 minutes\n",
      "episode 6910/10000, Eps Reward: -441.2798143795455, Epsilon: 0.00035228405139155504, weights: 0.07951142354431795, elapsed: 301.3826852520307 minutes\n",
      "episode 6920/10000, Eps Reward: 119.12168085699034, Epsilon: 0.0003482536859407724, weights: 0.03995301015675068, elapsed: 302.172019414107 minutes\n",
      "episode 6930/10000, Eps Reward: -278.92954417584247, Epsilon: 0.00034426943056963335, weights: 8.08728645183146, elapsed: 302.6689860224724 minutes\n",
      "episode 6940/10000, Eps Reward: -104.14700560145889, Epsilon: 0.00034033075774794985, weights: 23.41806571185589, elapsed: 303.2896285613378 minutes\n",
      "episode 6950/10000, Eps Reward: 245.74590026297838, Epsilon: 0.00033643714598083227, weights: 0.030571403331123292, elapsed: 304.11775079965594 minutes\n",
      "episode 6960/10000, Eps Reward: -107.50094573388947, Epsilon: 0.00033258807973964174, weights: 0.1529304627329111, elapsed: 304.7178258339564 minutes\n",
      "episode 6970/10000, Eps Reward: -103.78584869737088, Epsilon: 0.00032878304939373213, weights: 2.444735014811158, elapsed: 305.3244092663129 minutes\n",
      "episode 6980/10000, Eps Reward: -111.81199925260871, Epsilon: 0.0003250215511429736, weights: 0.029253711341880262, elapsed: 305.91249170700706 minutes\n",
      "episode 6990/10000, Eps Reward: 425.48435685709035, Epsilon: 0.0003213030869510466, weights: 0.026120432652533054, elapsed: 306.86454710165657 minutes\n",
      "episode 7000/10000, Eps Reward: 246.69164814590013, Epsilon: 0.00031762716447950105, weights: 1.6122360536828637, elapsed: 307.6970797260602 minutes\n",
      "episode 7010/10000, Eps Reward: 246.0114752718329, Epsilon: 0.00031399329702256815, weights: 11.857194822281599, elapsed: 308.5475901524226 minutes\n",
      "episode 7020/10000, Eps Reward: 424.54884450015254, Epsilon: 0.00031040100344271906, weights: 0.018557204864919186, elapsed: 309.49572412172955 minutes\n",
      "episode 7030/10000, Eps Reward: 424.531906935975, Epsilon: 0.0003068498081069605, weights: 25.70746324211359, elapsed: 310.4467407464981 minutes\n",
      "episode 7040/10000, Eps Reward: -109.44133902825654, Epsilon: 0.00030333924082385924, weights: 0.005329497158527374, elapsed: 311.0364037473997 minutes\n",
      "episode 7050/10000, Eps Reward: 249.10829972263872, Epsilon: 0.0002998688367812865, weights: 0.1550749046728015, elapsed: 311.8679120659828 minutes\n",
      "episode 7060/10000, Eps Reward: -107.02334374477478, Epsilon: 0.000296438136484876, weights: 2.4036083430983126, elapsed: 312.46666631301247 minutes\n",
      "episode 7070/10000, Eps Reward: 243.42091976358392, Epsilon: 0.0002930466856971845, weights: 4.675351832062006, elapsed: 313.30650479396184 minutes\n",
      "episode 7080/10000, Eps Reward: 68.0389823867398, Epsilon: 0.0002896940353775492, weights: 0.19193772599101067, elapsed: 314.02164483070374 minutes\n",
      "episode 7090/10000, Eps Reward: 598.5697752196464, Epsilon: 0.00028637974162263333, weights: 0.1848603714024648, elapsed: 315.08953391313554 minutes\n",
      "episode 7100/10000, Eps Reward: 253.36703297145488, Epsilon: 0.00028310336560765146, weights: 27.787545247003436, elapsed: 315.93719474871955 minutes\n",
      "episode 7110/10000, Eps Reward: 428.9578118638942, Epsilon: 0.00027986447352826754, weights: 0.07384899188764393, elapsed: 316.91342653830844 minutes\n",
      "episode 7120/10000, Eps Reward: 73.72625122005041, Epsilon: 0.0002766626365431577, weights: 0.21622486354317516, elapsed: 317.6397631406784 minutes\n",
      "episode 7130/10000, Eps Reward: 63.27914535873079, Epsilon: 0.0002734974307172299, weights: 0.12169972900301218, elapsed: 318.3700208266576 minutes\n",
      "episode 7140/10000, Eps Reward: -424.78548745529423, Epsilon: 0.00027036843696549357, weights: 11.949190014973283, elapsed: 318.80450813770295 minutes\n",
      "episode 7150/10000, Eps Reward: 423.7720271242616, Epsilon: 0.00026727524099757084, weights: 0.01265699916984886, elapsed: 319.7566418965658 minutes\n",
      "episode 7160/10000, Eps Reward: 71.30830307226897, Epsilon: 0.0002642174332628434, weights: 0.05863155052065849, elapsed: 320.4828879356384 minutes\n",
      "episode 7170/10000, Eps Reward: 422.177342825904, Epsilon: 0.00026119460889622616, weights: 0.06071162247098982, elapsed: 321.4304081042608 minutes\n",
      "episode 7180/10000, Eps Reward: -101.469989619879, Epsilon: 0.00025820636766456175, weights: 29.192058254033327, elapsed: 322.0506159265836 minutes\n",
      "episode 7190/10000, Eps Reward: 94.58821299730928, Epsilon: 0.00025525231391362803, weights: 31.69201472401619, elapsed: 322.82198782364526 minutes\n",
      "episode 7200/10000, Eps Reward: 259.8181959011213, Epsilon: 0.0002523320565157523, weights: 0.07010658306535333, elapsed: 323.6990510980288 minutes\n",
      "episode 7210/10000, Eps Reward: 85.51532189365, Epsilon: 0.0002494452088180242, weights: 0.09296155907213688, elapsed: 324.4581875403722 minutes\n",
      "episode 7220/10000, Eps Reward: 70.60176487415188, Epsilon: 0.0002465913885911016, weights: 0.14074215525761247, elapsed: 325.18191785415013 minutes\n",
      "episode 7230/10000, Eps Reward: 313.26880284917587, Epsilon: 0.0002437702179786022, weights: 0.1629607230424881, elapsed: 326.1312151034673 minutes\n",
      "episode 7240/10000, Eps Reward: -108.4649446749739, Epsilon: 0.00024098132344707335, weights: 14.04061195999384, elapsed: 326.74078442255654 minutes\n",
      "episode 7250/10000, Eps Reward: 248.68145809505276, Epsilon: 0.00023822433573653557, weights: 0.04683796758763492, elapsed: 327.59079275925956 minutes\n",
      "episode 7260/10000, Eps Reward: 106.94556970245696, Epsilon: 0.00023549888981159065, weights: 0.07296059955842793, elapsed: 328.39106057484946 minutes\n",
      "episode 7270/10000, Eps Reward: -455.48081010832993, Epsilon: 0.00023280462481308986, weights: 27.860950745642185, elapsed: 328.7812918265661 minutes\n",
      "episode 7280/10000, Eps Reward: 72.97937743061905, Epsilon: 0.0002301411840103547, weights: 9.592935057356954, elapsed: 329.5115511894226 minutes\n",
      "episode 7290/10000, Eps Reward: -559.4661635229512, Epsilon: 0.0002275082147539446, weights: 2.344959338195622, elapsed: 329.8970989624659 minutes\n",
      "episode 7300/10000, Eps Reward: -460.46157301624305, Epsilon: 0.00022490536842896465, weights: 6.0625990787521005, elapsed: 330.28472526073455 minutes\n",
      "episode 7310/10000, Eps Reward: -638.5377392675109, Epsilon: 0.00022233230040890784, weights: 3.185250430367887, elapsed: 330.54870030085243 minutes\n",
      "episode 7320/10000, Eps Reward: -109.91610518759865, Epsilon: 0.00021978867001002517, weights: 1.6664397781714797, elapsed: 331.1474720637004 minutes\n",
      "episode 7330/10000, Eps Reward: 66.86109566456298, Epsilon: 0.00021727414044621783, weights: 13.83576538041234, elapsed: 331.86808174848557 minutes\n",
      "episode 7340/10000, Eps Reward: 253.46840541563793, Epsilon: 0.00021478837878444556, weights: 28.14865423925221, elapsed: 332.72154062191646 minutes\n",
      "episode 7350/10000, Eps Reward: 81.56790407073035, Epsilon: 0.00021233105590064494, weights: 0.0042422456899657845, elapsed: 333.47720668713254 minutes\n",
      "episode 7360/10000, Eps Reward: -275.57864576943024, Epsilon: 0.0002099018464361523, weights: 0.0076015175436623394, elapsed: 333.9841190457344 minutes\n",
      "episode 7370/10000, Eps Reward: 68.78538208945346, Epsilon: 0.000207500428754625, weights: 0.050144404638558626, elapsed: 334.7072768052419 minutes\n",
      "episode 7380/10000, Eps Reward: 68.01007502781574, Epsilon: 0.0002051264848994554, weights: 0.012339892477029935, elapsed: 335.42502089738844 minutes\n",
      "episode 7390/10000, Eps Reward: -109.71237365283623, Epsilon: 0.0002027797005516724, weights: 29.31879496574402, elapsed: 336.03551079034804 minutes\n",
      "episode 7400/10000, Eps Reward: -110.7956655926848, Epsilon: 0.00020045976498832456, weights: 0.1512402961961925, elapsed: 336.63896769682566 minutes\n",
      "episode 7410/10000, Eps Reward: -638.9822826719167, Epsilon: 0.00019816637104133896, weights: 19.232293599285185, elapsed: 336.9008584499359 minutes\n",
      "episode 7420/10000, Eps Reward: -462.496719213175, Epsilon: 0.00019589921505685107, weights: 0.0527970299590379, elapsed: 337.2772963921229 minutes\n",
      "episode 7430/10000, Eps Reward: -461.84056431287655, Epsilon: 0.00019365799685500001, weights: 0.03158513727248646, elapsed: 337.6503823796908 minutes\n",
      "episode 7440/10000, Eps Reward: -462.38771630750796, Epsilon: 0.0001914424196901835, weights: 0.07884331233799458, elapsed: 338.0268007159233 minutes\n",
      "episode 7450/10000, Eps Reward: -465.208989291856, Epsilon: 0.00018925219021176767, weights: 12.207708163186908, elapsed: 338.40142948230107 minutes\n",
      "episode 7460/10000, Eps Reward: -461.6166668142575, Epsilon: 0.00018708701842524623, weights: 11.427529249340296, elapsed: 338.7789046128591 minutes\n",
      "episode 7470/10000, Eps Reward: -286.30881169249386, Epsilon: 0.0001849466176538444, weights: 0.10641661589033902, elapsed: 339.26912224292755 minutes\n",
      "episode 7480/10000, Eps Reward: -464.2595724085766, Epsilon: 0.0001828307045005615, weights: 6.468240851536393, elapsed: 339.64730248451235 minutes\n",
      "episode 7490/10000, Eps Reward: -103.15764407836727, Epsilon: 0.00018073899881064845, weights: 0.60659359395504, elapsed: 340.26671849886577 minutes\n",
      "episode 7500/10000, Eps Reward: -107.95589846534021, Epsilon: 0.00017867122363451408, weights: 0.0009810228366404772, elapsed: 340.88761909008025 minutes\n",
      "episode 7510/10000, Eps Reward: 113.92362080738039, Epsilon: 0.000176627105191056, weights: 0.04455462051555514, elapsed: 341.70428770780563 minutes\n",
      "episode 7520/10000, Eps Reward: 66.89082085541347, Epsilon: 0.00017460637283141093, weights: 45.06961537897587, elapsed: 342.42281248569486 minutes\n",
      "episode 7530/10000, Eps Reward: 595.7293005358481, Epsilon: 0.00017260875900311978, weights: 0.013213441707193851, elapsed: 343.50527806679406 minutes\n",
      "episode 7540/10000, Eps Reward: -261.31656525997425, Epsilon: 0.0001706339992147028, weights: 19.287368558347225, elapsed: 344.0444180925687 minutes\n",
      "episode 7550/10000, Eps Reward: -112.47352859067738, Epsilon: 0.00016868183200063997, weights: 0.06686720671132207, elapsed: 344.6504997094472 minutes\n",
      "episode 7560/10000, Eps Reward: -83.740497668502, Epsilon: 0.00016675199888675174, weights: 2.7021476021036506, elapsed: 345.30782769918443 minutes\n",
      "episode 7570/10000, Eps Reward: -113.79807223244761, Epsilon: 0.00016484424435597646, weights: 39.06777963042259, elapsed: 345.9123281200727 minutes\n",
      "episode 7580/10000, Eps Reward: 255.21201348579785, Epsilon: 0.00016295831581453858, weights: 0.04008970072027296, elapsed: 346.76674340168637 minutes\n",
      "episode 7590/10000, Eps Reward: -241.51352317962383, Epsilon: 0.00016109396355850456, weights: 0.19834525091573596, elapsed: 347.33115541934967 minutes\n",
      "episode 7600/10000, Eps Reward: -637.0706201421937, Epsilon: 0.00015925094074072116, weights: 9.076185749843717, elapsed: 347.59044181903204 minutes\n",
      "episode 7610/10000, Eps Reward: -258.85812979819286, Epsilon: 0.0001574290033381316, weights: 0.004869562108069658, elapsed: 348.14418152570727 minutes\n",
      "episode 7620/10000, Eps Reward: 59.58330054272117, Epsilon: 0.00015562791011946659, weights: 17.11258128285408, elapsed: 348.87155371904373 minutes\n",
      "episode 7630/10000, Eps Reward: -107.96589125996577, Epsilon: 0.00015384742261330398, weights: 17.686342913657427, elapsed: 349.483325723807 minutes\n",
      "episode 7640/10000, Eps Reward: -460.93632753645625, Epsilon: 0.0001520873050764943, weights: 0.001964405513717793, elapsed: 349.86446566581725 minutes\n",
      "episode 7650/10000, Eps Reward: -113.39193741527177, Epsilon: 0.00015034732446294772, weights: 2.122599521651864, elapsed: 350.47313080628714 minutes\n",
      "episode 7660/10000, Eps Reward: -81.06629288524238, Epsilon: 0.00014862725039277764, weights: 12.954139467328787, elapsed: 351.126817047596 minutes\n",
      "episode 7670/10000, Eps Reward: -60.201550141252845, Epsilon: 0.0001469268551217976, weights: 0.01703619206091389, elapsed: 351.812019542853 minutes\n",
      "episode 7680/10000, Eps Reward: -92.51795609336003, Epsilon: 0.00014524591351136725, weights: 7.717245986685157, elapsed: 352.45062232017517 minutes\n",
      "episode 7690/10000, Eps Reward: 245.27942048801614, Epsilon: 0.00014358420299858296, weights: 20.27826762199402, elapsed: 353.2993109027545 minutes\n",
      "episode 7700/10000, Eps Reward: 66.90631481868806, Epsilon: 0.0001419415035668098, weights: 0.005988507939036936, elapsed: 354.0256463646889 minutes\n",
      "episode 7710/10000, Eps Reward: -108.30411089419235, Epsilon: 0.0001403175977165504, weights: 0.03089366853237152, elapsed: 354.64578421115874 minutes\n",
      "episode 7720/10000, Eps Reward: -290.0215816700178, Epsilon: 0.0001387122704366474, weights: 10.870393543504179, elapsed: 355.1273749391238 minutes\n",
      "episode 7730/10000, Eps Reward: -634.4868498214527, Epsilon: 0.00013712530917581495, weights: 9.472239209339023, elapsed: 355.3978445450465 minutes\n",
      "episode 7740/10000, Eps Reward: 238.37384754802002, Epsilon: 0.00013555650381449636, weights: 0.020089517114683986, elapsed: 356.23484686613085 minutes\n",
      "episode 7750/10000, Eps Reward: 67.5860763414576, Epsilon: 0.00013400564663704334, weights: 0.007005955092608929, elapsed: 356.9697550058365 minutes\n",
      "episode 7760/10000, Eps Reward: 68.24839271595287, Epsilon: 0.00013247253230421355, weights: 19.724592251703143, elapsed: 357.69530901908877 minutes\n",
      "episode 7770/10000, Eps Reward: -287.70344762108255, Epsilon: 0.00013095695782598327, weights: 47.5904760658741, elapsed: 358.1884822567304 minutes\n",
      "episode 7780/10000, Eps Reward: -111.80816097432485, Epsilon: 0.00012945872253467057, weights: 8.754858408123255, elapsed: 358.8064271092415 minutes\n",
      "episode 7790/10000, Eps Reward: 591.7191624531613, Epsilon: 0.00012797762805836612, weights: 0.015315447701141238, elapsed: 359.88108124335605 minutes\n",
      "episode 7800/10000, Eps Reward: 238.74601895851976, Epsilon: 0.000126513478294668, weights: 15.30107576213777, elapsed: 360.7175168553988 minutes\n",
      "episode 7810/10000, Eps Reward: -108.11859361942697, Epsilon: 0.00012506607938471724, weights: 8.315327345393598, elapsed: 361.3470255176226 minutes\n",
      "episode 7820/10000, Eps Reward: 242.28272984621285, Epsilon: 0.00012363523968752995, weights: 8.93140038009733, elapsed: 362.1970175345739 minutes\n",
      "episode 7830/10000, Eps Reward: 426.9146825801516, Epsilon: 0.00012222076975462344, weights: 12.50732123106718, elapsed: 363.1737894932429 minutes\n",
      "episode 7840/10000, Eps Reward: 107.90450280432273, Epsilon: 0.00012082248230493249, weights: 0.023314564488828182, elapsed: 363.9701506694158 minutes\n",
      "episode 7850/10000, Eps Reward: 104.94879422677562, Epsilon: 0.0001194401922000127, weights: 0.0020632639789255336, elapsed: 364.7495943427086 minutes\n",
      "episode 7860/10000, Eps Reward: 85.0457557480874, Epsilon: 0.00011807371641952747, weights: 0.009889226057566702, elapsed: 365.50820753574374 minutes\n",
      "episode 7870/10000, Eps Reward: -586.8769851750192, Epsilon: 0.00011672287403701538, weights: 0.004144829581491649, elapsed: 365.8523619572322 minutes\n",
      "episode 7880/10000, Eps Reward: -634.4676528158482, Epsilon: 0.00011538748619593492, weights: 11.72115738876164, elapsed: 366.1158314506213 minutes\n",
      "episode 7890/10000, Eps Reward: -802.733918494447, Epsilon: 0.00011406737608598315, weights: 23.51716459169984, elapsed: 366.2769772211711 minutes\n",
      "episode 7900/10000, Eps Reward: 235.4142606607039, Epsilon: 0.0001127623689196854, weights: 25.34024851769209, elapsed: 367.1142102599144 minutes\n",
      "episode 7910/10000, Eps Reward: -85.01339996781367, Epsilon: 0.00011147229190925277, weights: 0.02266767295077443, elapsed: 367.7814520835876 minutes\n",
      "episode 7920/10000, Eps Reward: -289.44694430738133, Epsilon: 0.00011019697424370436, weights: 0.007558967772638425, elapsed: 368.27971796194714 minutes\n",
      "episode 7930/10000, Eps Reward: -252.4718795046659, Epsilon: 0.00010893624706625126, weights: 9.398453668225557, elapsed: 368.83579977750776 minutes\n",
      "episode 7940/10000, Eps Reward: -618.1467365600387, Epsilon: 0.00010768994345193933, weights: 14.694396482780576, elapsed: 369.12944823503494 minutes\n",
      "episode 7950/10000, Eps Reward: -902.6655112365831, Epsilon: 0.00010645789838554765, weights: 27.71331299468875, elapsed: 369.2971022605896 minutes\n",
      "episode 7960/10000, Eps Reward: -462.1682928506713, Epsilon: 0.00010523994873973997, weights: 25.52783227711916, elapsed: 369.6782573620478 minutes\n",
      "episode 7970/10000, Eps Reward: -273.7426986778993, Epsilon: 0.00010403593325346592, weights: 0.0029161378188291565, elapsed: 370.2012591203054 minutes\n",
      "episode 7980/10000, Eps Reward: -289.56423692008525, Epsilon: 0.00010284569251060966, weights: 33.67239812761545, elapsed: 370.6868975281715 minutes\n",
      "episode 7990/10000, Eps Reward: -247.69795427456316, Epsilon: 0.00010166906891888237, weights: 0.045194948790594935, elapsed: 371.24102967182796 minutes\n",
      "episode 8000/10000, Eps Reward: -459.49085527471925, Epsilon: 0.00010050590668895651, weights: 11.693113189190626, elapsed: 371.62110847234726 minutes\n",
      "episode 8010/10000, Eps Reward: -452.2956110409699, Epsilon: 0.0001, weights: 0.022627213038504124, elapsed: 372.03062090476357 minutes\n",
      "episode 8020/10000, Eps Reward: 597.5492399267603, Epsilon: 0.0001, weights: 0.010543156182393432, elapsed: 373.10657929182054 minutes\n",
      "episode 8030/10000, Eps Reward: 240.53787696808158, Epsilon: 0.0001, weights: 0.04131551255704835, elapsed: 373.95995656649274 minutes\n",
      "episode 8040/10000, Eps Reward: 242.02205851234376, Epsilon: 0.0001, weights: 0.003620698262238875, elapsed: 374.80421606302264 minutes\n",
      "episode 8050/10000, Eps Reward: 67.67648621362409, Epsilon: 0.0001, weights: 0.019750792300328612, elapsed: 375.52378199100497 minutes\n",
      "episode 8060/10000, Eps Reward: 71.8300953351742, Epsilon: 0.0001, weights: 0.03793352114735171, elapsed: 376.2514177640279 minutes\n",
      "episode 8070/10000, Eps Reward: 80.66897864155766, Epsilon: 0.0001, weights: 0.05154925584793091, elapsed: 377.0102843085925 minutes\n",
      "episode 8080/10000, Eps Reward: -39.950496211408485, Epsilon: 0.0001, weights: 14.308019459247589, elapsed: 377.7298592766126 minutes\n",
      "episode 8090/10000, Eps Reward: 240.10589904310103, Epsilon: 0.0001, weights: 0.11119186144787818, elapsed: 378.57673071225486 minutes\n",
      "episode 8100/10000, Eps Reward: -273.5941359220895, Epsilon: 0.0001, weights: 16.83624266833067, elapsed: 379.09009478886924 minutes\n",
      "episode 8110/10000, Eps Reward: 238.66235525609721, Epsilon: 0.0001, weights: 0.03730682248715311, elapsed: 379.936440316836 minutes\n",
      "episode 8120/10000, Eps Reward: 240.64262111756474, Epsilon: 0.0001, weights: 0.004297694016713649, elapsed: 380.768729364872 minutes\n",
      "episode 8130/10000, Eps Reward: 241.65369618123833, Epsilon: 0.0001, weights: 15.802991120144725, elapsed: 381.60179838339485 minutes\n",
      "episode 8140/10000, Eps Reward: 71.62655237060441, Epsilon: 0.0001, weights: 22.370830707252026, elapsed: 382.3283918341001 minutes\n",
      "episode 8150/10000, Eps Reward: -93.96187609420944, Epsilon: 0.0001, weights: 0.00877092729206197, elapsed: 382.9594478329023 minutes\n",
      "episode 8160/10000, Eps Reward: 129.18288801537537, Epsilon: 0.0001, weights: 0.2516361291054636, elapsed: 383.78861153125763 minutes\n",
      "episode 8170/10000, Eps Reward: 420.5516906404843, Epsilon: 0.0001, weights: 25.953418165445328, elapsed: 384.7510648926099 minutes\n",
      "episode 8180/10000, Eps Reward: -104.46242023496863, Epsilon: 0.0001, weights: 17.22961315046996, elapsed: 385.3633746425311 minutes\n",
      "episode 8190/10000, Eps Reward: 65.83901297535124, Epsilon: 0.0001, weights: 12.590831622481346, elapsed: 386.09153134028116 minutes\n",
      "episode 8200/10000, Eps Reward: -113.6627996312335, Epsilon: 0.0001, weights: 0.022660142742097378, elapsed: 386.694651500384 minutes\n",
      "episode 8210/10000, Eps Reward: 75.23175307965488, Epsilon: 0.0001, weights: 17.923743756487966, elapsed: 387.44735718568165 minutes\n",
      "episode 8220/10000, Eps Reward: 78.24840543721285, Epsilon: 0.0001, weights: 0.033401154389139265, elapsed: 388.20335235198337 minutes\n",
      "episode 8230/10000, Eps Reward: 67.56693375448415, Epsilon: 0.0001, weights: 0.3485613325610757, elapsed: 388.93333205779396 minutes\n",
      "episode 8240/10000, Eps Reward: -286.7836929155686, Epsilon: 0.0001, weights: 21.707444116473198, elapsed: 389.42615143060686 minutes\n",
      "episode 8250/10000, Eps Reward: 239.5695970911137, Epsilon: 0.0001, weights: 0.08060601446777582, elapsed: 390.2600025375684 minutes\n",
      "episode 8260/10000, Eps Reward: 250.60331444908692, Epsilon: 0.0001, weights: 11.80422642827034, elapsed: 391.1618518392245 minutes\n",
      "episode 8270/10000, Eps Reward: 66.28296173774329, Epsilon: 0.0001, weights: 19.86540325731039, elapsed: 391.9029703934987 minutes\n",
      "episode 8280/10000, Eps Reward: 239.32711530292696, Epsilon: 0.0001, weights: 0.01846646354533732, elapsed: 392.73708273967105 minutes\n",
      "episode 8290/10000, Eps Reward: 239.98082643137087, Epsilon: 0.0001, weights: 0.0199273539474234, elapsed: 393.57874032258985 minutes\n",
      "episode 8300/10000, Eps Reward: -86.55495510684987, Epsilon: 0.0001, weights: 0.23160711582750082, elapsed: 394.2306217988332 minutes\n",
      "episode 8310/10000, Eps Reward: -44.47616175121955, Epsilon: 0.0001, weights: 15.901138484477997, elapsed: 394.9431590557098 minutes\n",
      "episode 8320/10000, Eps Reward: -118.02014120419412, Epsilon: 0.0001, weights: 0.010494790127268061, elapsed: 395.53800972700117 minutes\n",
      "episode 8330/10000, Eps Reward: 76.56053223820234, Epsilon: 0.0001, weights: 0.0010759504802990705, elapsed: 396.2771018624306 minutes\n",
      "episode 8340/10000, Eps Reward: -115.73164583751546, Epsilon: 0.0001, weights: 17.074759809300303, elapsed: 396.8748342315356 minutes\n",
      "episode 8350/10000, Eps Reward: 420.6939581540413, Epsilon: 0.0001, weights: 0.008211027539800853, elapsed: 397.8284331361453 minutes\n",
      "episode 8360/10000, Eps Reward: 66.05705334661151, Epsilon: 0.0001, weights: 0.006516970111988485, elapsed: 398.55346707900367 minutes\n",
      "episode 8370/10000, Eps Reward: -459.8258261448497, Epsilon: 0.0001, weights: 0.03173044044524431, elapsed: 398.92521661520004 minutes\n",
      "episode 8380/10000, Eps Reward: -272.44788755442016, Epsilon: 0.0001, weights: 6.0748953483998775, elapsed: 399.445108862718 minutes\n",
      "episode 8390/10000, Eps Reward: -458.83091182677254, Epsilon: 0.0001, weights: 27.111554503440857, elapsed: 399.83093384901684 minutes\n",
      "episode 8400/10000, Eps Reward: 251.30713164483353, Epsilon: 0.0001, weights: 0.050619964487850666, elapsed: 400.69012960592903 minutes\n",
      "episode 8410/10000, Eps Reward: 241.29616538492118, Epsilon: 0.0001, weights: 6.644359481520951, elapsed: 401.5381875038147 minutes\n",
      "episode 8420/10000, Eps Reward: -104.03697080521329, Epsilon: 0.0001, weights: 11.589788943529129, elapsed: 402.15674666961036 minutes\n",
      "episode 8430/10000, Eps Reward: -389.39975367693535, Epsilon: 0.0001, weights: 18.287949111312628, elapsed: 402.6535136461258 minutes\n",
      "episode 8440/10000, Eps Reward: -640.1942313445802, Epsilon: 0.0001, weights: 3.757225001230836, elapsed: 402.9096363345782 minutes\n",
      "episode 8450/10000, Eps Reward: 60.806070364661174, Epsilon: 0.0001, weights: 0.0030214923026505858, elapsed: 403.6364885409673 minutes\n",
      "episode 8460/10000, Eps Reward: 72.5928550415554, Epsilon: 0.0001, weights: 2.7618814082816243, elapsed: 404.3820870359739 minutes\n",
      "episode 8470/10000, Eps Reward: -114.51146641267557, Epsilon: 0.0001, weights: 5.813953962177038, elapsed: 404.98398462931317 minutes\n",
      "episode 8480/10000, Eps Reward: 62.86461697020345, Epsilon: 0.0001, weights: 10.564049012959003, elapsed: 405.70639764467876 minutes\n",
      "episode 8490/10000, Eps Reward: -98.10197810394808, Epsilon: 0.0001, weights: 18.898416753858328, elapsed: 406.3418788790703 minutes\n",
      "episode 8500/10000, Eps Reward: 82.96642167890327, Epsilon: 0.0001, weights: 2.7719272756949067, elapsed: 407.0950244029363 minutes\n",
      "episode 8510/10000, Eps Reward: 73.56880160936377, Epsilon: 0.0001, weights: 11.052479508332908, elapsed: 407.83567763964334 minutes\n",
      "episode 8520/10000, Eps Reward: 67.79919514166926, Epsilon: 0.0001, weights: 0.12350192619487643, elapsed: 408.57451154788333 minutes\n",
      "episode 8530/10000, Eps Reward: 256.58845954009496, Epsilon: 0.0001, weights: 0.008036734943743795, elapsed: 409.43126978079476 minutes\n",
      "episode 8540/10000, Eps Reward: 595.7487178818885, Epsilon: 0.0001, weights: 0.06663410877808928, elapsed: 410.4963129440943 minutes\n",
      "episode 8550/10000, Eps Reward: 253.80003785748346, Epsilon: 0.0001, weights: 0.00811719625198748, elapsed: 411.3535880168279 minutes\n",
      "episode 8560/10000, Eps Reward: 131.75187595132257, Epsilon: 0.0001, weights: 0.04474244173616171, elapsed: 412.1796265125275 minutes\n",
      "episode 8570/10000, Eps Reward: 241.39485094958468, Epsilon: 0.0001, weights: 0.061119030229747295, elapsed: 413.01347875992457 minutes\n",
      "episode 8580/10000, Eps Reward: 254.91602519500503, Epsilon: 0.0001, weights: 0.17465527821332216, elapsed: 413.88585780064267 minutes\n",
      "episode 8590/10000, Eps Reward: 416.37741448340955, Epsilon: 0.0001, weights: 21.75287889689207, elapsed: 414.8454441666603 minutes\n",
      "episode 8600/10000, Eps Reward: 420.03003666653495, Epsilon: 0.0001, weights: 0.042172086890786886, elapsed: 415.79280005693437 minutes\n",
      "episode 8610/10000, Eps Reward: 244.13070587073418, Epsilon: 0.0001, weights: 13.774511029943824, elapsed: 416.6362820108732 minutes\n",
      "episode 8620/10000, Eps Reward: 591.1048811996769, Epsilon: 0.0001, weights: 0.24993370287120342, elapsed: 417.7057290593783 minutes\n",
      "episode 8630/10000, Eps Reward: 593.9634522823078, Epsilon: 0.0001, weights: 18.626838602125645, elapsed: 418.7889926314354 minutes\n",
      "episode 8640/10000, Eps Reward: 594.6325764496751, Epsilon: 0.0001, weights: 15.803505931049585, elapsed: 419.8587008277575 minutes\n",
      "episode 8650/10000, Eps Reward: 596.3801393669249, Epsilon: 0.0001, weights: 0.13164486829191446, elapsed: 420.9174741665522 minutes\n",
      "episode 8660/10000, Eps Reward: 436.9732292295492, Epsilon: 0.0001, weights: 12.071309363469481, elapsed: 421.90283499161404 minutes\n",
      "episode 8670/10000, Eps Reward: 244.80999730239495, Epsilon: 0.0001, weights: 0.013906446867622435, elapsed: 422.7442909280459 minutes\n",
      "episode 8680/10000, Eps Reward: 67.3738464329222, Epsilon: 0.0001, weights: 0.014996541984146461, elapsed: 423.4843660593033 minutes\n",
      "episode 8690/10000, Eps Reward: 313.3790384888275, Epsilon: 0.0001, weights: 0.15216827322728932, elapsed: 424.4288556933403 minutes\n",
      "episode 8700/10000, Eps Reward: -112.06742734153981, Epsilon: 0.0001, weights: 31.338066704571247, elapsed: 425.03283781607945 minutes\n",
      "episode 8710/10000, Eps Reward: -288.2832356489836, Epsilon: 0.0001, weights: 0.01002163568045944, elapsed: 425.52878087361654 minutes\n",
      "episode 8720/10000, Eps Reward: 423.8782344398793, Epsilon: 0.0001, weights: 0.001419964391971007, elapsed: 426.4914939483007 minutes\n",
      "episode 8730/10000, Eps Reward: 236.46577135209517, Epsilon: 0.0001, weights: 7.487158834934235, elapsed: 427.3227414647738 minutes\n",
      "episode 8740/10000, Eps Reward: -287.07212863790267, Epsilon: 0.0001, weights: 14.782540464773774, elapsed: 427.8163411974907 minutes\n",
      "episode 8750/10000, Eps Reward: -116.54876480511834, Epsilon: 0.0001, weights: 0.0778890869114548, elapsed: 428.4210881114006 minutes\n",
      "episode 8760/10000, Eps Reward: -451.74043959890344, Epsilon: 0.0001, weights: 13.419543957337737, elapsed: 428.8274754166603 minutes\n",
      "episode 8770/10000, Eps Reward: -642.7407518220023, Epsilon: 0.0001, weights: 4.654713049530983, elapsed: 429.0786940177282 minutes\n",
      "episode 8780/10000, Eps Reward: 236.66123479122766, Epsilon: 0.0001, weights: 0.00952736078761518, elapsed: 429.9047334829966 minutes\n",
      "episode 8790/10000, Eps Reward: -286.432597491157, Epsilon: 0.0001, weights: 0.10510477120988071, elapsed: 430.3991318821907 minutes\n",
      "episode 8800/10000, Eps Reward: -270.4622553925598, Epsilon: 0.0001, weights: 0.000764645890740212, elapsed: 430.9234175125758 minutes\n",
      "episode 8810/10000, Eps Reward: -115.48429139661611, Epsilon: 0.0001, weights: 0.0020893439650535583, elapsed: 431.53130071957906 minutes\n",
      "episode 8820/10000, Eps Reward: 61.26779560632033, Epsilon: 0.0001, weights: 0.001191615592688322, elapsed: 432.24904783169427 minutes\n",
      "episode 8830/10000, Eps Reward: -98.43502816720445, Epsilon: 0.0001, weights: 0.011919725919142365, elapsed: 432.879317009449 minutes\n",
      "episode 8840/10000, Eps Reward: -638.573745108067, Epsilon: 0.0001, weights: 0.00567841250449419, elapsed: 433.1430323243141 minutes\n",
      "episode 8850/10000, Eps Reward: -467.7164985148993, Epsilon: 0.0001, weights: 15.516710944473743, elapsed: 433.52000409762064 minutes\n",
      "episode 8860/10000, Eps Reward: -115.61416042277278, Epsilon: 0.0001, weights: 0.046995543874800205, elapsed: 434.1143386681875 minutes\n",
      "episode 8870/10000, Eps Reward: -117.41942121058055, Epsilon: 0.0001, weights: 0.26743057754356414, elapsed: 434.7230168938637 minutes\n",
      "episode 8880/10000, Eps Reward: -115.98709219247613, Epsilon: 0.0001, weights: 0.0006028039497323334, elapsed: 435.33244657913843 minutes\n",
      "episode 8890/10000, Eps Reward: -644.2873551801747, Epsilon: 0.0001, weights: 18.318094961345196, elapsed: 435.58210186163586 minutes\n",
      "episode 8900/10000, Eps Reward: 238.30347124464242, Epsilon: 0.0001, weights: 0.12525174650363624, elapsed: 436.4190764307976 minutes\n",
      "episode 8910/10000, Eps Reward: 418.8634225714569, Epsilon: 0.0001, weights: 5.107951081357896, elapsed: 437.3768453876177 minutes\n",
      "episode 8920/10000, Eps Reward: 235.89154291106897, Epsilon: 0.0001, weights: 0.003534641000442207, elapsed: 438.2080906232198 minutes\n",
      "episode 8930/10000, Eps Reward: 239.61530725843258, Epsilon: 0.0001, weights: 0.07296766713261604, elapsed: 439.04922941923144 minutes\n",
      "episode 8940/10000, Eps Reward: 268.32268779204503, Epsilon: 0.0001, weights: 0.00043819927304866724, elapsed: 439.929677871863 minutes\n",
      "episode 8950/10000, Eps Reward: -638.5555745441388, Epsilon: 0.0001, weights: 14.36426778882742, elapsed: 440.19158700704577 minutes\n",
      "episode 8960/10000, Eps Reward: 62.422138129670586, Epsilon: 0.0001, weights: 0.1882495661266148, elapsed: 440.9067459742228 minutes\n",
      "episode 8970/10000, Eps Reward: 71.45658702062798, Epsilon: 0.0001, weights: 0.0009767508163349703, elapsed: 441.6281804243724 minutes\n",
      "episode 8980/10000, Eps Reward: 63.100572591046635, Epsilon: 0.0001, weights: 5.668635504320264, elapsed: 442.3474039157232 minutes\n",
      "episode 8990/10000, Eps Reward: 63.23090502420759, Epsilon: 0.0001, weights: 0.08307227259501815, elapsed: 443.06410525639853 minutes\n",
      "episode 9000/10000, Eps Reward: -287.136327909397, Epsilon: 0.0001, weights: 0.005668669211445376, elapsed: 443.57228503227236 minutes\n",
      "episode 9010/10000, Eps Reward: -276.5739012126661, Epsilon: 0.0001, weights: 16.974513567984104, elapsed: 444.0908609231313 minutes\n",
      "episode 9020/10000, Eps Reward: -468.528704820901, Epsilon: 0.0001, weights: 17.44870149344206, elapsed: 444.454556397597 minutes\n",
      "episode 9030/10000, Eps Reward: -469.1340259407908, Epsilon: 0.0001, weights: 4.641168361529708, elapsed: 444.82135971387225 minutes\n",
      "episode 9040/10000, Eps Reward: -114.0877931007797, Epsilon: 0.0001, weights: 9.95720917545259, elapsed: 445.42742251555126 minutes\n",
      "episode 9050/10000, Eps Reward: 240.29003968201613, Epsilon: 0.0001, weights: 0.10483676008880138, elapsed: 446.263354575634 minutes\n",
      "episode 9060/10000, Eps Reward: -105.32549798024188, Epsilon: 0.0001, weights: 9.958745984360576, elapsed: 446.8772281050682 minutes\n",
      "episode 9070/10000, Eps Reward: -464.2792763838978, Epsilon: 0.0001, weights: 7.31352243386209, elapsed: 447.25162018934884 minutes\n",
      "episode 9080/10000, Eps Reward: -283.3719521098175, Epsilon: 0.0001, weights: 0.021684586885385215, elapsed: 447.7470041235288 minutes\n",
      "episode 9090/10000, Eps Reward: -290.93192633826004, Epsilon: 0.0001, weights: 21.93139985948801, elapsed: 448.2379897872607 minutes\n",
      "episode 9100/10000, Eps Reward: -241.87508700779912, Epsilon: 0.0001, weights: 11.78401025570929, elapsed: 448.8099428812663 minutes\n",
      "episode 9110/10000, Eps Reward: -623.017653368761, Epsilon: 0.0001, weights: 9.608363911509514, elapsed: 449.10151022672653 minutes\n",
      "episode 9120/10000, Eps Reward: -821.4261656296819, Epsilon: 0.0001, weights: 0.002143318866728805, elapsed: 449.2337756673495 minutes\n",
      "episode 9130/10000, Eps Reward: 250.96460553113644, Epsilon: 0.0001, weights: 0.004533502433332615, elapsed: 450.08610875606536 minutes\n",
      "episode 9140/10000, Eps Reward: 62.14247487771354, Epsilon: 0.0001, weights: 26.298849765211344, elapsed: 450.80175175666807 minutes\n",
      "episode 9150/10000, Eps Reward: -92.33508503453454, Epsilon: 0.0001, weights: 0.0715067470446229, elapsed: 451.4395751476288 minutes\n",
      "episode 9160/10000, Eps Reward: 63.09833896366125, Epsilon: 0.0001, weights: 16.899354830384254, elapsed: 452.15979609886807 minutes\n",
      "episode 9170/10000, Eps Reward: -819.6349516446842, Epsilon: 0.0001, weights: 4.432553615421057, elapsed: 452.29399145444233 minutes\n",
      "episode 9180/10000, Eps Reward: -619.2250041089533, Epsilon: 0.0001, weights: 15.058161069639027, elapsed: 452.5829730550448 minutes\n",
      "episode 9190/10000, Eps Reward: -637.0485348685863, Epsilon: 0.0001, weights: 4.897665933705866, elapsed: 452.8482477585475 minutes\n",
      "episode 9200/10000, Eps Reward: -292.35358291727806, Epsilon: 0.0001, weights: 5.38017398212105, elapsed: 453.3389866113663 minutes\n",
      "episode 9210/10000, Eps Reward: -821.4894369737536, Epsilon: 0.0001, weights: 13.560313558205962, elapsed: 453.47201314767204 minutes\n",
      "episode 9220/10000, Eps Reward: -467.7237829294334, Epsilon: 0.0001, weights: 27.786223579198122, elapsed: 453.84558387200036 minutes\n",
      "episode 9230/10000, Eps Reward: -93.81650593498573, Epsilon: 0.0001, weights: 0.07269260031171143, elapsed: 454.4802842140198 minutes\n",
      "episode 9240/10000, Eps Reward: -293.51191295109203, Epsilon: 0.0001, weights: 5.430975626222789, elapsed: 454.96321150064466 minutes\n",
      "episode 9250/10000, Eps Reward: 410.98063614192654, Epsilon: 0.0001, weights: 0.012717794510535896, elapsed: 455.9090225696564 minutes\n",
      "episode 9260/10000, Eps Reward: 434.71563157029186, Epsilon: 0.0001, weights: 0.029201410710811615, elapsed: 456.8951437791189 minutes\n",
      "episode 9270/10000, Eps Reward: 80.8756814108479, Epsilon: 0.0001, weights: 9.946175325661898, elapsed: 457.6469919244448 minutes\n",
      "episode 9280/10000, Eps Reward: -280.70612341346657, Epsilon: 0.0001, weights: 0.005237490666331723, elapsed: 458.1572715918223 minutes\n",
      "episode 9290/10000, Eps Reward: -292.29484482545854, Epsilon: 0.0001, weights: 11.625106528401375, elapsed: 458.64875388940175 minutes\n",
      "episode 9300/10000, Eps Reward: -41.49300739085278, Epsilon: 0.0001, weights: 36.687879763543606, elapsed: 459.36341015497845 minutes\n",
      "episode 9310/10000, Eps Reward: -279.22972534402095, Epsilon: 0.0001, weights: 0.02206390118226409, elapsed: 459.8785827080409 minutes\n",
      "episode 9320/10000, Eps Reward: -291.92855137302683, Epsilon: 0.0001, weights: 0.00914356202702038, elapsed: 460.35914990107216 minutes\n",
      "episode 9330/10000, Eps Reward: -116.60585837652256, Epsilon: 0.0001, weights: 13.988144915550947, elapsed: 460.9493336876233 minutes\n",
      "episode 9340/10000, Eps Reward: -111.83377119892548, Epsilon: 0.0001, weights: 0.010918987565673888, elapsed: 461.5540928641955 minutes\n",
      "episode 9350/10000, Eps Reward: 76.79965334227265, Epsilon: 0.0001, weights: 0.02655653841793537, elapsed: 462.2957846840223 minutes\n",
      "episode 9360/10000, Eps Reward: 83.02485515378852, Epsilon: 0.0001, weights: 0.062422629445791245, elapsed: 463.04761516253154 minutes\n",
      "episode 9370/10000, Eps Reward: -779.9713651235646, Epsilon: 0.0001, weights: 18.85155225172639, elapsed: 463.25719719727834 minutes\n",
      "episode 9380/10000, Eps Reward: -115.62903375754301, Epsilon: 0.0001, weights: 1.470235865097493, elapsed: 463.8624600927035 minutes\n",
      "episode 9390/10000, Eps Reward: 63.71961462989702, Epsilon: 0.0001, weights: 6.891472345218062, elapsed: 464.59061870574953 minutes\n",
      "episode 9400/10000, Eps Reward: -464.44019460569706, Epsilon: 0.0001, weights: 23.354679834097624, elapsed: 464.96420633395513 minutes\n",
      "episode 9410/10000, Eps Reward: -642.9956911180929, Epsilon: 0.0001, weights: 12.269257420673966, elapsed: 465.22089140812557 minutes\n",
      "episode 9420/10000, Eps Reward: -291.07052144582156, Epsilon: 0.0001, weights: 10.268903141841292, elapsed: 465.7121476531029 minutes\n",
      "episode 9430/10000, Eps Reward: -771.5169438503857, Epsilon: 0.0001, weights: 8.535316608846188, elapsed: 465.9277038296064 minutes\n",
      "episode 9440/10000, Eps Reward: -290.2094067830614, Epsilon: 0.0001, weights: 0.00036590383388102055, elapsed: 466.4184373696645 minutes\n",
      "episode 9450/10000, Eps Reward: -107.47076304032763, Epsilon: 0.0001, weights: 8.330833973363042, elapsed: 467.0338545203209 minutes\n",
      "episode 9460/10000, Eps Reward: -641.8113139243065, Epsilon: 0.0001, weights: 0.00014975079102441669, elapsed: 467.2861304839452 minutes\n",
      "episode 9470/10000, Eps Reward: -289.1761005226575, Epsilon: 0.0001, weights: 7.907130651175976, elapsed: 467.76982288360597 minutes\n",
      "episode 9480/10000, Eps Reward: -592.0643250117766, Epsilon: 0.0001, weights: 5.945314762648195, elapsed: 468.1106111288071 minutes\n",
      "episode 9490/10000, Eps Reward: -109.88867497557666, Epsilon: 0.0001, weights: 0.01669221743941307, elapsed: 468.7390913645426 minutes\n",
      "episode 9500/10000, Eps Reward: -567.521228671734, Epsilon: 0.0001, weights: 0.016050973907113075, elapsed: 469.12304503122965 minutes\n",
      "episode 9510/10000, Eps Reward: -463.89829518468696, Epsilon: 0.0001, weights: 10.545330891385674, elapsed: 469.50546918710074 minutes\n",
      "episode 9520/10000, Eps Reward: -456.88067908003825, Epsilon: 0.0001, weights: 0.016946561518125236, elapsed: 469.8905117511749 minutes\n",
      "episode 9530/10000, Eps Reward: -453.9832729687102, Epsilon: 0.0001, weights: 0.056428007083013654, elapsed: 470.28464984496435 minutes\n",
      "episode 9540/10000, Eps Reward: 240.6246017133147, Epsilon: 0.0001, weights: 5.931675327941775, elapsed: 471.1177178382874 minutes\n",
      "episode 9550/10000, Eps Reward: -285.40659955371245, Epsilon: 0.0001, weights: 0.014931870624423027, elapsed: 471.61236051718396 minutes\n",
      "episode 9560/10000, Eps Reward: -464.59586996712403, Epsilon: 0.0001, weights: 5.945318888872862, elapsed: 471.9838514010111 minutes\n",
      "episode 9570/10000, Eps Reward: -453.7894212551913, Epsilon: 0.0001, weights: 7.271294260863215, elapsed: 472.38217017650607 minutes\n",
      "episode 9580/10000, Eps Reward: -104.2005454781727, Epsilon: 0.0001, weights: 10.201753966510296, elapsed: 472.99812445640566 minutes\n",
      "episode 9590/10000, Eps Reward: -619.7156184931084, Epsilon: 0.0001, weights: 13.15550612192601, elapsed: 473.29438129266106 minutes\n",
      "episode 9600/10000, Eps Reward: -640.0097294021039, Epsilon: 0.0001, weights: 0.0011005119886249304, elapsed: 473.5638208150864 minutes\n",
      "episode 9610/10000, Eps Reward: -418.7615385133037, Epsilon: 0.0001, weights: 1.5582599444314837, elapsed: 474.01863112449644 minutes\n",
      "episode 9620/10000, Eps Reward: -100.11347361336344, Epsilon: 0.0001, weights: 4.969625491648912, elapsed: 474.6601372559865 minutes\n",
      "episode 9630/10000, Eps Reward: -414.9469347197639, Epsilon: 0.0001, weights: 15.118917495012283, elapsed: 475.11489148537316 minutes\n",
      "episode 9640/10000, Eps Reward: -287.6957059405246, Epsilon: 0.0001, weights: 10.374478161334991, elapsed: 475.6038079102834 minutes\n",
      "episode 9650/10000, Eps Reward: 77.86082927541266, Epsilon: 0.0001, weights: 0.17670142464339733, elapsed: 476.34888447523116 minutes\n",
      "episode 9660/10000, Eps Reward: -628.1491699484529, Epsilon: 0.0001, weights: 0.01618800518917851, elapsed: 476.6316037098567 minutes\n",
      "episode 9670/10000, Eps Reward: -95.99629010013709, Epsilon: 0.0001, weights: 0.0014339520130306482, elapsed: 477.26812477111815 minutes\n",
      "episode 9680/10000, Eps Reward: -459.9387371895289, Epsilon: 0.0001, weights: 12.52247971855104, elapsed: 477.65538407961526 minutes\n",
      "episode 9690/10000, Eps Reward: -288.9569847369427, Epsilon: 0.0001, weights: 0.040005886694416404, elapsed: 478.14492762883503 minutes\n",
      "episode 9700/10000, Eps Reward: -799.8305157743273, Epsilon: 0.0001, weights: 12.664789164438844, elapsed: 478.3258598804474 minutes\n",
      "episode 9710/10000, Eps Reward: -463.72925149941665, Epsilon: 0.0001, weights: 9.643712179735303, elapsed: 478.71188066800437 minutes\n",
      "episode 9720/10000, Eps Reward: -639.3635651894394, Epsilon: 0.0001, weights: 11.23234649002552, elapsed: 478.9713207880656 minutes\n",
      "episode 9730/10000, Eps Reward: -645.086845851509, Epsilon: 0.0001, weights: 13.443886688910425, elapsed: 479.2172414859136 minutes\n",
      "episode 9740/10000, Eps Reward: -292.6368377479621, Epsilon: 0.0001, weights: 0.0038964666600804776, elapsed: 479.69488051335014 minutes\n",
      "episode 9750/10000, Eps Reward: -464.5681341992446, Epsilon: 0.0001, weights: 24.401465002447367, elapsed: 480.06905261278155 minutes\n",
      "episode 9760/10000, Eps Reward: -457.8201251873569, Epsilon: 0.0001, weights: 3.3868185710161924, elapsed: 480.4598240931829 minutes\n",
      "episode 9770/10000, Eps Reward: -815.4866098782761, Epsilon: 0.0001, weights: 27.382281731814146, elapsed: 480.59883879820507 minutes\n",
      "episode 9780/10000, Eps Reward: -288.5192315484488, Epsilon: 0.0001, weights: 4.871640942059457, elapsed: 481.087998243173 minutes\n",
      "episode 9790/10000, Eps Reward: -458.649761109109, Epsilon: 0.0001, weights: 14.7860704138875, elapsed: 481.47512367963793 minutes\n",
      "episode 9800/10000, Eps Reward: -644.8839192834506, Epsilon: 0.0001, weights: 2.298899231478572, elapsed: 481.7221753279368 minutes\n",
      "episode 9810/10000, Eps Reward: -113.39779736441247, Epsilon: 0.0001, weights: 0.35482729598879814, elapsed: 482.33135946591693 minutes\n",
      "episode 9820/10000, Eps Reward: -273.177551345865, Epsilon: 0.0001, weights: 0.00152399146463722, elapsed: 482.84760883251823 minutes\n",
      "episode 9830/10000, Eps Reward: -641.2151888489072, Epsilon: 0.0001, weights: 8.669901309534907, elapsed: 483.10559617678325 minutes\n",
      "episode 9840/10000, Eps Reward: 114.64964573091575, Epsilon: 0.0001, weights: 0.02058295882306993, elapsed: 483.915234208107 minutes\n",
      "episode 9850/10000, Eps Reward: -457.7041699198038, Epsilon: 0.0001, weights: 0.024239099642727524, elapsed: 484.29948122898736 minutes\n",
      "episode 9860/10000, Eps Reward: -292.76731047936096, Epsilon: 0.0001, weights: 0.003893149900250137, elapsed: 484.78215020100276 minutes\n",
      "episode 9870/10000, Eps Reward: -289.08286996364427, Epsilon: 0.0001, weights: 0.033560509560629725, elapsed: 485.27028065919876 minutes\n",
      "episode 9880/10000, Eps Reward: -467.47061024139185, Epsilon: 0.0001, weights: 8.608934253454208, elapsed: 485.633960489432 minutes\n",
      "episode 9890/10000, Eps Reward: -642.0860392002975, Epsilon: 0.0001, weights: 7.143400347791612, elapsed: 485.88699923356376 minutes\n",
      "episode 9900/10000, Eps Reward: -639.7715820776314, Epsilon: 0.0001, weights: 21.001957796514034, elapsed: 486.1442231575648 minutes\n",
      "episode 9910/10000, Eps Reward: 75.2521564610806, Epsilon: 0.0001, weights: 0.011981629184447229, elapsed: 486.8986567457517 minutes\n",
      "episode 9920/10000, Eps Reward: -282.36871788242377, Epsilon: 0.0001, weights: 5.514554066583514, elapsed: 487.40537241697314 minutes\n",
      "episode 9930/10000, Eps Reward: -266.2746528979703, Epsilon: 0.0001, weights: 23.4150032363832, elapsed: 487.9347989320755 minutes\n",
      "episode 9940/10000, Eps Reward: 238.2016307671372, Epsilon: 0.0001, weights: 0.016241717181401327, elapsed: 488.7894744038582 minutes\n",
      "episode 9950/10000, Eps Reward: 413.4533690929775, Epsilon: 0.0001, weights: 9.896729126572609, elapsed: 489.7399512410164 minutes\n",
      "episode 9960/10000, Eps Reward: 238.14350896350612, Epsilon: 0.0001, weights: 0.00010952576121781021, elapsed: 490.5704183737437 minutes\n",
      "episode 9970/10000, Eps Reward: -288.3427087967957, Epsilon: 0.0001, weights: 11.467977220192552, elapsed: 491.0603734056155 minutes\n",
      "episode 9980/10000, Eps Reward: -255.65996216947238, Epsilon: 0.0001, weights: 9.267571749165654, elapsed: 491.60159663359326 minutes\n",
      "episode 9990/10000, Eps Reward: -114.59593763822109, Epsilon: 0.0001, weights: 0.0039278002514038235, elapsed: 492.21312501033145 minutes\n",
      "episode 10000/10000, Eps Reward: -456.12229204824007, Epsilon: 0.0001, weights: 13.239713802933693, elapsed: 492.6028381427129 minutes\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "ALPHA = 0.001  # Learning rate\n",
    "GAMMA = 0.99  # Discount factor\n",
    "EPSILON = 1.0  # Exploration rate\n",
    "EPSILON_DECAY = 0.99885  # Decay rate for epsilon\n",
    "MIN_EPSILON = 0.0001  # Minimum epsilon value\n",
    "BATCH_SIZE = 1  # Batch size for experience replay\n",
    "MEMORY_SIZE = 5000  # Size of experience replay memory\n",
    "NUM_EPS = 10000  # Number of training episodes\n",
    "TARG_RATE = 20 # Update rate of target_net\n",
    "EPS_LEN = 200\n",
    "TAU_POLYAK = 0.005\n",
    "\n",
    "#total_reward = 0\n",
    "\n",
    "#reward_acul = np.empty(0)\n",
    "\n",
    "\n",
    "#state = quad_env.init_state()\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "reward_acul = np.empty(0)\n",
    "\n",
    "# Train the agent\n",
    "for i in range(1,NUM_EPS+1):\n",
    "    done = False\n",
    "\n",
    "\n",
    "    state = quad_env.init_state()\n",
    "    action = select_action(state, EPSILON)\n",
    "    total_reward = 0\n",
    "\n",
    "    \n",
    "    for j in range(1,EPS_LEN+1):\n",
    "        if done :\n",
    "            break\n",
    "\n",
    "        uav_loc = np.reshape(state[:-quad_env.user_number], (2,-1))\n",
    "        user_profile = state[-quad_env.user_number:]\n",
    "    \n",
    "        scheduling = schedule(user_profile,quad_env.user_loc,uav_loc,quad_env.transmit_pow,quad_env.noise,quad_env.height)\n",
    "    \n",
    "        next_state = quad_env.next_state(action,uav_loc,user_profile,scheduling)\n",
    "\n",
    "        next_action = select_action(next_state, EPSILON)\n",
    "    \n",
    "        uav_loc = np.reshape(next_state[:-quad_env.user_number], (2,-1))\n",
    "    \n",
    "        \n",
    "        reward , done = quad_env.my_reward(uav_loc, scheduling, user_profile)\n",
    "    \n",
    "    \n",
    "        ######################################################################################################################### Training\n",
    "        prev_model = copy.deepcopy(q_net)\n",
    "\n",
    "        next_state1 = torch.tensor(next_state, dtype=torch.float32, device = DEVICE).unsqueeze(0)\n",
    "        state1 = torch.tensor(state, dtype=torch.float32, device = DEVICE).unsqueeze(0)\n",
    "        # Compute target Q-value using SARSA update\n",
    "        with torch.no_grad():\n",
    "            target_q = reward + (GAMMA * q_net(next_state1)[0, next_action] if not done else 0)\n",
    "\n",
    "        # Compute loss and update network\n",
    "        q_values = q_net(state1)\n",
    "        predicted_q = q_values[0, action]\n",
    "\n",
    "        target_q1 = torch.FloatTensor(np.array([target_q])[np.newaxis,:]).to(DEVICE)\n",
    "        \n",
    "        #print(predicted_q.unsqueeze(0).unsqueeze(0),target_q1)\n",
    "\n",
    "        \n",
    "        \n",
    "        loss = loss_fn(predicted_q.unsqueeze(0).unsqueeze(0),(target_q1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        ####################################################\n",
    "    \n",
    "        \n",
    "\n",
    "        state = next_state\n",
    "\n",
    "        action = next_action\n",
    "        \n",
    "        total_reward += reward\n",
    "\n",
    "\n",
    "    reward_acul = np.append(reward_acul,total_reward)\n",
    "\n",
    "    # Decay epsilon to reduce exploration\n",
    "    EPSILON = max(MIN_EPSILON, EPSILON * EPSILON_DECAY)\n",
    "\n",
    "    # Print progress every episodes\n",
    "\n",
    "    if i%10 == 0:\n",
    "        toc = time.time()\n",
    "        print(f\"episode {i}/{NUM_EPS}, Eps Reward: {np.mean(reward_acul[-10:])}, Epsilon: {EPSILON}, weights: {weight_change(q_net,prev_model)}, elapsed: {(toc-tic)/60} minutes\")\n",
    "\n",
    "    if i%100 == 0:\n",
    "    \n",
    "        check_point = {\n",
    "        'epoch':i,\n",
    "        'model_state':q_net.state_dict(),\n",
    "        'optimizer_state': optimizer.state_dict()\n",
    "        }\n",
    "    \n",
    "        torch.save(check_point,\"checkpoint_eps.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a109b184-4631-452f-9230-84bcf8860750",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"rewards.npy\",reward_acul)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
