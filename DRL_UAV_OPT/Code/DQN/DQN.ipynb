{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9b048e30-68a8-4f87-8066-9883c314d489",
   "metadata": {
    "id": "L2xjHP_d3owr"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# all array inputs must be of the type np.array\n",
    "\n",
    "class my_env:\n",
    "    #def __init__(self, uav_number, user_number, size, user_loc, noise, height, transmit_pow, safe_dist): # initializes environment\n",
    "    def __init__(self):\n",
    "        self.uav_number = 2\n",
    "        self.user_number = 5\n",
    "        self.size = np.array([10,10])\n",
    "        self.user_loc = np.array([[-5,-5,5,5,0],[-5,5,-5,5,0]])\n",
    "        self.safe_dist = 5\n",
    "        self.noise = 0.01\n",
    "        self.height = 7\n",
    "        self.transmit_pow = 1\n",
    "        self.observation_space = 2*self.uav_number + self.user_number\n",
    "\n",
    "        ### Parameters\n",
    "        self.actions = 5**(self.uav_number) # 0: 10 units Left , 1: 10 units up , 2: 10 units right, 3: 10 units down, 4: stay\n",
    "        self.user_profile = 1*np.ones(self.user_number)\n",
    "        ###\n",
    "\n",
    "    def my_reward(self, uav_loc, scheduling, user_prof): # calculate reward\n",
    "        num_agents = np.shape(uav_loc)[1]\n",
    "        num_user = np.shape(self.user_loc)[1]\n",
    "\n",
    "        pref = np.zeros((num_agents,num_user))\n",
    "        pref_rate = np.zeros((num_agents,num_user))\n",
    "        for i in range(np.shape(pref)[0]):\n",
    "            for j in range(np.shape(pref)[1]):\n",
    "                interf = 0\n",
    "                for k in range(np.shape(pref)[0]):\n",
    "                    if k != i:\n",
    "                        interf = interf + self.transmit_pow/(self.height**2 + np.linalg.norm(uav_loc[:,k]-self.user_loc[:,j]))\n",
    "                pref[i,j] = user_prof[j]*np.log2(1 + self.transmit_pow/(self.height**2 + np.linalg.norm(uav_loc[:,i]-self.user_loc[:,j]))/(interf+self.noise))\n",
    "                #pref[i,j] = np.log2(1 + self.transmit_pow/(self.height**2 + np.linalg.norm(uav_loc[:,i]-self.user_loc[:,j]))/(interf+self.noise))\n",
    "\n",
    "\n",
    "        ####### ---- penalty\n",
    "        penalty = 0\n",
    "\n",
    "        for i in range(np.shape(pref)[0]):\n",
    "            for k in range(np.shape(pref)[0]):\n",
    "                if k != i:\n",
    "                    penalty = penalty + (np.linalg.norm(uav_loc[:,k]-uav_loc[:,i]) < self.safe_dist)\n",
    "\n",
    "        # reward = np.sum(np.multiply(scheduling,pref)) - np.log2(1 + self.transmit_pow/(self.height**2)/self.noise )*penalty/2\n",
    "        reward = np.sum(np.multiply(scheduling,pref)) - 1000*penalty/2\n",
    "\n",
    "        if penalty != 0:\n",
    "            done =  True\n",
    "        else: \n",
    "            done = False\n",
    "        \n",
    "        return reward , done\n",
    "\n",
    "\n",
    "    def next_state(self, action1, uav_loc, user_prof, scheduling):\n",
    "        if action1<5:\n",
    "            action = np.base_repr(action1,base=5,padding = 1)\n",
    "        else :\n",
    "            action = np.base_repr(action1,base=5,padding = 0)\n",
    "\n",
    "        for i in range(len(action)):\n",
    "            if action[i] == \"0\":\n",
    "\n",
    "                uav_loc[:,i] = uav_loc[:,i] + (-2*np.array([1,0]))\n",
    "                uav_loc[0,i] = uav_loc[0,i] + (uav_loc[0,i]<-self.size[0]/2)*(-self.size[0]/2-uav_loc[0,i])\n",
    "\n",
    "            elif action[i] == \"1\":\n",
    "\n",
    "                uav_loc[:,i] = uav_loc[:,i] + (2*np.array([0,1]))\n",
    "                uav_loc[1,i] = uav_loc[1,i] + (uav_loc[1,i]>self.size[1]/2)*(self.size[1]/2-uav_loc[1,i])\n",
    "\n",
    "            elif action[i] == \"2\":\n",
    "\n",
    "                uav_loc[:,i] = uav_loc[:,i] + (2*np.array([1,0]))\n",
    "                uav_loc[0,i] = uav_loc[0,i] + (uav_loc[0,i]>self.size[0]/2)*(self.size[0]/2-uav_loc[0,i])\n",
    "\n",
    "            elif action[i] == \"3\":\n",
    "\n",
    "                uav_loc[:,i] = uav_loc[:,i] + (-2*np.array([0,1]))\n",
    "                uav_loc[1,i] = uav_loc[1,i] + (uav_loc[1,i]<-self.size[1]/2)*(-self.size[1]/2-uav_loc[1,i])\n",
    "\n",
    "            else :\n",
    "                pass\n",
    "\n",
    "        #user_prof = user_prof + (0.1 * ~(np.sum(scheduling,axis=0)>0))\n",
    "        # user_prof = user_prof - (np.min(user_prof)>5)*5\n",
    "        user_prof = 1/(0.9/user_prof + 0.1*np.sum(scheduling,axis=0))\n",
    "\n",
    "        return np.hstack((uav_loc.flatten() , user_prof))\n",
    "\n",
    "    def init_state(self):\n",
    "\n",
    "        while True:\n",
    "            a = np.random.uniform(-self.size[0]/2,self.size[0]/2,size = (1,self.uav_number))\n",
    "            b = np.random.uniform(-self.size[1]/2,self.size[1]/2,size = (1,self.uav_number))\n",
    "            c = np.vstack((a,b))\n",
    "            if np.linalg.norm(c[:,0]-c[:,1])>self.safe_dist:\n",
    "                break\n",
    "        \n",
    " \n",
    "\n",
    "        return np.hstack((a.flatten(),b.flatten(),self.user_profile))\n",
    "\n",
    "\n",
    "\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def schedule(user_prof,user_loc,UAV_loc,transmit_pow,noise,height):\n",
    "\n",
    "\n",
    "    num_agents = np.shape(UAV_loc)[1]\n",
    "    num_user = np.shape(user_loc)[1]\n",
    "\n",
    "    A = cp.Variable((num_agents,num_user))\n",
    "\n",
    "    pref = np.zeros((num_agents,num_user))\n",
    "    for i in range(np.shape(pref)[0]):\n",
    "        for j in range(np.shape(pref)[1]):\n",
    "            interf = 0\n",
    "            for k in range(np.shape(pref)[0]):\n",
    "                if k != i:\n",
    "                    interf = interf + transmit_pow/(height**2 + np.linalg.norm(UAV_loc[:,k]-user_loc[:,j]))\n",
    "            pref[i,j] = user_prof[j]*np.log2(1 + transmit_pow/(height**2 + np.linalg.norm(UAV_loc[:,i]-user_loc[:,j]))/(interf+noise))\n",
    "\n",
    "    objective = cp.Minimize(-1*cp.sum(cp.multiply(A,pref)))\n",
    "\n",
    "    constraints = [A>=0,A<=1]\n",
    "    constraints.append(cp.sum(A,axis = 0) <= 1)\n",
    "    constraints.append(cp.sum(A,axis = 1) <= 1)\n",
    "\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "\n",
    "    problem.solve()\n",
    "\n",
    "    return np.round(A.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "45385770-d2f3-477f-b8db-a0263840f408",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QuqbYBR-2_UO",
    "outputId": "b1ef074b-7fb2-48e6-d8ad-db96e4078d59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Digikala\\anaconda3\\envs\\my_temp\\quad_RL\\final\\DQN\n",
      "DGN2.ipynb\n",
      "checkpoint_eps.pth\n",
      "log.txt\n",
      "rewards.npy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "155bbf88-e0dd-405c-87dc-a40a331f78f7",
   "metadata": {
    "id": "de6f3779-5d33-436f-a918-5ac4dd091357"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import random\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fcd8c574-66f5-4b93-82e4-55109e854242",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dcee31e6-d718-4372-be76-0cce78b2b24b",
    "outputId": "45094f64-dca2-48d9-bc92-ca38200c9981"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "ALPHA = 0.001  # Learning rate\n",
    "\n",
    "MEMORY_SIZE = 1  # Size of experience replay memory\n",
    "\n",
    "\n",
    "\n",
    "# Experience replay memory\n",
    "memory = deque(maxlen=MEMORY_SIZE)\n",
    "\n",
    "# Check for GPU\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "\n",
    "# Define the Q-network using\n",
    "\n",
    "def weight_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 1024)\n",
    "        self.fc4 = nn.Linear(1024, output_dim)\n",
    "\n",
    "    # def forward(self, state):\n",
    "    #     x = torch.relu(self.fc1(state))\n",
    "    #     x = torch.relu(self.fc2(x))\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = torch.relu(self.fc1(state))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        return self.fc4(x)  # Output Q-values for each action\n",
    "\n",
    "# Initialize environment, model, and optimizer\n",
    "quad_env = my_env()\n",
    "input_dim =quad_env.observation_space  # State space dimension\n",
    "output_dim = quad_env.actions  # Action space size\n",
    "\n",
    "q_net = QNetwork(input_dim, output_dim).to(DEVICE)\n",
    "q_net.apply(weight_init)\n",
    "target_net = copy.deepcopy(q_net)\n",
    "optimizer = optim.Adam(q_net.parameters(), lr=ALPHA)\n",
    "#loss_fn = nn.SmoothL1Loss()\n",
    "loss_fn = nn.MSELoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304aeefd-a139-40a0-a9de-da339511bff3",
   "metadata": {
    "id": "f71fe30c-cd4c-4822-b17b-7a62079fc3cc"
   },
   "source": [
    "## function defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "69d9d2d4-6d4a-4e9f-9ef7-9d644b1066ed",
   "metadata": {
    "id": "dbe8ceb3-db69-4de0-9ad9-119d0feeb95c"
   },
   "outputs": [],
   "source": [
    "# Function to select an action using epsilon-greedy policy\n",
    "def select_action(state, epsilon):\n",
    "    if random.random() < epsilon:\n",
    "        return random.randint(0, quad_env.actions-1)  # Exploration: random action\n",
    "    else:\n",
    "        state = torch.FloatTensor(state).to(DEVICE)  # Convert state to tensor\n",
    "        q_values = q_net(state)\n",
    "        return torch.argmax(q_values).item()  # Exploitation: action with highest Q-value\n",
    "\n",
    "# Function to store experiences in memory\n",
    "def store_experience(state, action, reward, next_state, done):\n",
    "    memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "\n",
    "def weight_change(model1,model2):\n",
    "    weight_diff = 0\n",
    "    for param1, param2 in zip(model1.parameters(), model2.parameters()):\n",
    "        weight_diff += torch.sum(torch.abs(param1 - param2)).item()\n",
    "    return weight_diff\n",
    "\n",
    "\n",
    "# Function to update the Q-values using experience replay\n",
    "def update_q_network(batch_size):\n",
    "    if len(memory) < batch_size:\n",
    "        return\n",
    "\n",
    "    batch = random.sample(memory, batch_size)\n",
    "    states, actions, rewards, next_states , done = zip(*batch)\n",
    "\n",
    "    states = torch.FloatTensor(np.array(states)).to(DEVICE)\n",
    "    next_states = torch.FloatTensor(np.array(next_states)).to(DEVICE)\n",
    "    actions = torch.LongTensor(actions).to(DEVICE)\n",
    "    rewards = torch.FloatTensor(rewards).to(DEVICE)\n",
    "    done = torch.BoolTensor(done).to(DEVICE)\n",
    "\n",
    "\n",
    "    # Get current Q-values for the actions taken\n",
    "    q_values = q_net(states)\n",
    "\n",
    "\n",
    "    current_q_values = q_values.gather(1, actions.unsqueeze(1))\n",
    "\n",
    "\n",
    "    # Get the maximum Q-values for the next states\n",
    "    #next_q_values = target_net(next_states).max(1)[0].unsqueeze(1)\n",
    "    next_q_values = q_net(next_states).max(1)[0].unsqueeze(1)\n",
    "    \n",
    "    target_q_values = rewards.unsqueeze(1) + (GAMMA * next_q_values)*(~(done.unsqueeze(1)))\n",
    "\n",
    "    # Compute the loss\n",
    "    loss = loss_fn(current_q_values, target_q_values)\n",
    "\n",
    "    # Update the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fb22964e-f7ea-4ec7-9fdb-ed7b616d1524",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "id": "7804389a-98d8-4ce4-adde-420d703767ce",
    "outputId": "b685d1a8-fecc-4e69-e614-4d2870de9af6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 10/10000, Eps Reward: -971.9447123004862, Epsilon: 0.988559330361785, weights: 92.12357064289972, elapsed: 0.02145131826400757 minutes\n",
      "episode 20/10000, Eps Reward: -967.5739064709184, Epsilon: 0.9772495496453408, weights: 97.27148237056099, elapsed: 0.04276270866394043 minutes\n",
      "episode 30/10000, Eps Reward: -981.4397620852309, Epsilon: 0.9660691603937541, weights: 166.3982686600648, elapsed: 0.056244063377380374 minutes\n",
      "episode 40/10000, Eps Reward: -970.8661547141771, Epsilon: 0.9550166822820216, weights: 70.25055936630815, elapsed: 0.07682933807373046 minutes\n",
      "episode 50/10000, Eps Reward: -982.6627814404943, Epsilon: 0.9440906519210489, weights: 18.46612693183124, elapsed: 0.09174799919128418 minutes\n",
      "episode 60/10000, Eps Reward: -959.7310432225729, Epsilon: 0.9332896226638931, weights: 56.47650733124465, elapsed: 0.11963180700937907 minutes\n",
      "episode 70/10000, Eps Reward: -987.6782292791825, Epsilon: 0.9226121644142213, weights: 66.15927073732018, elapsed: 0.12960244417190553 minutes\n",
      "episode 80/10000, Eps Reward: -939.451009935512, Epsilon: 0.9120568634369598, weights: 9.325175172183663, elapsed: 0.16812002261479694 minutes\n",
      "episode 90/10000, Eps Reward: -953.0270165168738, Epsilon: 0.9016223221711109, weights: 78.25665271375328, elapsed: 0.20189973910649617 minutes\n",
      "episode 100/10000, Eps Reward: -988.1378713654947, Epsilon: 0.8913071590447111, weights: 62.74024969339371, elapsed: 0.21335022846857707 minutes\n",
      "episode 110/10000, Eps Reward: -958.8830260804631, Epsilon: 0.8811100082919047, weights: 10.678514875471592, elapsed: 0.24144676526387532 minutes\n",
      "episode 120/10000, Eps Reward: -964.7918542782833, Epsilon: 0.8710295197721121, weights: 143.54561226721853, elapsed: 0.26644715865453084 minutes\n",
      "episode 130/10000, Eps Reward: -969.9467970389775, Epsilon: 0.8610643587912663, weights: 65.00840940047055, elapsed: 0.2891402045885722 minutes\n",
      "episode 140/10000, Eps Reward: -944.0478050190035, Epsilon: 0.8512132059250941, weights: 26.73005838925019, elapsed: 0.3258615811665853 minutes\n",
      "episode 150/10000, Eps Reward: -976.5529903817671, Epsilon: 0.8414747568444195, weights: 24.665124544873834, elapsed: 0.34419818719228107 minutes\n",
      "episode 160/10000, Eps Reward: -986.6607199912949, Epsilon: 0.8318477221424653, weights: 12.507317648967728, elapsed: 0.35725109179814657 minutes\n",
      "episode 170/10000, Eps Reward: -940.3823772055381, Epsilon: 0.8223308271641319, weights: 96.5799380382523, elapsed: 0.39423638582229614 minutes\n",
      "episode 180/10000, Eps Reward: -989.391483864817, Epsilon: 0.812922811837227, weights: 50.33159233164042, elapsed: 0.40507072607676187 minutes\n",
      "episode 190/10000, Eps Reward: -952.4470511574852, Epsilon: 0.8036224305056286, weights: 26.957698528654873, elapsed: 0.43779216607411703 minutes\n",
      "episode 200/10000, Eps Reward: -973.6231013109152, Epsilon: 0.7944284517643544, weights: 89.3187389690429, elapsed: 0.45617475509643557 minutes\n",
      "episode 210/10000, Eps Reward: -945.380558664182, Epsilon: 0.7853396582965199, weights: 110.68307422660291, elapsed: 0.4917635997136434 minutes\n",
      "episode 220/10000, Eps Reward: -962.7410595215606, Epsilon: 0.7763548467121608, weights: 40.466380409896374, elapsed: 0.5177671392758687 minutes\n",
      "episode 230/10000, Eps Reward: -934.4009924716851, Epsilon: 0.7674728273889002, weights: 31.71614685934037, elapsed: 0.5577267368634542 minutes\n",
      "episode 240/10000, Eps Reward: -946.5456237104287, Epsilon: 0.7586924243144371, weights: 47.22192241018638, elapsed: 0.5954691648483277 minutes\n",
      "episode 250/10000, Eps Reward: -944.3443777815586, Epsilon: 0.7500124749308392, weights: 33.645467462949455, elapsed: 0.6300043026606242 minutes\n",
      "episode 260/10000, Eps Reward: -957.8074190684589, Epsilon: 0.7414318299806156, weights: 31.015941681340337, elapsed: 0.6588425556818645 minutes\n",
      "episode 270/10000, Eps Reward: -985.4848113779024, Epsilon: 0.7329493533545505, weights: 56.75938488636166, elapsed: 0.6722783962885539 minutes\n",
      "episode 280/10000, Eps Reward: -962.0404903943208, Epsilon: 0.7245639219412776, weights: 27.205966744571924, elapsed: 0.6997848073641459 minutes\n",
      "episode 290/10000, Eps Reward: -966.386294602015, Epsilon: 0.7162744254785781, weights: 113.32759063038975, elapsed: 0.7218214233716329 minutes\n",
      "episode 300/10000, Eps Reward: -960.9584423905022, Epsilon: 0.7080797664063756, weights: 32.893513734452426, elapsed: 0.7501727302869161 minutes\n",
      "episode 310/10000, Eps Reward: -970.8574268950922, Epsilon: 0.699978859721416, weights: 24.943220725283027, elapsed: 0.7724658846855164 minutes\n",
      "episode 320/10000, Eps Reward: -960.548498585323, Epsilon: 0.6919706328336088, weights: 115.28193035908043, elapsed: 0.8003106077512105 minutes\n",
      "episode 330/10000, Eps Reward: -970.6224721291325, Epsilon: 0.6840540254240131, weights: 109.59973018616438, elapsed: 0.8232818484306336 minutes\n",
      "episode 340/10000, Eps Reward: -978.2300624909052, Epsilon: 0.6762279893044459, weights: 45.521296210587025, elapsed: 0.8411397735277811 minutes\n",
      "episode 350/10000, Eps Reward: -938.3775961411171, Epsilon: 0.6684914882786995, weights: 144.4069528914988, elapsed: 0.8775019367535909 minutes\n",
      "episode 360/10000, Eps Reward: -980.8630916212733, Epsilon: 0.6608434980053443, weights: 44.97331178188324, elapsed: 0.8957631508509318 minutes\n",
      "episode 370/10000, Eps Reward: -977.6406363611884, Epsilon: 0.6532830058621028, weights: 47.16413022018969, elapsed: 0.9140689531962077 minutes\n",
      "episode 380/10000, Eps Reward: -987.776238873808, Epsilon: 0.6458090108117747, weights: 19.768992183730006, elapsed: 0.9258336345354716 minutes\n",
      "episode 390/10000, Eps Reward: -971.177742151655, Epsilon: 0.6384205232696947, weights: 16.988978568464518, elapsed: 0.9479452490806579 minutes\n",
      "episode 400/10000, Eps Reward: -973.4484583028003, Epsilon: 0.6311165649727097, weights: 89.8274060189724, elapsed: 0.9658802549044291 minutes\n",
      "episode 410/10000, Eps Reward: -954.421818818274, Epsilon: 0.623896168849652, weights: 16.018489902839065, elapsed: 1.0001463611920676 minutes\n",
      "episode 420/10000, Eps Reward: -955.5503574713159, Epsilon: 0.6167583788932951, weights: 16.83778152614832, elapsed: 1.0312183499336243 minutes\n",
      "episode 430/10000, Eps Reward: -955.9093684817815, Epsilon: 0.609702250033776, weights: 72.82003236934543, elapsed: 1.062739098072052 minutes\n",
      "episode 440/10000, Eps Reward: -951.3413272309284, Epsilon: 0.6027268480134631, weights: 28.388295099139214, elapsed: 1.0948779463768006 minutes\n",
      "episode 450/10000, Eps Reward: -913.4587690815912, Epsilon: 0.5958312492632584, weights: 29.19839913584292, elapsed: 1.150629452864329 minutes\n",
      "episode 460/10000, Eps Reward: -977.8255804163233, Epsilon: 0.5890145407803127, weights: 4.589876405661926, elapsed: 1.1699464162190756 minutes\n",
      "episode 470/10000, Eps Reward: -961.9329402190676, Epsilon: 0.5822758200071402, weights: 29.956980760209262, elapsed: 1.198091737429301 minutes\n",
      "episode 480/10000, Eps Reward: -907.963464124918, Epsilon: 0.5756141947121178, weights: 9.050632970407605, elapsed: 1.255713685353597 minutes\n",
      "episode 490/10000, Eps Reward: -961.6053484501792, Epsilon: 0.5690287828713493, weights: 27.551729146391153, elapsed: 1.2826606194178263 minutes\n",
      "episode 500/10000, Eps Reward: -942.1358724527566, Epsilon: 0.5625187125518827, weights: 17.051089230924845, elapsed: 1.3227908452351889 minutes\n",
      "episode 510/10000, Eps Reward: -919.6909536179434, Epsilon: 0.5560831217962626, weights: 8.721002651378512, elapsed: 1.376821752389272 minutes\n",
      "episode 520/10000, Eps Reward: -952.5244638518983, Epsilon: 0.5497211585084044, weights: 10.99848360568285, elapsed: 1.410478154818217 minutes\n",
      "episode 530/10000, Eps Reward: -974.3752367560704, Epsilon: 0.5434319803407729, weights: 80.74646029435098, elapsed: 1.4298727869987489 minutes\n",
      "episode 540/10000, Eps Reward: -970.3655974630286, Epsilon: 0.5372147545828531, weights: 12.457344895228744, elapsed: 1.452650284767151 minutes\n",
      "episode 550/10000, Eps Reward: -963.0698367349581, Epsilon: 0.531068658050896, weights: 7.233861598186195, elapsed: 1.4821775674819946 minutes\n",
      "episode 560/10000, Eps Reward: -950.114214033227, Epsilon: 0.5249928769789257, weights: 26.725318212993443, elapsed: 1.5173280159632365 minutes\n",
      "episode 570/10000, Eps Reward: -973.4775193971961, Epsilon: 0.518986606910994, weights: 34.036512781865895, elapsed: 1.5383483211199442 minutes\n",
      "episode 580/10000, Eps Reward: -975.6424184574155, Epsilon: 0.5130490525946672, weights: 77.95372266508639, elapsed: 1.5566949486732482 minutes\n",
      "episode 590/10000, Eps Reward: -951.8031740435914, Epsilon: 0.5071794278757324, weights: 18.22676607966423, elapsed: 1.5931366642316183 minutes\n",
      "episode 600/10000, Eps Reward: -976.6661360503692, Epsilon: 0.5013769555941073, weights: 14.770094149746, elapsed: 1.6136884967486063 minutes\n",
      "episode 610/10000, Eps Reward: -948.0403612371465, Epsilon: 0.49564086748094127, weights: 17.759848849847913, elapsed: 1.649612828095754 minutes\n",
      "episode 620/10000, Eps Reward: -959.4299269659128, Epsilon: 0.4899704040568935, weights: 35.6122484318912, elapsed: 1.6798933625221253 minutes\n",
      "episode 630/10000, Eps Reward: -913.0964994453927, Epsilon: 0.48436481453157587, weights: 11.242995876818895, elapsed: 1.7378943840662637 minutes\n",
      "episode 640/10000, Eps Reward: -959.9641111536279, Epsilon: 0.4788233567041449, weights: 17.443423511460423, elapsed: 1.7685152371724446 minutes\n",
      "episode 650/10000, Eps Reward: -963.3906910926831, Epsilon: 0.4733452968650316, weights: 30.412951914593577, elapsed: 1.7952215075492859 minutes\n",
      "episode 660/10000, Eps Reward: -871.6801757403242, Epsilon: 0.46792990969879605, weights: 27.690305646508932, elapsed: 1.8724620739618938 minutes\n",
      "episode 670/10000, Eps Reward: -946.5760498821007, Epsilon: 0.46257647818809233, weights: 75.1482807341963, elapsed: 1.9102193077405294 minutes\n",
      "episode 680/10000, Eps Reward: -963.7916292250945, Epsilon: 0.4572842935187334, weights: 57.00068647041917, elapsed: 1.937078599135081 minutes\n",
      "episode 690/10000, Eps Reward: -906.7372317350677, Epsilon: 0.45205265498584113, weights: 30.229788314551115, elapsed: 1.9976028482119241 minutes\n",
      "episode 700/10000, Eps Reward: -954.3764833397005, Epsilon: 0.4468808699010701, weights: 30.63789303973317, elapsed: 2.029114500681559 minutes\n",
      "episode 710/10000, Eps Reward: -926.3157366837797, Epsilon: 0.4417682535008938, weights: 18.5352568551898, elapsed: 2.0795887231826784 minutes\n",
      "episode 720/10000, Eps Reward: -902.5323706190426, Epsilon: 0.4367141288559389, weights: 17.44861665740609, elapsed: 2.1407623052597047 minutes\n",
      "episode 730/10000, Eps Reward: -859.3846315719738, Epsilon: 0.43171782678135734, weights: 26.8605669811368, elapsed: 2.227853544553121 minutes\n",
      "episode 740/10000, Eps Reward: -918.5774110632947, Epsilon: 0.4267786857482238, weights: 50.172454703599215, elapsed: 2.2830743352572123 minutes\n",
      "episode 750/10000, Eps Reward: -899.894569768621, Epsilon: 0.42189605179594686, weights: 52.573497576639056, elapsed: 2.3453853885332743 minutes\n",
      "episode 760/10000, Eps Reward: -915.9039057356483, Epsilon: 0.41706927844568215, weights: 65.74530513584614, elapsed: 2.399445195992788 minutes\n",
      "episode 770/10000, Eps Reward: -953.6051310671231, Epsilon: 0.4122977266147364, weights: 39.58269948512316, elapsed: 2.4329939126968383 minutes\n",
      "episode 780/10000, Eps Reward: -963.5191982378379, Epsilon: 0.40758076453195, weights: 72.81603234261274, elapsed: 2.4604345679283144 minutes\n",
      "episode 790/10000, Eps Reward: -886.9751953003882, Epsilon: 0.402917767654049, weights: 11.619709637016058, elapsed: 2.5328945398330687 minutes\n",
      "episode 800/10000, Eps Reward: -886.304456913658, Epsilon: 0.398308118582952, weights: 17.14176081866026, elapsed: 2.6055627425511676 minutes\n",
      "episode 810/10000, Eps Reward: -929.4412220353042, Epsilon: 0.39375120698402555, weights: 13.608180023729801, elapsed: 2.653553756078084 minutes\n",
      "episode 820/10000, Eps Reward: -954.0305792127763, Epsilon: 0.38924642950527283, weights: 12.71487719193101, elapsed: 2.6857614874839784 minutes\n",
      "episode 830/10000, Eps Reward: -939.0066269122204, Epsilon: 0.38479318969744825, weights: 31.993174098432064, elapsed: 2.7302156845728556 minutes\n",
      "episode 840/10000, Eps Reward: -886.7256725279019, Epsilon: 0.3803908979350848, weights: 56.01889732480049, elapsed: 2.7999979813893634 minutes\n",
      "episode 850/10000, Eps Reward: -926.6879879144328, Epsilon: 0.3760389713384255, weights: 40.74659828469157, elapsed: 2.8473188201586406 minutes\n",
      "episode 860/10000, Eps Reward: -943.4537306180416, Epsilon: 0.3717368336962485, weights: 56.921404177322984, elapsed: 2.8874812444051106 minutes\n",
      "episode 870/10000, Eps Reward: -962.600010691149, Epsilon: 0.36748391538957365, weights: 21.77105986699462, elapsed: 2.9162156065305074 minutes\n",
      "episode 880/10000, Eps Reward: -945.2388588850241, Epsilon: 0.3632796533162438, weights: 13.479414463043213, elapsed: 2.955981520811717 minutes\n",
      "episode 890/10000, Eps Reward: -854.1828376189338, Epsilon: 0.3591234908163674, weights: 193.48472541570663, elapsed: 3.0442757606506348 minutes\n",
      "episode 900/10000, Eps Reward: -927.7510794124216, Epsilon: 0.3550148775986148, weights: 9.588209407404065, elapsed: 3.092061503728231 minutes\n",
      "episode 910/10000, Eps Reward: -916.2570971565608, Epsilon: 0.35095326966735774, weights: 18.10315688699484, elapsed: 3.150219202041626 minutes\n",
      "episode 920/10000, Eps Reward: -947.4109227902733, Epsilon: 0.3469381292506421, weights: 15.613286565989256, elapsed: 3.1850778698921203 minutes\n",
      "episode 930/10000, Eps Reward: -964.9532816999233, Epsilon: 0.34296892472898516, weights: 15.37981753051281, elapsed: 3.213195502758026 minutes\n",
      "episode 940/10000, Eps Reward: -963.8652058276954, Epsilon: 0.339045130564987, weights: 12.304250900633633, elapsed: 3.2387358427047728 minutes\n",
      "episode 950/10000, Eps Reward: -941.6834426788977, Epsilon: 0.3351662272337476, weights: 37.936781231313944, elapsed: 3.2783968329429625 minutes\n",
      "episode 960/10000, Eps Reward: -959.3018483021358, Epsilon: 0.3313317011540795, weights: 25.995630525052547, elapsed: 3.308906312783559 minutes\n",
      "episode 970/10000, Eps Reward: -933.0811223826234, Epsilon: 0.327541044620508, weights: 37.72051686421037, elapsed: 3.3523090839385987 minutes\n",
      "episode 980/10000, Eps Reward: -903.4319553703341, Epsilon: 0.32379375573604896, weights: 36.91047102585435, elapsed: 3.414271716276805 minutes\n",
      "episode 990/10000, Eps Reward: -918.264854674653, Epsilon: 0.320089338345756, weights: 4.87236029561609, elapsed: 3.470592673619588 minutes\n",
      "episode 1000/10000, Eps Reward: -931.9291044617843, Epsilon: 0.3164273019710274, weights: 69.42491258308291, elapsed: 3.515794082482656 minutes\n",
      "episode 1010/10000, Eps Reward: -949.1441388841315, Epsilon: 0.3128071617446651, weights: 16.011695755645633, elapsed: 3.552434476216634 minutes\n",
      "episode 1020/10000, Eps Reward: -892.0367185349432, Epsilon: 0.3092284383466767, weights: 35.07986468076706, elapsed: 3.6229777177174887 minutes\n",
      "episode 1030/10000, Eps Reward: -914.4332685949605, Epsilon: 0.3056906579408113, weights: 32.688475634902716, elapsed: 3.6827898740768434 minutes\n",
      "episode 1040/10000, Eps Reward: -904.7257657885357, Epsilon: 0.30219335211182197, weights: 24.44686810299754, elapsed: 3.743356001377106 minutes\n",
      "episode 1050/10000, Eps Reward: -950.9996786283127, Epsilon: 0.29873605780344586, weights: 14.66978858038783, elapsed: 3.778639082113902 minutes\n",
      "episode 1060/10000, Eps Reward: -835.4677336852321, Epsilon: 0.295318317257094, weights: 24.774114549160004, elapsed: 3.8735314130783083 minutes\n",
      "episode 1070/10000, Eps Reward: -905.1012998164945, Epsilon: 0.2919396779512421, weights: 11.050722369924188, elapsed: 3.934234356880188 minutes\n",
      "episode 1080/10000, Eps Reward: -964.5853770418702, Epsilon: 0.28859969254151513, weights: 30.000523425638676, elapsed: 3.9605512181917826 minutes\n",
      "episode 1090/10000, Eps Reward: -928.1531002629494, Epsilon: 0.2852979188014572, weights: 15.242675455287099, elapsed: 4.007252196470897 minutes\n",
      "episode 1100/10000, Eps Reward: -910.9569623602553, Epsilon: 0.2820339195639795, weights: 0.863723220769316, elapsed: 4.067831953366597 minutes\n",
      "episode 1110/10000, Eps Reward: -797.7436736599396, Epsilon: 0.27880726266347705, weights: 41.056086238473654, elapsed: 4.130448973178863 minutes\n",
      "episode 1120/10000, Eps Reward: -862.3890790898846, Epsilon: 0.27561752087860925, weights: 18.70408608019352, elapsed: 4.218972539901733 minutes\n",
      "episode 1130/10000, Eps Reward: -916.7108125471632, Epsilon: 0.27246427187573324, weights: 39.60764295980334, elapsed: 4.274203157424926 minutes\n",
      "episode 1140/10000, Eps Reward: -947.4421948227968, Epsilon: 0.2693470981529862, weights: 20.483798256143928, elapsed: 4.313190833727519 minutes\n",
      "episode 1150/10000, Eps Reward: -894.3474640199153, Epsilon: 0.2662655869850061, weights: 16.542669218033552, elapsed: 4.382067632675171 minutes\n",
      "episode 1160/10000, Eps Reward: -898.1738709288868, Epsilon: 0.26321933036828526, weights: 31.69993581622839, elapsed: 4.448417901992798 minutes\n",
      "episode 1170/10000, Eps Reward: -877.6769261410384, Epsilon: 0.2602079249671496, weights: 32.12235425040126, elapsed: 4.528656216462453 minutes\n",
      "episode 1180/10000, Eps Reward: -913.2119732742306, Epsilon: 0.25723097206035517, weights: 71.1439816430211, elapsed: 4.588048374652862 minutes\n",
      "episode 1190/10000, Eps Reward: -947.302116869669, Epsilon: 0.2542880774882957, weights: 20.900583531707525, elapsed: 4.62572056055069 minutes\n",
      "episode 1200/10000, Eps Reward: -875.2781219730135, Epsilon: 0.25137885160081536, weights: 9.515111684799194, elapsed: 4.705908755461375 minutes\n",
      "episode 1210/10000, Eps Reward: -878.900012051444, Epsilon: 0.24850290920561657, weights: 37.8885920830071, elapsed: 4.78267541329066 minutes\n",
      "episode 1220/10000, Eps Reward: -903.3774903141132, Epsilon: 0.2456598695172598, weights: 20.89724911376834, elapsed: 4.843428834279378 minutes\n",
      "episode 1230/10000, Eps Reward: -858.5153937987485, Epsilon: 0.24284935610674582, weights: 5.077049553394318, elapsed: 4.934560223420461 minutes\n",
      "episode 1240/10000, Eps Reward: -891.792147735395, Epsilon: 0.24007099685167538, weights: 34.945745538920164, elapsed: 5.0003812710444135 minutes\n",
      "episode 1250/10000, Eps Reward: -895.0584698948524, Epsilon: 0.2373244238869784, weights: 20.54285237006843, elapsed: 5.067982653776805 minutes\n",
      "episode 1260/10000, Eps Reward: -899.5210187988217, Epsilon: 0.2346092735562078, weights: 29.521842800080776, elapsed: 5.136983899275462 minutes\n",
      "episode 1270/10000, Eps Reward: -961.7015401719227, Epsilon: 0.23192518636338968, weights: 60.72826112061739, elapsed: 5.165799578030904 minutes\n",
      "episode 1280/10000, Eps Reward: -920.6324625076661, Epsilon: 0.22927180692542473, weights: 6.99798346683383, elapsed: 5.221444729963938 minutes\n",
      "episode 1290/10000, Eps Reward: -891.3905505242583, Epsilon: 0.22664878392503437, weights: 17.702577274292707, elapsed: 5.291133161385854 minutes\n",
      "episode 1300/10000, Eps Reward: -873.2881962279758, Epsilon: 0.22405577006424496, weights: 32.08088316768408, elapsed: 5.3724493821462 minutes\n",
      "episode 1310/10000, Eps Reward: -751.7459175382737, Epsilon: 0.2214924220184041, weights: 16.486824620515108, elapsed: 5.522590812047323 minutes\n",
      "episode 1320/10000, Eps Reward: -916.771996427717, Epsilon: 0.21895840039072345, weights: 27.873067393898964, elapsed: 5.578029485543569 minutes\n",
      "episode 1330/10000, Eps Reward: -843.5821286667899, Epsilon: 0.21645336966734122, weights: 14.57634392566979, elapsed: 5.672055232524872 minutes\n",
      "episode 1340/10000, Eps Reward: -930.6821401304153, Epsilon: 0.21397699817289872, weights: 76.23479377478361, elapsed: 5.717876068751017 minutes\n",
      "episode 1350/10000, Eps Reward: -966.2826634201432, Epsilon: 0.21152895802662566, weights: 26.967485638335347, elapsed: 5.7427639404932656 minutes\n",
      "episode 1360/10000, Eps Reward: -890.694415270625, Epsilon: 0.2091089250989272, weights: 29.641580805182457, elapsed: 5.8165242910385135 minutes\n",
      "episode 1370/10000, Eps Reward: -956.6135117143085, Epsilon: 0.20671657896846818, weights: 10.140445209573954, elapsed: 5.846879780292511 minutes\n",
      "episode 1380/10000, Eps Reward: -928.0484814026333, Epsilon: 0.20435160287974796, weights: 30.11465210467577, elapsed: 5.894379731019338 minutes\n",
      "episode 1390/10000, Eps Reward: -912.6764704991714, Epsilon: 0.2020136837011611, weights: 3.4879427533596754, elapsed: 5.954986929893494 minutes\n",
      "episode 1400/10000, Eps Reward: -923.4457675455403, Epsilon: 0.19970251188353727, weights: 9.623843217268586, elapsed: 6.006448252995809 minutes\n",
      "episode 1410/10000, Eps Reward: -927.077468180311, Epsilon: 0.19741778141915603, weights: 36.18827332183719, elapsed: 6.058851186434428 minutes\n",
      "episode 1420/10000, Eps Reward: -800.6714132747497, Epsilon: 0.19515918980123015, weights: 20.058054350316525, elapsed: 6.1801342805226644 minutes\n",
      "episode 1430/10000, Eps Reward: -873.0639017544623, Epsilon: 0.1929264379838526, weights: 39.49905243515968, elapsed: 6.260788806279501 minutes\n",
      "episode 1440/10000, Eps Reward: -852.0555443588548, Epsilon: 0.19071923034240174, weights: 33.767105508595705, elapsed: 6.3516170779864 minutes\n",
      "episode 1450/10000, Eps Reward: -941.7163672295961, Epsilon: 0.1885372746343997, weights: 24.382323883473873, elapsed: 6.395094100634257 minutes\n",
      "episode 1460/10000, Eps Reward: -856.0011425339769, Epsilon: 0.18638028196081816, weights: 28.11891982704401, elapsed: 6.48482045729955 minutes\n",
      "episode 1470/10000, Eps Reward: -909.8338889384053, Epsilon: 0.18424796672782712, weights: 115.53150602802634, elapsed: 6.542584458986918 minutes\n",
      "episode 1480/10000, Eps Reward: -877.3230957567359, Epsilon: 0.18214004660898125, weights: 22.791404396295547, elapsed: 6.622662878036499 minutes\n",
      "episode 1490/10000, Eps Reward: -869.5215085786164, Epsilon: 0.18005624250783886, weights: 28.382113616913557, elapsed: 6.707318464914958 minutes\n",
      "episode 1500/10000, Eps Reward: -932.3728174194257, Epsilon: 0.1779962785210084, weights: 76.96038874983788, elapsed: 6.753379281361898 minutes\n",
      "episode 1510/10000, Eps Reward: -843.8681037743196, Epsilon: 0.17595988190161785, weights: 16.647386085242033, elapsed: 6.85117598772049 minutes\n",
      "episode 1520/10000, Eps Reward: -869.3434286122585, Epsilon: 0.17394678302320213, weights: 57.83810444176197, elapsed: 6.933660217126211 minutes\n",
      "episode 1530/10000, Eps Reward: -908.0111234933195, Epsilon: 0.17195671534400342, weights: 13.335678160190582, elapsed: 6.996379915873209 minutes\n",
      "episode 1540/10000, Eps Reward: -653.5986135068027, Epsilon: 0.16998941537168014, weights: 14.229204747825861, elapsed: 7.144557984670003 minutes\n",
      "episode 1550/10000, Eps Reward: -956.5466941690696, Epsilon: 0.16804462262841943, weights: 24.03860540688038, elapsed: 7.179147394498189 minutes\n",
      "episode 1560/10000, Eps Reward: -781.4163181617911, Epsilon: 0.1661220796164492, weights: 20.950599525123835, elapsed: 7.252841631571452 minutes\n",
      "episode 1570/10000, Eps Reward: -874.6219878372005, Epsilon: 0.1642215317839442, weights: 38.71983417868614, elapsed: 7.334731451670328 minutes\n",
      "episode 1580/10000, Eps Reward: -870.6342913631639, Epsilon: 0.16234272749132242, weights: 47.90789736062288, elapsed: 7.418580337365468 minutes\n",
      "episode 1590/10000, Eps Reward: -879.0765101453293, Epsilon: 0.16048541797792745, weights: 44.41202772036195, elapsed: 7.49741678237915 minutes\n",
      "episode 1600/10000, Eps Reward: -940.3183341003912, Epsilon: 0.15864935732909116, weights: 17.56541702337563, elapsed: 7.541039244333903 minutes\n",
      "episode 1610/10000, Eps Reward: -956.059502514139, Epsilon: 0.15683430244357394, weights: 16.699985824525356, elapsed: 7.574857529004415 minutes\n",
      "episode 1620/10000, Eps Reward: -866.5047185252713, Epsilon: 0.1550400130013771, weights: 10.364432763308287, elapsed: 7.66300406853358 minutes\n",
      "episode 1630/10000, Eps Reward: -882.6760727485453, Epsilon: 0.1532662514319238, weights: 18.97493528202176, elapsed: 7.733801992734273 minutes\n",
      "episode 1640/10000, Eps Reward: -920.4799811635773, Epsilon: 0.15151278288260356, weights: 6.859620881266892, elapsed: 7.790463093916575 minutes\n",
      "episode 1650/10000, Eps Reward: -914.2113276458374, Epsilon: 0.14977937518767712, weights: 21.200281094759703, elapsed: 7.848338075478872 minutes\n",
      "episode 1660/10000, Eps Reward: -958.7801713908232, Epsilon: 0.14806579883753662, weights: 11.481018140912056, elapsed: 7.881746089458465 minutes\n",
      "episode 1670/10000, Eps Reward: -878.986158543106, Epsilon: 0.14637182694831793, weights: 12.45858908444643, elapsed: 7.9608561833699545 minutes\n",
      "episode 1680/10000, Eps Reward: -948.9977737838897, Epsilon: 0.14469723523186026, weights: 82.45334734395146, elapsed: 7.994252888361613 minutes\n",
      "episode 1690/10000, Eps Reward: -924.0239922039455, Epsilon: 0.1430418019660095, weights: 17.51295303925872, elapsed: 8.04410490989685 minutes\n",
      "episode 1700/10000, Eps Reward: -928.6825687834582, Epsilon: 0.14140530796526146, weights: 17.97033702582121, elapsed: 8.096014181772867 minutes\n",
      "episode 1710/10000, Eps Reward: -745.1038942955049, Epsilon: 0.13978753655174084, weights: 40.522360380738974, elapsed: 8.191170644760131 minutes\n",
      "episode 1720/10000, Eps Reward: -829.7519209323606, Epsilon: 0.13818827352651247, weights: 16.740395300090313, elapsed: 8.296704109509786 minutes\n",
      "episode 1730/10000, Eps Reward: -694.9488196642527, Epsilon: 0.13660730714122035, weights: 5.1708421446383, elapsed: 8.424609299500784 minutes\n",
      "episode 1740/10000, Eps Reward: -763.1456565294244, Epsilon: 0.1350444280700515, weights: 60.911217361688614, elapsed: 8.512360366185506 minutes\n",
      "episode 1750/10000, Eps Reward: -909.2619825560138, Epsilon: 0.13349942938202033, weights: 27.89176393672824, elapsed: 8.57063471476237 minutes\n",
      "episode 1760/10000, Eps Reward: -916.3970798342916, Epsilon: 0.13197210651357044, weights: 31.14036562293768, elapsed: 8.624021077156067 minutes\n",
      "episode 1770/10000, Eps Reward: -754.0727557786105, Epsilon: 0.13046225724148938, weights: 22.079079497605562, elapsed: 8.711638748645782 minutes\n",
      "episode 1780/10000, Eps Reward: -860.8466317189468, Epsilon: 0.1289696816561337, weights: 48.685789719223976, elapsed: 8.799565569559734 minutes\n",
      "episode 1790/10000, Eps Reward: -855.404089713927, Epsilon: 0.12749418213496014, weights: 56.4605203717947, elapsed: 8.889856660366059 minutes\n",
      "episode 1800/10000, Eps Reward: -602.6947949102869, Epsilon: 0.12603556331635965, weights: 47.50626948103309, elapsed: 9.06654193798701 minutes\n",
      "episode 1810/10000, Eps Reward: -670.7840577579681, Epsilon: 0.12459363207379089, weights: 10.756695933640003, elapsed: 9.210410583019257 minutes\n",
      "episode 1820/10000, Eps Reward: -754.9235011994322, Epsilon: 0.12316819749020934, weights: 9.177728619426489, elapsed: 9.299934415022532 minutes\n",
      "episode 1830/10000, Eps Reward: -832.1587462675919, Epsilon: 0.12175907083278943, weights: 16.629898969084024, elapsed: 9.408650529384612 minutes\n",
      "episode 1840/10000, Eps Reward: -936.4275033181636, Epsilon: 0.1203660655279355, weights: 19.90420894138515, elapsed: 9.451332251230875 minutes\n",
      "episode 1850/10000, Eps Reward: -938.2926756811466, Epsilon: 0.11898899713657866, weights: 21.02537865191698, elapsed: 9.49598182439804 minutes\n",
      "episode 1860/10000, Eps Reward: -901.2723197908524, Epsilon: 0.11762768332975655, weights: 37.54426564089954, elapsed: 9.56106922229131 minutes\n",
      "episode 1870/10000, Eps Reward: -970.4601850632068, Epsilon: 0.11628194386447226, weights: 36.015195064246655, elapsed: 9.58814924955368 minutes\n",
      "episode 1880/10000, Eps Reward: -881.2844884684233, Epsilon: 0.11495160055982938, weights: 11.258581563830376, elapsed: 9.662795754273732 minutes\n",
      "episode 1890/10000, Eps Reward: -718.7652456693459, Epsilon: 0.11363647727344031, weights: 61.37556444108486, elapsed: 9.77533579270045 minutes\n",
      "episode 1900/10000, Eps Reward: -736.0616015051257, Epsilon: 0.11233639987810436, weights: 53.62230910360813, elapsed: 9.877184859911601 minutes\n",
      "episode 1910/10000, Eps Reward: -875.6433045083156, Epsilon: 0.11105119623875258, weights: 26.8853290528059, elapsed: 9.962260440985363 minutes\n",
      "episode 1920/10000, Eps Reward: -903.6459998182169, Epsilon: 0.10978069618965641, weights: 46.91781881451607, elapsed: 10.029866246382396 minutes\n",
      "episode 1930/10000, Eps Reward: -870.1056916727981, Epsilon: 0.10852473151189732, weights: 37.38106110692024, elapsed: 10.113507270812988 minutes\n",
      "episode 1940/10000, Eps Reward: -635.657093762464, Epsilon: 0.10728313591109373, weights: 56.85017615184188, elapsed: 10.213298765818278 minutes\n",
      "episode 1950/10000, Eps Reward: -939.1567983934037, Epsilon: 0.10605574499538319, weights: 19.39962724968791, elapsed: 10.25389939546585 minutes\n",
      "episode 1960/10000, Eps Reward: -950.204519071558, Epsilon: 0.10484239625365623, weights: 41.34383252263069, elapsed: 10.28861562013626 minutes\n",
      "episode 1970/10000, Eps Reward: -920.1756069488108, Epsilon: 0.10364292903403932, weights: 46.52563366666436, elapsed: 10.344842310746511 minutes\n",
      "episode 1980/10000, Eps Reward: -907.4005890807794, Epsilon: 0.1024571845226239, weights: 18.605981394648552, elapsed: 10.410522953669231 minutes\n",
      "episode 1990/10000, Eps Reward: -803.8844483064483, Epsilon: 0.10128500572243895, weights: 32.3213490601629, elapsed: 10.470198361078898 minutes\n",
      "episode 2000/10000, Eps Reward: -896.6148885783707, Epsilon: 0.10012623743266384, weights: 12.246325347572565, elapsed: 10.534744143486023 minutes\n",
      "episode 2010/10000, Eps Reward: -995.1939906309274, Epsilon: 0.09898072622807927, weights: 13.86994381248951, elapsed: 10.54188133875529 minutes\n",
      "episode 2020/10000, Eps Reward: -831.7076669875071, Epsilon: 0.09784832043875323, weights: 16.481449007987976, elapsed: 10.64913998444875 minutes\n",
      "episode 2030/10000, Eps Reward: -821.4725570439963, Epsilon: 0.09672887012995926, weights: 65.21497072279453, elapsed: 10.760693116982777 minutes\n",
      "episode 2040/10000, Eps Reward: -773.980028132169, Epsilon: 0.09562222708232461, weights: 82.78096662089229, elapsed: 10.839672613143922 minutes\n",
      "episode 2050/10000, Eps Reward: -925.1290921980122, Epsilon: 0.09452824477220538, weights: 2.2023828853853047, elapsed: 10.893946758906047 minutes\n",
      "episode 2060/10000, Eps Reward: -897.7738998529701, Epsilon: 0.09344677835228626, weights: 1.8968808841891587, elapsed: 10.964252010981243 minutes\n",
      "episode 2070/10000, Eps Reward: -921.7456833438798, Epsilon: 0.09237768463240227, weights: 21.200496489182115, elapsed: 11.018611192703247 minutes\n",
      "episode 2080/10000, Eps Reward: -724.1533671002167, Epsilon: 0.09132082206057975, weights: 30.926852349191904, elapsed: 11.129245809714 minutes\n",
      "episode 2090/10000, Eps Reward: -848.3397571833195, Epsilon: 0.09027605070429445, weights: 24.80304436571896, elapsed: 11.225635798772176 minutes\n",
      "episode 2100/10000, Eps Reward: -559.4580585346675, Epsilon: 0.0892432322319439, weights: 37.9165577404201, elapsed: 11.369343598683676 minutes\n",
      "episode 2110/10000, Eps Reward: -928.5546343340718, Epsilon: 0.08822222989453175, weights: 47.72327532991767, elapsed: 11.421693770090739 minutes\n",
      "episode 2120/10000, Eps Reward: -953.3236929747134, Epsilon: 0.08721290850756179, weights: 37.421978659927845, elapsed: 11.459187030792236 minutes\n",
      "episode 2130/10000, Eps Reward: -903.514147740793, Epsilon: 0.08621513443313891, weights: 21.97477904520929, elapsed: 11.522117122014363 minutes\n",
      "episode 2140/10000, Eps Reward: -834.1763322929089, Epsilon: 0.0852287755622751, weights: 27.278002806007862, elapsed: 11.6282727877299 minutes\n",
      "episode 2150/10000, Eps Reward: -622.6297344487579, Epsilon: 0.08425370129739754, weights: 54.6606958899647, elapsed: 11.736082700888316 minutes\n",
      "episode 2160/10000, Eps Reward: -870.3923102451641, Epsilon: 0.08328978253505716, weights: 41.306226689368486, elapsed: 11.82114874124527 minutes\n",
      "episode 2170/10000, Eps Reward: -731.304659269372, Epsilon: 0.08233689164883481, weights: 15.00076831690967, elapsed: 11.926599331696828 minutes\n",
      "episode 2180/10000, Eps Reward: -811.8450153893397, Epsilon: 0.08139490247244299, weights: 60.162190437316895, elapsed: 12.041186845302581 minutes\n",
      "episode 2190/10000, Eps Reward: -867.6584098395682, Epsilon: 0.08046369028302104, weights: 12.717199072241783, elapsed: 12.12759165763855 minutes\n",
      "episode 2200/10000, Eps Reward: -537.175729150817, Epsilon: 0.07954313178462137, weights: 14.98997668363154, elapsed: 12.286906663576762 minutes\n",
      "episode 2210/10000, Eps Reward: -730.6054127621849, Epsilon: 0.07863310509188452, weights: 44.45108200237155, elapsed: 12.391368953386943 minutes\n",
      "episode 2220/10000, Eps Reward: -895.4165541894843, Epsilon: 0.07773348971390122, weights: 25.21195868961513, elapsed: 12.458996959527333 minutes\n",
      "episode 2230/10000, Eps Reward: -733.9122333687092, Epsilon: 0.07684416653825892, weights: 54.630047004669905, elapsed: 12.563760284582774 minutes\n",
      "episode 2240/10000, Eps Reward: -843.1540435225658, Epsilon: 0.07596501781527072, weights: 4.354006379842758, elapsed: 12.662854937712352 minutes\n",
      "episode 2250/10000, Eps Reward: -881.0104664179971, Epsilon: 0.07509592714238508, weights: 60.662335466593504, elapsed: 12.740770562489827 minutes\n",
      "episode 2260/10000, Eps Reward: -854.7529260145133, Epsilon: 0.0742367794487736, weights: 36.06440468505025, elapsed: 12.83139564593633 minutes\n",
      "episode 2270/10000, Eps Reward: -926.9416699638057, Epsilon: 0.07338746098009515, weights: 18.620493032038212, elapsed: 12.88115125099818 minutes\n",
      "episode 2280/10000, Eps Reward: -685.2726588842115, Epsilon: 0.07254785928343449, weights: 9.10551131144166, elapsed: 13.012074927488962 minutes\n",
      "episode 2290/10000, Eps Reward: -840.7671450500411, Epsilon: 0.07171786319241302, weights: 22.59827694669366, elapsed: 13.115190331141154 minutes\n",
      "episode 2300/10000, Eps Reward: -964.2044608917998, Epsilon: 0.07089736281246993, weights: 37.42950140684843, elapsed: 13.144059185187022 minutes\n",
      "episode 2310/10000, Eps Reward: -928.5721560242404, Epsilon: 0.07008624950631179, weights: 14.717863414436579, elapsed: 13.195309138298034 minutes\n",
      "episode 2320/10000, Eps Reward: -946.9856893135818, Epsilon: 0.06928441587952858, weights: 13.6101946067065, elapsed: 13.234866646925608 minutes\n",
      "episode 2330/10000, Eps Reward: -905.6797104169336, Epsilon: 0.06849175576637419, weights: 43.006167624145746, elapsed: 13.296980039278667 minutes\n",
      "episode 2340/10000, Eps Reward: -937.6608002473074, Epsilon: 0.0677081642157098, weights: 13.78464681841433, elapsed: 13.34057183265686 minutes\n",
      "episode 2350/10000, Eps Reward: -897.5732975596163, Epsilon: 0.06693353747710788, weights: 24.477283522486687, elapsed: 13.40788065592448 minutes\n",
      "episode 2360/10000, Eps Reward: -954.2154507896925, Epsilon: 0.06616777298711521, weights: 28.653785474598408, elapsed: 13.442324141661325 minutes\n",
      "episode 2370/10000, Eps Reward: -936.8556743178569, Epsilon: 0.06541076935567322, weights: 17.09526450559497, elapsed: 13.486048789819082 minutes\n",
      "episode 2380/10000, Eps Reward: -936.8888135012891, Epsilon: 0.06466242635269351, weights: 7.664645206183195, elapsed: 13.534866992632548 minutes\n",
      "episode 2390/10000, Eps Reward: -727.4663052151968, Epsilon: 0.06392264489478694, weights: 0.2251576534472406, elapsed: 13.643345053990682 minutes\n",
      "episode 2400/10000, Eps Reward: -972.6359870148144, Epsilon: 0.06319132703214475, weights: 18.23532285168767, elapsed: 13.663918217023214 minutes\n",
      "episode 2410/10000, Eps Reward: -858.254363317764, Epsilon: 0.06246837593556958, weights: 11.55226756632328, elapsed: 13.759144679705303 minutes\n",
      "episode 2420/10000, Eps Reward: -739.5496145150871, Epsilon: 0.06175369588365491, weights: 12.360031817108393, elapsed: 13.859070551395416 minutes\n",
      "episode 2430/10000, Eps Reward: -741.2788409166766, Epsilon: 0.061047192250111224, weights: 16.893511129543185, elapsed: 13.953810453414917 minutes\n",
      "episode 2440/10000, Eps Reward: -706.734655608462, Epsilon: 0.0603487714912371, weights: 21.161295162513852, elapsed: 14.075973391532898 minutes\n",
      "episode 2450/10000, Eps Reward: -733.2503942213234, Epsilon: 0.059658341133533736, weights: 22.32454115152359, elapsed: 14.179468746980032 minutes\n",
      "episode 2460/10000, Eps Reward: -538.1498937427934, Epsilon: 0.05897580976146106, weights: 27.78343454003334, elapsed: 14.341406019528707 minutes\n",
      "episode 2470/10000, Eps Reward: -899.9647290869952, Epsilon: 0.05830108700533397, weights: 21.545703110285103, elapsed: 14.409949994087219 minutes\n",
      "episode 2480/10000, Eps Reward: -940.1664752934936, Epsilon: 0.05763408352935713, weights: 44.90846958383918, elapsed: 14.449515465895335 minutes\n",
      "episode 2490/10000, Eps Reward: -903.0398906625672, Epsilon: 0.056974711019796474, weights: 23.904931649565697, elapsed: 14.514172418912251 minutes\n",
      "episode 2500/10000, Eps Reward: -940.8182099060721, Epsilon: 0.05632288217328622, weights: 5.740825995802879, elapsed: 14.555798053741455 minutes\n",
      "episode 2510/10000, Eps Reward: -787.8053417998034, Epsilon: 0.05567851068526956, weights: 55.1848217099905, elapsed: 14.629697370529176 minutes\n",
      "episode 2520/10000, Eps Reward: -894.5641541330654, Epsilon: 0.05504151123857156, weights: 24.2663182169199, elapsed: 14.701330979665121 minutes\n",
      "episode 2530/10000, Eps Reward: -953.6116966935108, Epsilon: 0.05441179949210297, weights: 29.10742984339595, elapsed: 14.732498188813528 minutes\n",
      "episode 2540/10000, Eps Reward: -746.3470343805585, Epsilon: 0.053789292069693025, weights: 19.01201370358467, elapsed: 14.82900831302007 minutes\n",
      "episode 2550/10000, Eps Reward: -566.4076500898652, Epsilon: 0.053173906549050215, weights: 18.010796409100294, elapsed: 14.97080115477244 minutes\n",
      "episode 2560/10000, Eps Reward: -768.5123853337446, Epsilon: 0.05256556145084922, weights: 2.9169346005655825, elapsed: 15.052753273646037 minutes\n",
      "episode 2570/10000, Eps Reward: -721.5608789899196, Epsilon: 0.05196417622794278, weights: 52.49239196628332, elapsed: 15.160604854424795 minutes\n",
      "episode 2580/10000, Eps Reward: -527.1256608631295, Epsilon: 0.051369671254696894, weights: 65.58249320834875, elapsed: 15.325769305229187 minutes\n",
      "episode 2590/10000, Eps Reward: -936.26666006793, Epsilon: 0.05078196781644821, weights: 12.260853879153728, elapsed: 15.370908315976461 minutes\n",
      "episode 2600/10000, Eps Reward: -969.0784747336186, Epsilon: 0.050200988099081766, weights: 22.645179064944386, elapsed: 15.397420700391134 minutes\n",
      "episode 2610/10000, Eps Reward: -756.5714798472142, Epsilon: 0.04962665517872822, weights: 18.60760946571827, elapsed: 15.490859727064768 minutes\n",
      "episode 2620/10000, Eps Reward: -668.7289950235124, Epsilon: 0.04905889301157878, weights: 11.279956333339214, elapsed: 15.631565062204997 minutes\n",
      "episode 2630/10000, Eps Reward: -916.8588492023589, Epsilon: 0.048497626423816775, weights: 24.548390928655863, elapsed: 15.686968712011973 minutes\n",
      "episode 2640/10000, Eps Reward: -726.8451606952771, Epsilon: 0.047942781101664333, weights: 9.857922315597534, elapsed: 15.793760426839192 minutes\n",
      "episode 2650/10000, Eps Reward: -798.4044090199802, Epsilon: 0.04739428358154294, weights: 0.17957893677521497, elapsed: 15.856972519556681 minutes\n",
      "episode 2660/10000, Eps Reward: -599.9590214783016, Epsilon: 0.04685206124034663, weights: 14.741062998771667, elapsed: 16.039300147692362 minutes\n",
      "episode 2670/10000, Eps Reward: -377.3807093587636, Epsilon: 0.04631604228582642, weights: 34.98293947800994, elapsed: 16.232513070106506 minutes\n",
      "episode 2680/10000, Eps Reward: -805.0724101738199, Epsilon: 0.045786155747084674, weights: 15.445467649027705, elapsed: 16.3549446105957 minutes\n",
      "episode 2690/10000, Eps Reward: -757.3154202682146, Epsilon: 0.045262331465178426, weights: 2.09081294760108, elapsed: 16.44649735291799 minutes\n",
      "episode 2700/10000, Eps Reward: -878.6468938522312, Epsilon: 0.044744500083829936, weights: 5.954119707457721, elapsed: 16.531257001558938 minutes\n",
      "episode 2710/10000, Eps Reward: -853.7727700300557, Epsilon: 0.04423259304024377, weights: 57.66961678490043, elapsed: 16.62492067416509 minutes\n",
      "episode 2720/10000, Eps Reward: -922.4564823319422, Epsilon: 0.043726542556028744, weights: 20.992242824286222, elapsed: 16.6755828221639 minutes\n",
      "episode 2730/10000, Eps Reward: -709.5773750212127, Epsilon: 0.043226281628223874, weights: 7.353130051866174, elapsed: 16.79253747065862 minutes\n",
      "episode 2740/10000, Eps Reward: -575.6000077848886, Epsilon: 0.042731744020426926, weights: 0.20751804811879992, elapsed: 16.929026818275453 minutes\n",
      "episode 2750/10000, Eps Reward: -725.8611641125268, Epsilon: 0.04224286425402446, weights: 46.26131737977266, elapsed: 17.035807196299235 minutes\n",
      "episode 2760/10000, Eps Reward: -806.066575246169, Epsilon: 0.0417595775995222, weights: 19.10131916590035, elapsed: 17.09486178557078 minutes\n",
      "episode 2770/10000, Eps Reward: -738.1523852338979, Epsilon: 0.04128182006797467, weights: 33.342437006533146, elapsed: 17.196734376748402 minutes\n",
      "episode 2780/10000, Eps Reward: -725.0693858030421, Epsilon: 0.04080952840251274, weights: 13.166275290772319, elapsed: 17.307303190231323 minutes\n",
      "episode 2790/10000, Eps Reward: -853.8445362282882, Epsilon: 0.04034264006996824, weights: 4.2991406712681055, elapsed: 17.40140078465144 minutes\n",
      "episode 2800/10000, Eps Reward: -888.6939802197148, Epsilon: 0.03988109325259433, weights: 28.711138524115086, elapsed: 17.473973790804546 minutes\n",
      "episode 2810/10000, Eps Reward: -577.902941222009, Epsilon: 0.03942482683988056, weights: 0.04733016574755311, elapsed: 17.610110461711884 minutes\n",
      "episode 2820/10000, Eps Reward: -675.5094802209485, Epsilon: 0.03897378042046166, weights: 26.550313491374254, elapsed: 17.75016531944275 minutes\n",
      "episode 2830/10000, Eps Reward: -380.05703328038436, Epsilon: 0.03852789427411883, weights: 19.231292344629765, elapsed: 17.94272291660309 minutes\n",
      "episode 2840/10000, Eps Reward: -577.0368442623719, Epsilon: 0.038087109363872565, weights: 12.967147203162313, elapsed: 18.080725077788035 minutes\n",
      "episode 2850/10000, Eps Reward: -101.43664303196311, Epsilon: 0.037651367328165944, weights: 28.98435292392969, elapsed: 18.317542934417723 minutes\n",
      "episode 2860/10000, Eps Reward: -920.3814767249521, Epsilon: 0.037220610473137315, weights: 14.372831616550684, elapsed: 18.37122287750244 minutes\n",
      "episode 2870/10000, Eps Reward: -926.3006744691471, Epsilon: 0.03679478176498148, weights: 20.19351837038994, elapsed: 18.420750550429027 minutes\n",
      "episode 2880/10000, Eps Reward: -736.9158612941384, Epsilon: 0.036373824822398114, weights: 12.771815991029143, elapsed: 18.52147050698598 minutes\n",
      "episode 2890/10000, Eps Reward: -873.2772625224039, Epsilon: 0.035957683909126764, weights: 38.70308088324964, elapsed: 18.604875711599984 minutes\n",
      "episode 2900/10000, Eps Reward: -906.826395889348, Epsilon: 0.035546303926567095, weights: 20.982241954654455, elapsed: 18.666546138127647 minutes\n",
      "episode 2910/10000, Eps Reward: -721.9185128000958, Epsilon: 0.035139630406483664, weights: 26.863485168665648, elapsed: 18.836802438894907 minutes\n",
      "episode 2920/10000, Eps Reward: -979.38689270552, Epsilon: 0.03473760950379412, weights: 24.754844890907407, elapsed: 18.855539870262145 minutes\n",
      "episode 2930/10000, Eps Reward: -906.6178596349949, Epsilon: 0.034340187989439906, weights: 7.585644355043769, elapsed: 18.919102680683135 minutes\n",
      "episode 2940/10000, Eps Reward: -997.3154259573533, Epsilon: 0.03394731324333853, weights: 31.20181652903557, elapsed: 18.923373981316885 minutes\n",
      "episode 2950/10000, Eps Reward: -706.4941438622741, Epsilon: 0.033558933247416496, weights: 3.2384512410499156, elapsed: 19.046687507629393 minutes\n",
      "episode 2960/10000, Eps Reward: -490.3576171078653, Epsilon: 0.0331749965787219, weights: 54.62058889493346, elapsed: 19.233902192115785 minutes\n",
      "episode 2970/10000, Eps Reward: -309.1386431134527, Epsilon: 0.03279545240261584, weights: 0.5030961576849222, elapsed: 19.468890849749247 minutes\n",
      "episode 2980/10000, Eps Reward: -561.7000017090611, Epsilon: 0.0324202504660417, weights: 13.896319039165974, elapsed: 19.616826701164246 minutes\n",
      "episode 2990/10000, Eps Reward: -583.7474393294092, Epsilon: 0.032049341090871535, weights: 0.07799290074035525, elapsed: 19.80986911058426 minutes\n",
      "episode 3000/10000, Eps Reward: -876.8080309880849, Epsilon: 0.03168267516732841, weights: 56.02316727396101, elapsed: 19.88883695602417 minutes\n",
      "episode 3010/10000, Eps Reward: -365.222988372909, Epsilon: 0.03132020414748412, weights: 14.37675303593278, elapsed: 20.09164890845617 minutes\n",
      "episode 3020/10000, Eps Reward: -561.3359361998384, Epsilon: 0.030961880038831303, weights: 17.831562308594584, elapsed: 20.238568456967673 minutes\n",
      "episode 3030/10000, Eps Reward: -753.6401343514527, Epsilon: 0.030607655397928993, weights: 35.33340618759394, elapsed: 20.332703383763633 minutes\n",
      "episode 3040/10000, Eps Reward: -621.1138852126921, Epsilon: 0.03025748332412096, weights: 11.225886702537537, elapsed: 20.50124536752701 minutes\n",
      "episode 3050/10000, Eps Reward: -993.9943572631353, Epsilon: 0.029911317453325897, weights: 65.7421060577035, elapsed: 20.50859127442042 minutes\n",
      "episode 3060/10000, Eps Reward: -550.060356266468, Epsilon: 0.029569111951898618, weights: 0.01125801942544058, elapsed: 20.66254652738571 minutes\n",
      "episode 3070/10000, Eps Reward: -159.84477870090655, Epsilon: 0.02923082151056155, weights: 17.557937319390476, elapsed: 20.923516515890757 minutes\n",
      "episode 3080/10000, Eps Reward: -456.1737593202446, Epsilon: 0.028896401338405594, weights: 10.326634962111712, elapsed: 21.07089635133743 minutes\n",
      "episode 3090/10000, Eps Reward: -373.03767658441325, Epsilon: 0.028565807156959624, weights: 20.62689427100122, elapsed: 21.268141690889994 minutes\n",
      "episode 3100/10000, Eps Reward: -963.7936427871513, Epsilon: 0.028238995194327897, weights: 13.750912552699447, elapsed: 21.298782908916472 minutes\n",
      "episode 3110/10000, Eps Reward: -480.02821204578277, Epsilon: 0.027915922179394446, weights: 12.371513232588768, elapsed: 21.49612549940745 minutes\n",
      "episode 3120/10000, Eps Reward: -405.4887394725044, Epsilon: 0.027596545336093882, weights: 24.183149570133537, elapsed: 21.675081904729208 minutes\n",
      "episode 3130/10000, Eps Reward: -866.463396099779, Epsilon: 0.02728082237774761, weights: 31.899854513816535, elapsed: 21.761026461919148 minutes\n",
      "episode 3140/10000, Eps Reward: -767.3127032588504, Epsilon: 0.02696871150146498, weights: 28.686055839061737, elapsed: 21.844611529509226 minutes\n",
      "episode 3150/10000, Eps Reward: -644.7797436217714, Epsilon: 0.026660171382608393, weights: 6.947463491931558, elapsed: 21.999361606438956 minutes\n",
      "episode 3160/10000, Eps Reward: -550.8690866193142, Epsilon: 0.026355161169321777, weights: 8.61025781929493, elapsed: 22.150597667694093 minutes\n",
      "episode 3170/10000, Eps Reward: -413.9744759162838, Epsilon: 0.026053640477121665, weights: 35.89165423437953, elapsed: 22.325358907381695 minutes\n",
      "episode 3180/10000, Eps Reward: -525.3688027111978, Epsilon: 0.025755569383550093, weights: 17.529057126492262, elapsed: 22.49496247768402 minutes\n",
      "episode 3190/10000, Eps Reward: -805.664344983584, Epsilon: 0.02546090842288877, weights: 0.03622126404661685, elapsed: 22.55468947092692 minutes\n",
      "episode 3200/10000, Eps Reward: -714.4367028438385, Epsilon: 0.025169618580933653, weights: 32.91744979843497, elapsed: 22.666501077016196 minutes\n",
      "episode 3210/10000, Eps Reward: -994.4599732711682, Epsilon: 0.024881661289829313, weights: 19.942851096391678, elapsed: 22.674552937348682 minutes\n",
      "episode 3220/10000, Eps Reward: -893.1354774219651, Epsilon: 0.024596998422962417, weights: 6.51504611549899, elapsed: 22.745537078380586 minutes\n",
      "episode 3230/10000, Eps Reward: -522.3497543218607, Epsilon: 0.024315592289913614, weights: 0.007663496304303408, elapsed: 22.916694688796998 minutes\n",
      "episode 3240/10000, Eps Reward: 87.26882379515295, Epsilon: 0.024037405631467182, weights: 26.073912121355534, elapsed: 23.20631757179896 minutes\n",
      "episode 3250/10000, Eps Reward: 204.4524354649875, Epsilon: 0.0237624016146778, weights: 0.06590105376380961, elapsed: 23.56419417858124 minutes\n",
      "episode 3260/10000, Eps Reward: -690.0858840590016, Epsilon: 0.023490543827993683, weights: 51.57867310941219, elapsed: 23.692508312066398 minutes\n",
      "episode 3270/10000, Eps Reward: -942.37602301124, Epsilon: 0.023221796276435606, weights: 27.533280486240983, elapsed: 23.733195054531098 minutes\n",
      "episode 3280/10000, Eps Reward: -940.0072942212724, Epsilon: 0.02295612337683098, weights: 11.482030149549246, elapsed: 23.773710191249847 minutes\n",
      "episode 3290/10000, Eps Reward: -991.2771399266843, Epsilon: 0.022693489953102556, weights: 21.164688654243946, elapsed: 23.783567921320596 minutes\n",
      "episode 3300/10000, Eps Reward: -616.6510524065908, Epsilon: 0.022433861231610962, weights: 16.03363944031298, elapsed: 23.897091511885325 minutes\n",
      "episode 3310/10000, Eps Reward: -459.8592336680276, Epsilon: 0.022177202836550544, weights: 33.23435625806451, elapsed: 24.042955148220063 minutes\n",
      "episode 3320/10000, Eps Reward: -698.5936898891163, Epsilon: 0.021923480785397888, weights: 22.29010260477662, elapsed: 24.168382259209952 minutes\n",
      "episode 3330/10000, Eps Reward: -903.4182578723139, Epsilon: 0.021672661484412395, weights: 32.81210208311677, elapsed: 24.229018286863962 minutes\n",
      "episode 3340/10000, Eps Reward: -639.9674565100966, Epsilon: 0.021424711724188365, weights: 9.271498104557395, elapsed: 24.38913151820501 minutes\n",
      "episode 3350/10000, Eps Reward: -234.2396896789815, Epsilon: 0.021179598675257937, weights: 0.020464860514039174, elapsed: 24.607350595792134 minutes\n",
      "episode 3360/10000, Eps Reward: -100.63448913451364, Epsilon: 0.020937289883744336, weights: 45.97271293960512, elapsed: 24.844343558947244 minutes\n",
      "episode 3370/10000, Eps Reward: -590.0836631005034, Epsilon: 0.02069775326706488, weights: 0.15676485584117472, elapsed: 24.973658462365467 minutes\n",
      "episode 3380/10000, Eps Reward: -603.8913869757868, Epsilon: 0.0204609571096831, weights: 0.008163771708495915, elapsed: 25.09430211385091 minutes\n",
      "episode 3390/10000, Eps Reward: -444.4290870358697, Epsilon: 0.020226870058909534, weights: 61.71973502263427, elapsed: 25.318354868888854 minutes\n",
      "episode 3400/10000, Eps Reward: -404.96209223187526, Epsilon: 0.01999546112075045, weights: 0.6635739740449935, elapsed: 25.50677305062612 minutes\n",
      "episode 3410/10000, Eps Reward: -607.8692680224837, Epsilon: 0.019766699655804174, weights: 0.02827840531244874, elapsed: 25.632365492979684 minutes\n",
      "episode 3420/10000, Eps Reward: -563.9021716277201, Epsilon: 0.019540555375204303, weights: 0.016261898446828127, elapsed: 25.77719033161799 minutes\n",
      "episode 3430/10000, Eps Reward: -513.2098101221034, Epsilon: 0.019316998336609346, weights: 16.776848847046494, elapsed: 25.948340264956155 minutes\n",
      "episode 3440/10000, Eps Reward: -893.4607555847876, Epsilon: 0.019095998940238255, weights: 11.268616575747728, elapsed: 26.016204702854157 minutes\n",
      "episode 3450/10000, Eps Reward: -752.0879340451422, Epsilon: 0.018877527924951284, weights: 19.708654483780265, elapsed: 26.106839311122894 minutes\n",
      "episode 3460/10000, Eps Reward: -589.2761966980199, Epsilon: 0.018661556364375737, weights: 5.3564064260572195, elapsed: 26.241759049892426 minutes\n",
      "episode 3470/10000, Eps Reward: -320.07281051504253, Epsilon: 0.01844805566307599, weights: 0.017156075569801033, elapsed: 26.48256154457728 minutes\n",
      "episode 3480/10000, Eps Reward: -637.5085960283865, Epsilon: 0.018236997552767347, weights: 16.828469924628735, elapsed: 26.641957823435465 minutes\n",
      "episode 3490/10000, Eps Reward: -375.41968525265133, Epsilon: 0.018028354088573197, weights: 30.74994572252035, elapsed: 26.839157509803773 minutes\n",
      "episode 3500/10000, Eps Reward: -393.8860017292617, Epsilon: 0.017822097645325073, weights: 36.7175277620554, elapsed: 27.022282032171884 minutes\n",
      "episode 3510/10000, Eps Reward: 72.72140958065393, Epsilon: 0.017618200913904904, weights: 0.044849727768450975, elapsed: 27.306012852986655 minutes\n",
      "episode 3520/10000, Eps Reward: -39.610125873347656, Epsilon: 0.01741663689762922, weights: 42.46415075659752, elapsed: 27.583863468964896 minutes\n",
      "episode 3530/10000, Eps Reward: -694.736693472576, Epsilon: 0.017217378908674696, weights: 7.852644210681319, elapsed: 27.70947133700053 minutes\n",
      "episode 3540/10000, Eps Reward: -763.4855388032194, Epsilon: 0.01702040056454458, weights: 28.232564290985465, elapsed: 27.794742997487386 minutes\n",
      "episode 3550/10000, Eps Reward: -748.674531545533, Epsilon: 0.016825675784575538, weights: 0.036970744957216084, elapsed: 27.8905708193779 minutes\n",
      "episode 3560/10000, Eps Reward: -719.8021722139704, Epsilon: 0.016633178786484498, weights: 47.87104428559542, elapsed: 28.001442619164784 minutes\n",
      "episode 3570/10000, Eps Reward: -617.8245051797543, Epsilon: 0.01644288408295497, weights: 0.9635506849735975, elapsed: 28.11533059279124 minutes\n",
      "episode 3580/10000, Eps Reward: -566.146769117833, Epsilon: 0.016254766478262423, weights: 57.740713629405946, elapsed: 28.260386315981545 minutes\n",
      "episode 3590/10000, Eps Reward: -221.93068430791104, Epsilon: 0.01606880106493829, weights: 0.0054602488307864405, elapsed: 28.488661062717437 minutes\n",
      "episode 3600/10000, Eps Reward: 83.65553585793847, Epsilon: 0.01588496322047214, weights: 31.66225156188011, elapsed: 28.837529786427815 minutes\n",
      "episode 3610/10000, Eps Reward: 288.1640085787798, Epsilon: 0.015703228604051527, weights: 0.02377169771352783, elapsed: 29.19036299387614 minutes\n",
      "episode 3620/10000, Eps Reward: -214.94808116241538, Epsilon: 0.015523573153339206, weights: 57.05893108807504, elapsed: 29.421775635083517 minutes\n",
      "episode 3630/10000, Eps Reward: -415.6399160676395, Epsilon: 0.015345973081287191, weights: 23.151002809405327, elapsed: 29.592504437764486 minutes\n",
      "episode 3640/10000, Eps Reward: -440.4658868871966, Epsilon: 0.015170404872987243, weights: 0.060492523305583745, elapsed: 29.751340488592785 minutes\n",
      "episode 3650/10000, Eps Reward: -584.9693401313787, Epsilon: 0.014996845282557429, weights: 27.138617627788335, elapsed: 29.88633474508921 minutes\n",
      "episode 3660/10000, Eps Reward: -28.62791582655626, Epsilon: 0.014825271330064269, weights: 23.090960793197155, elapsed: 30.16887043317159 minutes\n",
      "episode 3670/10000, Eps Reward: -40.16207221323809, Epsilon: 0.014655660298480104, weights: 0.1613195936079137, elapsed: 30.444185268878936 minutes\n",
      "episode 3680/10000, Eps Reward: -237.55316134652168, Epsilon: 0.01448798973067529, weights: 0.0368339023552835, elapsed: 30.662049369017282 minutes\n",
      "episode 3690/10000, Eps Reward: -542.0148657039205, Epsilon: 0.014322237426444786, weights: 32.843398820608854, elapsed: 30.820545256137848 minutes\n",
      "episode 3700/10000, Eps Reward: -92.26693014703343, Epsilon: 0.014158381439568754, weights: 33.48463149089366, elapsed: 31.065391969680785 minutes\n",
      "episode 3710/10000, Eps Reward: -641.1411975459127, Epsilon: 0.013996400074906814, weights: 22.205758006311953, elapsed: 31.163933690388998 minutes\n",
      "episode 3720/10000, Eps Reward: -525.7094971150278, Epsilon: 0.01383627188552552, weights: 0.019180662697181106, elapsed: 31.333965361118317 minutes\n",
      "episode 3730/10000, Eps Reward: -490.7898014412996, Epsilon: 0.013677975669858705, weights: 20.693189997226, elapsed: 31.523918922742208 minutes\n",
      "episode 3740/10000, Eps Reward: -732.8658626712447, Epsilon: 0.013521490468900308, weights: 14.548940442269668, elapsed: 31.627191094557443 minutes\n",
      "episode 3750/10000, Eps Reward: -383.8397519476053, Epsilon: 0.013366795563429347, weights: 13.151328912004828, elapsed: 31.819475241502126 minutes\n",
      "episode 3760/10000, Eps Reward: -715.73105977026, Epsilon: 0.013213870471266596, weights: 12.792715212330222, elapsed: 31.934010354677834 minutes\n",
      "episode 3770/10000, Eps Reward: 74.73432748824605, Epsilon: 0.013062694944562673, weights: 0.0161364602172398, elapsed: 32.2159058491389 minutes\n",
      "episode 3780/10000, Eps Reward: -629.8292521860573, Epsilon: 0.012913248967117149, weights: 47.40021655196324, elapsed: 32.32012594540914 minutes\n",
      "episode 3790/10000, Eps Reward: -693.9104815236382, Epsilon: 0.012765512751728339, weights: 12.570089457090944, elapsed: 32.44699828227361 minutes\n",
      "episode 3800/10000, Eps Reward: -561.2342668387612, Epsilon: 0.012619466737573394, weights: 20.680954167153686, elapsed: 32.59726744890213 minutes\n",
      "episode 3810/10000, Eps Reward: -620.7123848161141, Epsilon: 0.012475091587618373, weights: 0.9869396621361375, elapsed: 32.71063946485519 minutes\n",
      "episode 3820/10000, Eps Reward: -604.605870141944, Epsilon: 0.012332368186057959, weights: 13.86396065657027, elapsed: 32.83434527715047 minutes\n",
      "episode 3830/10000, Eps Reward: -939.6526539858727, Epsilon: 0.01219127763578444, weights: 11.187498204410076, elapsed: 32.87581139008204 minutes\n",
      "episode 3840/10000, Eps Reward: -618.1893447659174, Epsilon: 0.012051801255885671, weights: 0.01931873243302107, elapsed: 32.98808428843816 minutes\n",
      "episode 3850/10000, Eps Reward: -410.72389762736327, Epsilon: 0.01191392057917166, weights: 14.45669137686491, elapsed: 33.16282184123993 minutes\n",
      "episode 3860/10000, Eps Reward: -267.34738915720436, Epsilon: 0.011777617349729427, weights: 27.549461798742414, elapsed: 33.36282828648885 minutes\n",
      "episode 3870/10000, Eps Reward: -521.4523245076487, Epsilon: 0.011642873520505864, weights: 16.354717193637043, elapsed: 33.53253450791041 minutes\n",
      "episode 3880/10000, Eps Reward: -560.7746869965081, Epsilon: 0.011509671250918235, weights: 87.68173074349761, elapsed: 33.676183716456094 minutes\n",
      "episode 3890/10000, Eps Reward: -776.316196860014, Epsilon: 0.01137799290449202, weights: 34.22742544580251, elapsed: 33.75568476120631 minutes\n",
      "episode 3900/10000, Eps Reward: -764.4931369346594, Epsilon: 0.011247821046525776, weights: 17.7152015902102, elapsed: 33.8408086736997 minutes\n",
      "episode 3910/10000, Eps Reward: -419.8774000952732, Epsilon: 0.011119138441782712, weights: 0.015470661106519401, elapsed: 34.015292811393735 minutes\n",
      "episode 3920/10000, Eps Reward: -0.45301232631528593, Epsilon: 0.0109919280522087, weights: 20.818606588058174, elapsed: 34.31761381228765 minutes\n",
      "episode 3930/10000, Eps Reward: -526.0632620204304, Epsilon: 0.010866173034676357, weights: 12.420083176344633, elapsed: 34.48709454536438 minutes\n",
      "episode 3940/10000, Eps Reward: -332.56579386451216, Epsilon: 0.010741856738754945, weights: 0.38832242193166167, elapsed: 34.71030166943868 minutes\n",
      "episode 3950/10000, Eps Reward: -386.5969338506703, Epsilon: 0.01061896270450582, weights: 0.005652137682773173, elapsed: 34.90085687637329 minutes\n",
      "episode 3960/10000, Eps Reward: 187.43879526621257, Epsilon: 0.010497474660303045, weights: 0.00899824732914567, elapsed: 35.2494233528773 minutes\n",
      "episode 3970/10000, Eps Reward: -240.2256875608773, Epsilon: 0.010377376520678987, weights: 17.71899051219225, elapsed: 35.46706597407659 minutes\n",
      "episode 3980/10000, Eps Reward: 200.2864916716146, Epsilon: 0.01025865238419453, weights: 0.024727513664402068, elapsed: 35.82445869048436 minutes\n",
      "episode 3990/10000, Eps Reward: 154.62217875299757, Epsilon: 0.010141286531333674, weights: 0.004539595654932782, elapsed: 36.21515677372614 minutes\n",
      "episode 4000/10000, Eps Reward: -817.9625546466787, Epsilon: 0.010025263422422208, weights: 0.016191604430787265, elapsed: 36.26635534365972 minutes\n",
      "episode 4010/10000, Eps Reward: -540.9970745611304, Epsilon: 0.009910567695570197, weights: 24.270294908434153, elapsed: 36.43119955062866 minutes\n",
      "episode 4020/10000, Eps Reward: -361.23833531508365, Epsilon: 0.00979718416463801, weights: 14.658406819449738, elapsed: 36.635621297359464 minutes\n",
      "episode 4030/10000, Eps Reward: -435.0124461917929, Epsilon: 0.009685097817225635, weights: 27.270232958719134, elapsed: 36.79749914010366 minutes\n",
      "episode 4040/10000, Eps Reward: 243.31649227527677, Epsilon: 0.009574293812684957, weights: 0.21206173254176974, elapsed: 37.12120482524236 minutes\n",
      "episode 4050/10000, Eps Reward: -102.1840898250971, Epsilon: 0.009464757480154823, weights: 38.150640103966, elapsed: 37.36061288118363 minutes\n",
      "episode 4060/10000, Eps Reward: 253.62583726572967, Epsilon: 0.009356474316618553, weights: 38.509223621338606, elapsed: 37.69037061134974 minutes\n",
      "episode 4070/10000, Eps Reward: 72.40186943942723, Epsilon: 0.009249429984983678, weights: 0.02684217761270702, elapsed: 37.97357223033905 minutes\n",
      "episode 4080/10000, Eps Reward: -53.62186794911345, Epsilon: 0.00914361031218368, weights: 5.2599022393114865, elapsed: 38.24148686726888 minutes\n",
      "episode 4090/10000, Eps Reward: -54.51505890120469, Epsilon: 0.009039001287301411, weights: 56.8658910356462, elapsed: 38.50598047971725 minutes\n",
      "episode 4100/10000, Eps Reward: -416.5475533307541, Epsilon: 0.008935589059713995, weights: 13.464121793396771, elapsed: 38.68076790571213 minutes\n",
      "episode 4110/10000, Eps Reward: -222.2182168998323, Epsilon: 0.00883335993725896, weights: 22.190891774371266, elapsed: 38.91038262844086 minutes\n",
      "episode 4120/10000, Eps Reward: -32.38708813972296, Epsilon: 0.008732300384421337, weights: 10.747451703064144, elapsed: 39.19806581735611 minutes\n",
      "episode 4130/10000, Eps Reward: -413.3650033716773, Epsilon: 0.008632397020541515, weights: 0.09507167906849645, elapsed: 39.37639500697454 minutes\n",
      "episode 4140/10000, Eps Reward: 105.9269966347922, Epsilon: 0.008533636618043586, weights: 0.00289715314283967, elapsed: 39.68244306643804 minutes\n",
      "episode 4150/10000, Eps Reward: 175.4042417003961, Epsilon: 0.008436006100683976, weights: 0.06023559087770991, elapsed: 40.0318932334582 minutes\n",
      "episode 4160/10000, Eps Reward: -177.56930449928964, Epsilon: 0.008339492541820084, weights: 0.00417029281379655, elapsed: 40.29050327936808 minutes\n",
      "episode 4170/10000, Eps Reward: -545.5990370561719, Epsilon: 0.008244083162698762, weights: 0.449213535990566, elapsed: 40.448803595701854 minutes\n",
      "episode 4180/10000, Eps Reward: -551.8710773915891, Epsilon: 0.008149765330764353, weights: 30.701821266207844, elapsed: 40.60103826125463 minutes\n",
      "episode 4190/10000, Eps Reward: -635.0371224846109, Epsilon: 0.008056526557986098, weights: 5.092573373578489, elapsed: 40.7049448688825 minutes\n",
      "episode 4200/10000, Eps Reward: -388.753958460895, Epsilon: 0.007964354499204676, weights: 9.175504602259025, elapsed: 40.89354076385498 minutes\n",
      "episode 4210/10000, Eps Reward: -29.900692595803115, Epsilon: 0.007873236950497646, weights: 0.03018452279502526, elapsed: 41.17941660483678 minutes\n",
      "episode 4220/10000, Eps Reward: -429.3850320268251, Epsilon: 0.007783161847563616, weights: 11.860554854385555, elapsed: 41.34593394597371 minutes\n",
      "episode 4230/10000, Eps Reward: 249.56234660421646, Epsilon: 0.007694117264124883, weights: 41.18144085910171, elapsed: 41.67288340727488 minutes\n",
      "episode 4240/10000, Eps Reward: -961.7611519795864, Epsilon: 0.0076060914103483444, weights: 26.30814934335649, elapsed: 41.70261470079422 minutes\n",
      "episode 4250/10000, Eps Reward: -593.356267716494, Epsilon: 0.007519072631284485, weights: 17.427867911290377, elapsed: 41.82823904355367 minutes\n",
      "episode 4260/10000, Eps Reward: -287.62601858066665, Epsilon: 0.007433049405324216, weights: 3.1814820023137145, elapsed: 42.014870707194014 minutes\n",
      "episode 4270/10000, Eps Reward: -77.95751187470206, Epsilon: 0.007348010342673371, weights: 0.004564870265312493, elapsed: 42.2678936402003 minutes\n",
      "episode 4280/10000, Eps Reward: -294.47031745466825, Epsilon: 0.007263944183844659, weights: 29.662382761016488, elapsed: 42.51445534626643 minutes\n",
      "episode 4290/10000, Eps Reward: 67.28484956320233, Epsilon: 0.00718083979816686, weights: 0.02710224367910996, elapsed: 42.792314632733664 minutes\n",
      "episode 4300/10000, Eps Reward: -28.276657813453642, Epsilon: 0.007098686182311086, weights: 0.0043688148725777864, elapsed: 43.07782122691472 minutes\n",
      "episode 4310/10000, Eps Reward: 78.94044138397939, Epsilon: 0.007017472458833904, weights: 0.015859973791521043, elapsed: 43.36737049023311 minutes\n",
      "episode 4320/10000, Eps Reward: -258.350422769478, Epsilon: 0.0069371878747371135, weights: 20.598821885883808, elapsed: 43.5751118183136 minutes\n",
      "episode 4330/10000, Eps Reward: -392.83483997602804, Epsilon: 0.006857821800044016, weights: 0.02613935840781778, elapsed: 43.76404871543249 minutes\n",
      "episode 4340/10000, Eps Reward: 86.09034284912326, Epsilon: 0.006779363726391965, weights: 0.014264718629419804, elapsed: 44.053180662790936 minutes\n",
      "episode 4350/10000, Eps Reward: 241.39126400102887, Epsilon: 0.006701803265641017, weights: 62.678266521543264, elapsed: 44.37744066317876 minutes\n",
      "episode 4360/10000, Eps Reward: -110.76170033188755, Epsilon: 0.006625130148498509, weights: 0.8830994910094887, elapsed: 44.61013907988866 minutes\n",
      "episode 4370/10000, Eps Reward: -281.00575391594856, Epsilon: 0.006549334223159361, weights: 22.0254115331918, elapsed: 44.80205252965291 minutes\n",
      "episode 4380/10000, Eps Reward: 436.84763674390507, Epsilon: 0.00647440545396194, weights: 0.03523542304174043, elapsed: 45.18225205739339 minutes\n",
      "episode 4390/10000, Eps Reward: -272.5783873128015, Epsilon: 0.006400333920059304, weights: 0.02058953046798706, elapsed: 45.380302556355794 minutes\n",
      "episode 4400/10000, Eps Reward: 64.80970101524451, Epsilon: 0.006327109814105645, weights: 0.014178550336509943, elapsed: 45.65795338948568 minutes\n",
      "episode 4410/10000, Eps Reward: -463.24558015152326, Epsilon: 0.006254723440957754, weights: 0.0040349447226617485, elapsed: 45.80269472201665 minutes\n",
      "episode 4420/10000, Eps Reward: -610.0263381157009, Epsilon: 0.006183165216391359, weights: 12.066811122000217, elapsed: 45.920517245928444 minutes\n",
      "episode 4430/10000, Eps Reward: 247.4083884568262, Epsilon: 0.006112425665832124, weights: 0.008450736291706562, elapsed: 46.24721980492274 minutes\n",
      "episode 4440/10000, Eps Reward: 68.46506532508856, Epsilon: 0.006042495423101193, weights: 15.365425052586943, elapsed: 46.525733017921446 minutes\n",
      "episode 4450/10000, Eps Reward: 69.5296346280077, Epsilon: 0.005973365229175067, weights: 35.46235361509025, elapsed: 46.803736527760826 minutes\n",
      "episode 4460/10000, Eps Reward: -219.4338458324136, Epsilon: 0.005905025930959675, weights: 6.586981445550919, elapsed: 47.029891057809195 minutes\n",
      "episode 4470/10000, Eps Reward: -285.8283250675499, Epsilon: 0.005837468480078472, weights: 70.56503923423588, elapsed: 47.21772778828939 minutes\n",
      "episode 4480/10000, Eps Reward: 423.28878770434204, Epsilon: 0.005770683931674401, weights: 0.02560122500290163, elapsed: 47.586898636817935 minutes\n",
      "episode 4490/10000, Eps Reward: 245.29699334018056, Epsilon: 0.005704663443225558, weights: 0.05209810344967991, elapsed: 47.911925872166954 minutes\n",
      "episode 4500/10000, Eps Reward: 67.18620816349717, Epsilon: 0.005639398273374414, weights: 18.87249694764614, elapsed: 48.191465922196706 minutes\n",
      "episode 4510/10000, Eps Reward: -601.7495462189066, Epsilon: 0.005574879780770417, weights: 3.5815256098285317, elapsed: 48.31799666881561 minutes\n",
      "episode 4520/10000, Eps Reward: -748.1082123843117, Epsilon: 0.005511099422925859, weights: 13.17367659183219, elapsed: 48.41858952840169 minutes\n",
      "episode 4530/10000, Eps Reward: -188.97180988741593, Epsilon: 0.005448048755084808, weights: 0.03357936890097335, elapsed: 48.667203879356386 minutes\n",
      "episode 4540/10000, Eps Reward: -31.54823714401806, Epsilon: 0.0053857194291049935, weights: 34.68463076651096, elapsed: 48.9467928647995 minutes\n",
      "episode 4550/10000, Eps Reward: 248.22543515826746, Epsilon: 0.005324103192352488, weights: 0.02473567659035325, elapsed: 49.27493031422297 minutes\n",
      "episode 4560/10000, Eps Reward: -68.08445276257534, Epsilon: 0.00526319188660902, weights: 18.204537723213434, elapsed: 49.53663514057795 minutes\n",
      "episode 4570/10000, Eps Reward: -285.23470963494356, Epsilon: 0.005202977446991794, weights: 0.001445845642592758, elapsed: 49.72392072280248 minutes\n",
      "episode 4580/10000, Eps Reward: 128.99834094664976, Epsilon: 0.005143451900885678, weights: 0.0924056937219575, elapsed: 50.04001980622609 minutes\n",
      "episode 4590/10000, Eps Reward: -582.5998013334008, Epsilon: 0.005084607366887597, weights: 19.19170767813921, elapsed: 50.17221720616023 minutes\n",
      "episode 4600/10000, Eps Reward: -209.29121047398627, Epsilon: 0.005026436053763003, weights: 0.0205173579743132, elapsed: 50.409567753473915 minutes\n",
      "episode 4610/10000, Eps Reward: -105.56261038073792, Epsilon: 0.0049689302594142885, weights: 14.283733169548213, elapsed: 50.65354988177617 minutes\n",
      "episode 4620/10000, Eps Reward: -46.767432651609056, Epsilon: 0.0049120823698609985, weights: 0.007896310184150934, elapsed: 50.92833806276322 minutes\n",
      "episode 4630/10000, Eps Reward: 252.04505891494426, Epsilon: 0.004855884858231718, weights: 0.009222799388226122, elapsed: 51.25757602055867 minutes\n",
      "episode 4640/10000, Eps Reward: 61.908835528734144, Epsilon: 0.004800330283767478, weights: 0.08004393591545522, elapsed: 51.536938440799716 minutes\n",
      "episode 4650/10000, Eps Reward: 74.14862502198717, Epsilon: 0.004745411290836575, weights: 22.032518580555916, elapsed: 51.82004593610763 minutes\n",
      "episode 4660/10000, Eps Reward: -218.55909170806916, Epsilon: 0.004691120607960658, weights: 0.00921821070369333, elapsed: 52.04815239906311 minutes\n",
      "episode 4670/10000, Eps Reward: 598.9442627288066, Epsilon: 0.00463745104685196, weights: 0.016758555284468457, elapsed: 52.464428067207336 minutes\n",
      "episode 4680/10000, Eps Reward: 421.2668241519855, Epsilon: 0.004584395501461532, weights: 8.31215088069439, elapsed: 52.83442862431208 minutes\n",
      "episode 4690/10000, Eps Reward: 420.90571930972, Epsilon: 0.004531946947038394, weights: 0.004887078306637704, elapsed: 53.20424455801646 minutes\n",
      "episode 4700/10000, Eps Reward: 138.42396808143704, Epsilon: 0.00448009843919941, weights: 0.003938665788155049, elapsed: 53.5295102874438 minutes\n",
      "episode 4710/10000, Eps Reward: 421.3341719464831, Epsilon: 0.004428843113009848, weights: 0.007360312796663493, elapsed: 53.90080873568853 minutes\n",
      "episode 4720/10000, Eps Reward: -282.462774058245, Epsilon: 0.00437817418207442, weights: 25.921050174161792, elapsed: 54.093212350209555 minutes\n",
      "episode 4730/10000, Eps Reward: -207.54395943287665, Epsilon: 0.0043280849376387456, weights: 0.002048977301456034, elapsed: 54.331292692820234 minutes\n",
      "episode 4740/10000, Eps Reward: 419.6247314609971, Epsilon: 0.004278568747701087, weights: 0.005281282356008887, elapsed: 54.70094941457113 minutes\n",
      "episode 4750/10000, Eps Reward: 420.10414829463264, Epsilon: 0.004229619056134248, weights: 0.00553523248527199, elapsed: 55.070613098144534 minutes\n",
      "episode 4760/10000, Eps Reward: 80.90123348498781, Epsilon: 0.004181229381817516, weights: 0.09763111127540469, elapsed: 55.36010268529256 minutes\n",
      "episode 4770/10000, Eps Reward: -453.50837223851386, Epsilon: 0.004133393317778545, weights: 13.340716240927577, elapsed: 55.51096493800481 minutes\n",
      "episode 4780/10000, Eps Reward: -106.40684296005286, Epsilon: 0.004086104530345035, weights: 11.683371188119054, elapsed: 55.74753098885218 minutes\n",
      "episode 4790/10000, Eps Reward: 247.1471105167115, Epsilon: 0.0040393567583061445, weights: 16.803575843572617, elapsed: 56.0733033935229 minutes\n",
      "episode 4800/10000, Eps Reward: 70.90832081348742, Epsilon: 0.003993143812083473, weights: 0.011247539485339075, elapsed: 56.35484511852265 minutes\n",
      "episode 4810/10000, Eps Reward: -26.595583964664435, Epsilon: 0.003947459572911544, weights: 23.070899901911616, elapsed: 56.64023449420929 minutes\n",
      "episode 4820/10000, Eps Reward: 72.06809041098933, Epsilon: 0.003902297992027655, weights: 31.256401106715202, elapsed: 56.92486588160197 minutes\n",
      "episode 4830/10000, Eps Reward: -90.17472666750803, Epsilon: 0.003857653089870997, weights: 14.320717126131058, elapsed: 57.17343322038651 minutes\n",
      "episode 4840/10000, Eps Reward: -285.231722273728, Epsilon: 0.003813518955290944, weights: 27.097711712121964, elapsed: 57.361806027094524 minutes\n",
      "episode 4850/10000, Eps Reward: -416.6900867217156, Epsilon: 0.0037698897447643897, weights: 10.728141487576067, elapsed: 57.536221015453336 minutes\n",
      "episode 4860/10000, Eps Reward: 66.59715683071819, Epsilon: 0.0037267596816220466, weights: 0.007091826875694096, elapsed: 57.81501984198888 minutes\n",
      "episode 4870/10000, Eps Reward: -57.51730934211595, Epsilon: 0.00368412305528359, weights: 0.04205660836305469, elapsed: 58.080896536509194 minutes\n",
      "episode 4880/10000, Eps Reward: 103.72494847850567, Epsilon: 0.003641974220501559, weights: 23.229535304009914, elapsed: 58.38184417883555 minutes\n",
      "episode 4890/10000, Eps Reward: -424.24450221236214, Epsilon: 0.0036003075966139055, weights: 21.808422178030014, elapsed: 58.550111305713656 minutes\n",
      "episode 4900/10000, Eps Reward: -251.31898384120777, Epsilon: 0.0035591176668050904, weights: 9.162113703787327, elapsed: 58.76343582868576 minutes\n",
      "episode 4910/10000, Eps Reward: -110.63711938270035, Epsilon: 0.0035183989773756395, weights: 8.431732146535069, elapsed: 58.998999957243605 minutes\n",
      "episode 4920/10000, Eps Reward: 345.6213567443757, Epsilon: 0.003478146137020052, weights: 0.03662362624891102, elapsed: 59.38492687145869 minutes\n",
      "episode 4930/10000, Eps Reward: -60.46601203012136, Epsilon: 0.0034383538161129727, weights: 0.031007722369395196, elapsed: 59.64640856981278 minutes\n",
      "episode 4940/10000, Eps Reward: -213.1054756520029, Epsilon: 0.0033990167460035284, weights: 19.201501273084432, elapsed: 59.87751053571701 minutes\n",
      "episode 4950/10000, Eps Reward: -326.80238047164863, Epsilon: 0.003360129718317742, weights: 0.006349365110509098, elapsed: 60.10206513007482 minutes\n",
      "episode 4960/10000, Eps Reward: -452.7291032831152, Epsilon: 0.003321687584268921, weights: 43.18841286934912, elapsed: 60.2529554883639 minutes\n",
      "episode 4970/10000, Eps Reward: 69.08097359420239, Epsilon: 0.00328368525397594, weights: 0.02644564479123801, elapsed: 60.53575622638066 minutes\n",
      "episode 4980/10000, Eps Reward: -243.97078439548415, Epsilon: 0.0032461176957893235, weights: 16.622904416173697, elapsed: 60.750726997852325 minutes\n",
      "episode 4990/10000, Eps Reward: -212.85908477761615, Epsilon: 0.003208979935625034, weights: 19.943877697456628, elapsed: 60.985336037476856 minutes\n",
      "episode 5000/10000, Eps Reward: -634.1415483707904, Epsilon: 0.003172267056305888, weights: 30.031691819429398, elapsed: 61.087364264329274 minutes\n",
      "episode 5010/10000, Eps Reward: -464.9844587168794, Epsilon: 0.0031359741969104998, weights: 21.223975494503975, elapsed: 61.23146820465724 minutes\n",
      "episode 5020/10000, Eps Reward: -641.7717422648922, Epsilon: 0.00310009655212968, weights: 27.648439031094313, elapsed: 61.32950011491776 minutes\n",
      "episode 5030/10000, Eps Reward: -580.4276793456536, Epsilon: 0.0030646293716301955, weights: 0.009307906497269869, elapsed: 61.465258502960204 minutes\n",
      "episode 5040/10000, Eps Reward: 254.98039359201803, Epsilon: 0.003029567959425804, weights: 0.028050151653587818, elapsed: 61.80035202503204 minutes\n",
      "episode 5050/10000, Eps Reward: 471.2575072874547, Epsilon: 0.0029949076732554924, weights: 0.0025498299510218203, elapsed: 62.20292944113414 minutes\n",
      "episode 5060/10000, Eps Reward: 65.56132263595377, Epsilon: 0.002960643923968822, weights: 0.016151761170476675, elapsed: 62.48155900637309 minutes\n",
      "episode 5070/10000, Eps Reward: -111.31182263152353, Epsilon: 0.0029267721749183058, weights: 0.021998224139679223, elapsed: 62.716133042176565 minutes\n",
      "episode 5080/10000, Eps Reward: 244.8931883707256, Epsilon: 0.002893287941358746, weights: 0.010940963169559836, elapsed: 63.04033952156703 minutes\n",
      "episode 5090/10000, Eps Reward: 64.53351688689068, Epsilon: 0.00286018678985343, weights: 26.977864734828472, elapsed: 63.319653097788496 minutes\n",
      "episode 5100/10000, Eps Reward: 614.5884786136426, Epsilon: 0.00282746433768713, weights: 0.005174346821149811, elapsed: 63.74904695749283 minutes\n",
      "episode 5110/10000, Eps Reward: 248.5630305089443, Epsilon: 0.002795116252285817, weights: 1.4518688321113586, elapsed: 64.08025752305984 minutes\n",
      "episode 5120/10000, Eps Reward: 137.45877386958267, Epsilon: 0.0027631382506430094, weights: 9.026859138160944, elapsed: 64.40261037349701 minutes\n",
      "episode 5130/10000, Eps Reward: 244.77214677616902, Epsilon: 0.0027315260987526876, weights: 0.006979465688345954, elapsed: 64.73057909806569 minutes\n",
      "episode 5140/10000, Eps Reward: 66.80233867100202, Epsilon: 0.002700275611048696, weights: 17.442731782794, elapsed: 65.01066204309464 minutes\n",
      "episode 5150/10000, Eps Reward: -285.4539975192089, Epsilon: 0.0026693826498505584, weights: 0.020451888907700777, elapsed: 65.19668294588725 minutes\n",
      "episode 5160/10000, Eps Reward: -421.1334660726226, Epsilon: 0.0026388431248156358, weights: 27.92519024759531, elapsed: 65.36599586009979 minutes\n",
      "episode 5170/10000, Eps Reward: -106.01203979401248, Epsilon: 0.002608652992397545, weights: 0.013159951893612742, elapsed: 65.60280493895213 minutes\n",
      "episode 5180/10000, Eps Reward: -639.6695835633831, Epsilon: 0.002578808255310784, weights: 31.619955668225884, elapsed: 65.70106030702591 minutes\n",
      "episode 5190/10000, Eps Reward: -280.5437672235418, Epsilon: 0.0025493049620014725, weights: 32.328665882349014, elapsed: 65.89400618076324 minutes\n",
      "episode 5200/10000, Eps Reward: -643.8730983551095, Epsilon: 0.0025201392061241514, weights: 29.16270600259304, elapsed: 65.9897712389628 minutes\n",
      "episode 5210/10000, Eps Reward: -109.6933513875967, Epsilon: 0.0024913071260245713, weights: 0.006257156375795603, elapsed: 66.22477663755417 minutes\n",
      "episode 5220/10000, Eps Reward: -462.15194830243036, Epsilon: 0.002462804904228394, weights: 13.752024356275797, elapsed: 66.36750833590825 minutes\n",
      "episode 5230/10000, Eps Reward: 90.45788566995506, Epsilon: 0.002434628766935741, weights: 23.83627412840724, elapsed: 66.66112395922343 minutes\n",
      "episode 5240/10000, Eps Reward: 423.3474009725488, Epsilon: 0.0024067749835215346, weights: 0.014947531977668405, elapsed: 67.03063507080078 minutes\n",
      "episode 5250/10000, Eps Reward: 425.218437893668, Epsilon: 0.002379239866041545, weights: 0.004942064406350255, elapsed: 67.39980107148489 minutes\n",
      "episode 5260/10000, Eps Reward: 255.1287995531913, Epsilon: 0.002352019768744093, weights: 0.002860653097741306, elapsed: 67.73492993513743 minutes\n",
      "episode 5270/10000, Eps Reward: 282.4451577222361, Epsilon: 0.0023251110875873414, weights: 12.87072667106986, elapsed: 68.08445653120677 minutes\n",
      "episode 5280/10000, Eps Reward: -104.43395469183083, Epsilon: 0.002298510259762104, weights: 6.975856704637408, elapsed: 68.31988568703333 minutes\n",
      "episode 5290/10000, Eps Reward: 602.2282555491905, Epsilon: 0.002272213763220118, weights: 0.0049141631461679935, elapsed: 68.73513962427775 minutes\n",
      "episode 5300/10000, Eps Reward: 139.54606440125198, Epsilon: 0.0022462181162077118, weights: 24.842842109501362, elapsed: 69.0561511238416 minutes\n",
      "episode 5310/10000, Eps Reward: -288.5473453297567, Epsilon: 0.0022205198768048056, weights: 5.003063310869038, elapsed: 69.24623920917512 minutes\n",
      "episode 5320/10000, Eps Reward: 63.99130554515283, Epsilon: 0.002195115642469192, weights: 0.005752015073085204, elapsed: 69.52560615539551 minutes\n",
      "episode 5330/10000, Eps Reward: -36.71546119099778, Epsilon: 0.0021700020495860244, weights: 10.580317789688706, elapsed: 69.80364802281062 minutes\n",
      "episode 5340/10000, Eps Reward: 632.911933877567, Epsilon: 0.002145175773022461, weights: 0.02149524458218366, elapsed: 70.2408428033193 minutes\n",
      "episode 5350/10000, Eps Reward: -413.340845300441, Epsilon: 0.002120633525687409, weights: 10.449590458651073, elapsed: 70.41978890101115 minutes\n",
      "episode 5360/10000, Eps Reward: 420.2989114967146, Epsilon: 0.002096372058096297, weights: 0.004412184236571193, elapsed: 70.78830712238947 minutes\n",
      "episode 5370/10000, Eps Reward: -39.03130052733185, Epsilon: 0.0020723881579408324, weights: 7.099731974303722, elapsed: 71.06481950680414 minutes\n",
      "episode 5380/10000, Eps Reward: 250.93361885078002, Epsilon: 0.002048678649663683, weights: 12.77704438753426, elapsed: 71.39282590945562 minutes\n",
      "episode 5390/10000, Eps Reward: 421.276973260916, Epsilon: 0.0020252403940380164, weights: 0.0027026160969398916, elapsed: 71.76472943623861 minutes\n",
      "episode 5400/10000, Eps Reward: -288.5111326531613, Epsilon: 0.002002070287751859, weights: 39.78726679831743, elapsed: 71.95263261000315 minutes\n",
      "episode 5410/10000, Eps Reward: 455.266728707355, Epsilon: 0.001979165262997204, weights: 0.0035079597146250308, elapsed: 72.34431292215983 minutes\n",
      "episode 5420/10000, Eps Reward: -286.8647994189645, Epsilon: 0.0019565222870638224, weights: 17.688108012080193, elapsed: 72.53405472040177 minutes\n",
      "episode 5430/10000, Eps Reward: -63.708477629642935, Epsilon: 0.0019341383619377206, weights: 5.390990344807506, elapsed: 72.7989651441574 minutes\n",
      "episode 5440/10000, Eps Reward: -106.48227299927382, Epsilon: 0.001912010523904193, weights: 0.029936664504930377, elapsed: 73.03715102275213 minutes\n",
      "episode 5450/10000, Eps Reward: -456.31339828327873, Epsilon: 0.0018901358431554153, weights: 7.272979664616287, elapsed: 73.18749245802562 minutes\n",
      "episode 5460/10000, Eps Reward: -109.44836638136447, Epsilon: 0.0018685114234025257, weights: 0.003854336100630462, elapsed: 73.42024945815405 minutes\n",
      "episode 5470/10000, Eps Reward: -111.33500713105263, Epsilon: 0.0018471344014921464, weights: 19.655642990022898, elapsed: 73.6534099260966 minutes\n",
      "episode 5480/10000, Eps Reward: -615.0785261461715, Epsilon: 0.001826001947027293, weights: 6.601544834673405, elapsed: 73.7671023607254 minutes\n",
      "episode 5490/10000, Eps Reward: 71.91486620417467, Epsilon: 0.0018051112619926165, weights: 0.004240750335156918, elapsed: 74.04603815873465 minutes\n",
      "episode 5500/10000, Eps Reward: -105.33613773811098, Epsilon: 0.001784459580383938, weights: 0.05563006130978465, elapsed: 74.28412346045177 minutes\n",
      "episode 5510/10000, Eps Reward: 86.40332851623388, Epsilon: 0.0017640441678420176, weights: 15.959556533489376, elapsed: 74.57934302488962 minutes\n",
      "episode 5520/10000, Eps Reward: 67.2999254256025, Epsilon: 0.0017438623212905175, weights: 37.13249522447586, elapsed: 74.85729448795318 minutes\n",
      "episode 5530/10000, Eps Reward: -40.9974054357632, Epsilon: 0.0017239113685781023, weights: 0.0006020944274496287, elapsed: 75.13127680619557 minutes\n",
      "episode 5540/10000, Eps Reward: -53.88994856180061, Epsilon: 0.0017041886681246376, weights: 0.0005384230462368578, elapsed: 75.39720839659373 minutes\n",
      "episode 5550/10000, Eps Reward: -283.9967384619582, Epsilon: 0.001684691608571434, weights: 15.323456279933453, elapsed: 75.58946500619253 minutes\n",
      "episode 5560/10000, Eps Reward: 242.40056144538204, Epsilon: 0.0016654176084354953, weights: 0.03345561370952055, elapsed: 75.91402310530344 minutes\n",
      "episode 5570/10000, Eps Reward: -108.72628298392492, Epsilon: 0.0016463641157677192, weights: 0.001106518873712048, elapsed: 76.14766442775726 minutes\n",
      "episode 5580/10000, Eps Reward: -110.04638548162409, Epsilon: 0.0016275286078150087, weights: 0.04724731022724882, elapsed: 76.38053086598714 minutes\n",
      "episode 5590/10000, Eps Reward: -380.91070016101384, Epsilon: 0.0016089085906862532, weights: 12.056215403601527, elapsed: 76.57505347331364 minutes\n",
      "episode 5600/10000, Eps Reward: 70.5462834910373, Epsilon: 0.0015905015990221262, weights: 7.309855610132217, elapsed: 76.85757007598878 minutes\n",
      "episode 5610/10000, Eps Reward: 244.4738673437245, Epsilon: 0.0015723051956686614, weights: 3.2547894809395075, elapsed: 77.18414822419484 minutes\n",
      "episode 5620/10000, Eps Reward: 65.89691064863698, Epsilon: 0.0015543169713545673, weights: 0.00337172114814166, elapsed: 77.46320368051529 minutes\n",
      "episode 5630/10000, Eps Reward: -114.99876661533217, Epsilon: 0.0015365345443722294, weights: 18.651470160111785, elapsed: 77.69760727485021 minutes\n",
      "episode 5640/10000, Eps Reward: 276.6784831118034, Epsilon: 0.001518955560262362, weights: 0.005064333789050579, elapsed: 78.04313377936681 minutes\n",
      "episode 5650/10000, Eps Reward: 456.02159015380187, Epsilon: 0.0015015776915022704, weights: 0.022909013787284493, elapsed: 78.43499876658122 minutes\n",
      "episode 5660/10000, Eps Reward: 244.41038700606973, Epsilon: 0.0014843986371976792, weights: 14.255834624171257, elapsed: 78.76079998811086 minutes\n",
      "episode 5670/10000, Eps Reward: 248.66365153491097, Epsilon: 0.0014674161227780837, weights: 0.026538374891970307, elapsed: 79.0863596200943 minutes\n",
      "episode 5680/10000, Eps Reward: -286.1269081131296, Epsilon: 0.0014506278996955894, weights: 0.011199443368241191, elapsed: 79.27543243567149 minutes\n",
      "episode 5690/10000, Eps Reward: 73.77166436599991, Epsilon: 0.0014340317451271946, weights: 0.03458471852354705, elapsed: 79.56066605647405 minutes\n",
      "episode 5700/10000, Eps Reward: 244.56173270919356, Epsilon: 0.0014176254616804812, weights: 6.034360259771347, elapsed: 79.88743959665298 minutes\n",
      "episode 5710/10000, Eps Reward: 772.9468957590203, Epsilon: 0.0014014068771026728, weights: 0.055759443901479244, elapsed: 80.35319260756175 minutes\n",
      "episode 5720/10000, Eps Reward: 268.44027965359675, Epsilon: 0.0013853738439930186, weights: 0.054134454287122935, elapsed: 80.6941376566887 minutes\n",
      "episode 5730/10000, Eps Reward: -50.058863793905445, Epsilon: 0.0013695242395184706, weights: 16.25238076224923, elapsed: 80.96445719003677 minutes\n",
      "episode 5740/10000, Eps Reward: 293.7231943081166, Epsilon: 0.0013538559651326122, weights: 0.24450096115469933, elapsed: 81.31827271382014 minutes\n",
      "episode 5750/10000, Eps Reward: -110.18631040514359, Epsilon: 0.0013383669462978037, weights: 0.008600927307270467, elapsed: 81.55086622238159 minutes\n",
      "episode 5760/10000, Eps Reward: 242.80271001690843, Epsilon: 0.0013230551322105043, weights: 11.726700715720654, elapsed: 81.87686278025309 minutes\n",
      "episode 5770/10000, Eps Reward: 239.69922935548078, Epsilon: 0.0013079184955297391, weights: 0.008122523489873856, elapsed: 82.20216304461161 minutes\n",
      "episode 5780/10000, Eps Reward: -109.65092896344618, Epsilon: 0.0012929550321086724, weights: 0.010728109278716147, elapsed: 82.43786052068074 minutes\n",
      "episode 5790/10000, Eps Reward: 65.07714762109995, Epsilon: 0.0012781627607292491, weights: 0.007933708606287837, elapsed: 82.71655426422755 minutes\n",
      "episode 5800/10000, Eps Reward: 430.90492891648927, Epsilon: 0.001263539722839877, weights: 0.0063793348090257496, elapsed: 83.09612567822138 minutes\n",
      "episode 5810/10000, Eps Reward: 598.6475382397361, Epsilon: 0.0012490839822961045, weights: 0.05590882309479639, elapsed: 83.51533783276876 minutes\n",
      "episode 5820/10000, Eps Reward: 419.37445505769466, Epsilon: 0.001234793625104269, weights: 0.01875071320682764, elapsed: 83.88597226540247 minutes\n",
      "episode 5830/10000, Eps Reward: 240.11461008899505, Epsilon: 0.0012206667591680776, weights: 26.3995562735945, elapsed: 84.21194704771042 minutes\n",
      "episode 5840/10000, Eps Reward: 293.6655283968024, Epsilon: 0.001206701514038085, weights: 8.189624419435859, elapsed: 84.5686201373736 minutes\n",
      "episode 5850/10000, Eps Reward: -111.46770479165507, Epsilon: 0.0011928960406640417, weights: 0.14550100872293115, elapsed: 84.8028361439705 minutes\n",
      "episode 5860/10000, Eps Reward: -111.2313740982396, Epsilon: 0.00117924851115007, weights: 0.024265448679216206, elapsed: 85.03939421971639 minutes\n",
      "episode 5870/10000, Eps Reward: 421.40165605694403, Epsilon: 0.0011657571185126451, weights: 0.025480790995061398, elapsed: 85.41131089528402 minutes\n",
      "episode 5880/10000, Eps Reward: -282.5524604123527, Epsilon: 0.0011524200764413445, weights: 13.817454921081662, elapsed: 85.60716799894969 minutes\n",
      "episode 5890/10000, Eps Reward: 67.45093373054486, Epsilon: 0.0011392356190623328, weights: 0.03696965891867876, elapsed: 85.88756721417109 minutes\n",
      "episode 5900/10000, Eps Reward: 420.1487539020245, Epsilon: 0.0011262020007045531, weights: 0.010879326378926635, elapsed: 86.25820076068243 minutes\n",
      "episode 5910/10000, Eps Reward: 312.96419308772363, Epsilon: 0.001113317495668596, weights: 16.21969385817647, elapsed: 86.63053492705028 minutes\n",
      "episode 5920/10000, Eps Reward: 651.7459557295107, Epsilon: 0.0011005803979982072, weights: 0.00834825518541038, elapsed: 87.08536520799001 minutes\n",
      "episode 5930/10000, Eps Reward: 420.45597743362794, Epsilon: 0.0010879890212544146, weights: 18.62489541247487, elapsed: 87.46100105841954 minutes\n",
      "episode 5940/10000, Eps Reward: 415.0580841864163, Epsilon: 0.0010755416982922382, weights: 0.003094639570917934, elapsed: 87.8322082956632 minutes\n",
      "episode 5950/10000, Eps Reward: -267.4406551581333, Epsilon: 0.001063236781039952, weights: 30.369419265538454, elapsed: 88.03478249708812 minutes\n",
      "episode 5960/10000, Eps Reward: -105.1302342789617, Epsilon: 0.001051072640280875, weights: 16.510162964463234, elapsed: 88.27570366859436 minutes\n",
      "episode 5970/10000, Eps Reward: 139.50196747488945, Epsilon: 0.0010390476654376553, weights: 17.06094240769744, elapsed: 88.60006449222564 minutes\n",
      "episode 5980/10000, Eps Reward: -292.18606154448537, Epsilon: 0.0010271602643590243, weights: 7.899848444387317, elapsed: 88.78871420621871 minutes\n",
      "episode 5990/10000, Eps Reward: 242.53843176435277, Epsilon: 0.0010154088631089912, weights: 6.457485720515251, elapsed: 89.11554585695266 minutes\n",
      "episode 6000/10000, Eps Reward: 421.3195747983822, Epsilon: 0.0010037919057584454, weights: 0.07645118050277233, elapsed: 89.48789384365082 minutes\n",
      "episode 6010/10000, Eps Reward: 594.4754750603433, Epsilon: 0.000992307854179149, weights: 10.110400345176458, elapsed: 89.9070291598638 minutes\n",
      "episode 6020/10000, Eps Reward: 67.08398158008787, Epsilon: 0.0009809551878400796, weights: 0.10917458217591047, elapsed: 90.18945945898692 minutes\n",
      "episode 6030/10000, Eps Reward: 594.2182856439881, Epsilon: 0.0009697324036061082, weights: 0.05768244247883558, elapsed: 90.60517369906107 minutes\n",
      "episode 6040/10000, Eps Reward: 129.6477738312314, Epsilon: 0.0009586380155389788, weights: 0.06780938549491111, elapsed: 90.92236308256786 minutes\n",
      "episode 6050/10000, Eps Reward: -431.0380866233081, Epsilon: 0.0009476705547005634, weights: 42.842986308038235, elapsed: 91.08642144203186 minutes\n",
      "episode 6060/10000, Eps Reward: 419.9389059376276, Epsilon: 0.0009368285689583703, weights: 0.04412388848140836, elapsed: 91.45793868700663 minutes\n",
      "episode 6070/10000, Eps Reward: -211.86454119272435, Epsilon: 0.000926110622793276, weights: 0.014789889333769679, elapsed: 91.69399701754251 minutes\n",
      "episode 6080/10000, Eps Reward: -105.97751427657015, Epsilon: 0.0009155152971094566, weights: 13.701373901218176, elapsed: 91.93181970119477 minutes\n",
      "episode 6090/10000, Eps Reward: -286.57094733902426, Epsilon: 0.000905041189046495, weights: 32.444853238761425, elapsed: 92.12148534854254 minutes\n",
      "episode 6100/10000, Eps Reward: 66.63795242347088, Epsilon: 0.0008946869117936369, weights: 22.7691101282835, elapsed: 92.40046929915746 minutes\n",
      "episode 6110/10000, Eps Reward: 601.4175186122192, Epsilon: 0.0008844510944061712, weights: 14.59618717059493, elapsed: 92.82125817537307 minutes\n",
      "episode 6120/10000, Eps Reward: 70.74111489699655, Epsilon: 0.0008743323816239126, weights: 18.090068316087127, elapsed: 93.10280034144719 minutes\n",
      "episode 6130/10000, Eps Reward: 243.23324147520376, Epsilon: 0.0008643294336917596, weights: 0.06495703110704198, elapsed: 93.42808553775151 minutes\n",
      "episode 6140/10000, Eps Reward: -259.8895478643279, Epsilon: 0.0008544409261823069, weights: 17.009624663740396, elapsed: 93.63567977348963 minutes\n",
      "episode 6150/10000, Eps Reward: 420.0241230308772, Epsilon: 0.0008446655498204846, weights: 0.08065900823567063, elapsed: 94.00986549456914 minutes\n",
      "episode 6160/10000, Eps Reward: 249.96270378034757, Epsilon: 0.0008350020103102073, weights: 0.05024154391139746, elapsed: 94.34327674706778 minutes\n",
      "episode 6170/10000, Eps Reward: 419.9960350765174, Epsilon: 0.0008254490281630029, weights: 0.05707038409309462, elapsed: 94.71480909188588 minutes\n",
      "episode 6180/10000, Eps Reward: 72.83756215606522, Epsilon: 0.0008160053385286045, weights: 23.052823569625616, elapsed: 95.00202769041061 minutes\n",
      "episode 6190/10000, Eps Reward: -106.54013539509688, Epsilon: 0.000806669691027479, weights: 0.012213344627525657, elapsed: 95.23860330184301 minutes\n",
      "episode 6200/10000, Eps Reward: 416.31844474582033, Epsilon: 0.0007974408495852727, weights: 0.00821568863466382, elapsed: 95.61150583426158 minutes\n",
      "episode 6210/10000, Eps Reward: 71.35343658027621, Epsilon: 0.0007883175922691504, weights: 0.003958551213145256, elapsed: 95.89838168223699 minutes\n",
      "episode 6220/10000, Eps Reward: -112.574173809362, Epsilon: 0.000779298711126006, weights: 0.006495838169939816, elapsed: 96.13365662495295 minutes\n",
      "episode 6230/10000, Eps Reward: -243.9565295935914, Epsilon: 0.0007703830120225264, weights: 11.341031577438116, elapsed: 96.34998245239258 minutes\n",
      "episode 6240/10000, Eps Reward: -463.0722912071686, Epsilon: 0.0007615693144870838, weights: 0.001612236606888473, elapsed: 96.4966158827146 minutes\n",
      "episode 6250/10000, Eps Reward: 603.9750984150621, Epsilon: 0.0007528564515534354, weights: 0.24468514253385365, elapsed: 96.91513984203338 minutes\n",
      "episode 6260/10000, Eps Reward: -101.15317255043489, Epsilon: 0.0007442432696062138, weights: 9.828374933451414, elapsed: 97.15839074055354 minutes\n",
      "episode 6270/10000, Eps Reward: 420.04043619639486, Epsilon: 0.000735728628228184, weights: 0.06252752171712928, elapsed: 97.53090519507727 minutes\n",
      "episode 6280/10000, Eps Reward: 421.92707608636135, Epsilon: 0.0007273114000492485, weights: 0.08375740563496947, elapsed: 97.9025573849678 minutes\n",
      "episode 6290/10000, Eps Reward: 241.98247207161003, Epsilon: 0.0007189904705971775, weights: 0.005973775172606111, elapsed: 98.2299290060997 minutes\n",
      "episode 6300/10000, Eps Reward: 769.9408000904293, Epsilon: 0.0007107647381500505, weights: 0.04029549588449299, elapsed: 98.69420392115912 minutes\n",
      "episode 6310/10000, Eps Reward: 238.74106662780778, Epsilon: 0.0007026331135903836, weights: 0.1551399095915258, elapsed: 99.0223592599233 minutes\n",
      "episode 6320/10000, Eps Reward: -113.70641099934429, Epsilon: 0.0006945945202609257, weights: 6.331497840583324, elapsed: 99.25954124132792 minutes\n",
      "episode 6330/10000, Eps Reward: -289.8274144479675, Epsilon: 0.0006866478938221061, weights: 0.15489581832662225, elapsed: 99.44920423030854 minutes\n",
      "episode 6340/10000, Eps Reward: 66.85235056917625, Epsilon: 0.0006787921821111112, weights: 11.4314159527421, elapsed: 99.73322091499965 minutes\n",
      "episode 6350/10000, Eps Reward: -947.6062033663211, Epsilon: 0.0006710263450025749, weights: 14.209330776706338, elapsed: 99.77047411998113 minutes\n",
      "episode 6360/10000, Eps Reward: 247.1391229623103, Epsilon: 0.0006633493542708616, weights: 6.946444335393608, elapsed: 100.09522358576457 minutes\n",
      "episode 6370/10000, Eps Reward: 248.43228403974143, Epsilon: 0.0006557601934539253, weights: 0.008442984602879733, elapsed: 100.42263921101888 minutes\n",
      "episode 6380/10000, Eps Reward: -463.81553089224025, Epsilon: 0.0006482578577187272, weights: 0.0076407904853112996, elapsed: 100.56475477615992 minutes\n",
      "episode 6390/10000, Eps Reward: 247.9913762143823, Epsilon: 0.0006408413537281904, weights: 0.04042660049162805, elapsed: 100.89255598783492 minutes\n",
      "episode 6400/10000, Eps Reward: -285.42081729777846, Epsilon: 0.0006335096995096798, weights: 25.950181551277637, elapsed: 101.08132245143254 minutes\n",
      "episode 6410/10000, Eps Reward: -105.76157869119216, Epsilon: 0.0006262619243249849, weights: 0.011908679269254208, elapsed: 101.3221830368042 minutes\n",
      "episode 6420/10000, Eps Reward: 70.7377070009023, Epsilon: 0.00061909706854179, weights: 13.814203716814518, elapsed: 101.60543621381125 minutes\n",
      "episode 6430/10000, Eps Reward: 419.83051783302943, Epsilon: 0.000612014183506616, weights: 0.02186007215641439, elapsed: 101.97684191862741 minutes\n",
      "episode 6440/10000, Eps Reward: 422.59238332422154, Epsilon: 0.0006050123314192149, weights: 33.94514990597963, elapsed: 102.34901414314906 minutes\n",
      "episode 6450/10000, Eps Reward: 602.1564185960676, Epsilon: 0.0005980905852084016, weights: 0.010671145864762366, elapsed: 102.76628802617391 minutes\n",
      "episode 6460/10000, Eps Reward: -104.34548996055435, Epsilon: 0.0005912480284093057, weights: 2.4648114098235965, elapsed: 103.00482816696167 minutes\n",
      "episode 6470/10000, Eps Reward: -111.65199881063631, Epsilon: 0.0005844837550420288, weights: 0.13066360936500132, elapsed: 103.2386025985082 minutes\n",
      "episode 6480/10000, Eps Reward: -102.6665257935651, Epsilon: 0.0005777968694916897, weights: 0.013835756573826075, elapsed: 103.48079363505046 minutes\n",
      "episode 6490/10000, Eps Reward: 239.66208144375923, Epsilon: 0.0005711864863898405, weights: 8.975180451758206, elapsed: 103.8061283826828 minutes\n",
      "episode 6500/10000, Eps Reward: -289.28258948776914, Epsilon: 0.0005646517304972417, weights: 30.506994746625423, elapsed: 103.99434098800023 minutes\n",
      "episode 6510/10000, Eps Reward: 771.7073188752337, Epsilon: 0.0005581917365879764, weights: 0.011082776938565075, elapsed: 104.46217422485351 minutes\n",
      "episode 6520/10000, Eps Reward: 419.69547818256945, Epsilon: 0.0005518056493348919, weights: 0.008353510056622326, elapsed: 104.83485184113185 minutes\n",
      "episode 6530/10000, Eps Reward: 420.5528448114157, Epsilon: 0.0005454926231963507, weights: 35.289272613823414, elapsed: 105.20517494281133 minutes\n",
      "episode 6540/10000, Eps Reward: 425.0979334192486, Epsilon: 0.0005392518223042779, weights: 0.010458006610861048, elapsed: 105.5758592804273 minutes\n",
      "episode 6550/10000, Eps Reward: 444.8762930728925, Epsilon: 0.0005330824203534893, weights: 16.29624706879258, elapsed: 105.96126672029496 minutes\n",
      "episode 6560/10000, Eps Reward: 65.7925741376442, Epsilon: 0.0005269836004922849, weights: 27.07943057268858, elapsed: 106.24047825733821 minutes\n",
      "episode 6570/10000, Eps Reward: 69.81304342875661, Epsilon: 0.0005209545552142957, weights: 0.004411707632243633, elapsed: 106.5238582889239 minutes\n",
      "episode 6580/10000, Eps Reward: 421.29141301278213, Epsilon: 0.0005149944862515657, weights: 0.006028150441125035, elapsed: 106.89509882926941 minutes\n",
      "episode 6590/10000, Eps Reward: 244.42995657739056, Epsilon: 0.0005091026044688594, weights: 0.03467508452013135, elapsed: 107.21986855268479 minutes\n",
      "episode 6600/10000, Eps Reward: 766.8572060733636, Epsilon: 0.0005032781297591765, weights: 0.017000234103761613, elapsed: 107.68129676183065 minutes\n",
      "episode 6610/10000, Eps Reward: 418.89676744084863, Epsilon: 0.0004975202909404631, weights: 0.010462832695338875, elapsed: 108.05422131617864 minutes\n",
      "episode 6620/10000, Eps Reward: 247.21811536427987, Epsilon: 0.0004918283256535046, weights: 0.011286655091680586, elapsed: 108.3817500114441 minutes\n",
      "episode 6630/10000, Eps Reward: 67.35661034821081, Epsilon: 0.0004862014802609867, weights: 11.356642607599497, elapsed: 108.66103509664535 minutes\n",
      "episode 6640/10000, Eps Reward: 603.1196659400547, Epsilon: 0.0004806390097477097, weights: 0.005879920441657305, elapsed: 109.07896426121394 minutes\n",
      "episode 6650/10000, Eps Reward: 69.24529647880105, Epsilon: 0.0004751401776219474, weights: 17.795639514923096, elapsed: 109.35951696634292 minutes\n",
      "episode 6660/10000, Eps Reward: 69.69131134388142, Epsilon: 0.000469704255817932, weights: 0.003631810308434069, elapsed: 109.63925489584605 minutes\n",
      "episode 6670/10000, Eps Reward: 68.44508708766688, Epsilon: 0.0004643305245994555, weights: 0.015932051464915276, elapsed: 109.91874431371689 minutes\n",
      "episode 6680/10000, Eps Reward: -113.71477318806521, Epsilon: 0.0004590182724645742, weights: 0.009806595044210553, elapsed: 110.15220202207566 minutes\n",
      "episode 6690/10000, Eps Reward: 425.49099190256186, Epsilon: 0.0004537667960514028, weights: 0.007336720242165029, elapsed: 110.52249150673548 minutes\n",
      "episode 6700/10000, Eps Reward: 425.3479705897524, Epsilon: 0.0004485754000449874, weights: 0.00952948079793714, elapsed: 110.89318953752517 minutes\n",
      "episode 6710/10000, Eps Reward: 424.40593016944297, Epsilon: 0.00044344339708524263, weights: 0.011710576480254531, elapsed: 111.26561689376831 minutes\n",
      "episode 6720/10000, Eps Reward: 420.153923987118, Epsilon: 0.0004383701076759426, weights: 0.04994551232084632, elapsed: 111.63594570159913 minutes\n",
      "episode 6730/10000, Eps Reward: 601.6841915843548, Epsilon: 0.0004333548600947534, weights: 0.014980890671722591, elapsed: 112.05321074326834 minutes\n",
      "episode 6740/10000, Eps Reward: 243.82053433913075, Epsilon: 0.0004283969903042945, weights: 16.57894267886877, elapsed: 112.37760364214579 minutes\n",
      "episode 6750/10000, Eps Reward: 425.2694004301343, Epsilon: 0.00042349584186421747, weights: 0.021094620460644364, elapsed: 112.74819196065268 minutes\n",
      "episode 6760/10000, Eps Reward: 247.07702555220584, Epsilon: 0.0004186507658442912, weights: 0.007484443034627475, elapsed: 113.07381279468537 minutes\n",
      "episode 6770/10000, Eps Reward: 246.94091482498123, Epsilon: 0.0004138611207384809, weights: 0.007954027154482901, elapsed: 113.3990920941035 minutes\n",
      "episode 6780/10000, Eps Reward: 472.06279811598387, Epsilon: 0.0004091262723800106, weights: 12.44069268554449, elapsed: 113.79789250294367 minutes\n",
      "episode 6790/10000, Eps Reward: -108.07587501807521, Epsilon: 0.00040444559385739655, weights: 0.005445030867122114, elapsed: 114.03159013986587 minutes\n",
      "episode 6800/10000, Eps Reward: 423.14945023352067, Epsilon: 0.00039981846543144244, weights: 0.026553813717328012, elapsed: 114.40315769910812 minutes\n",
      "episode 6810/10000, Eps Reward: 424.1432555057453, Epsilon: 0.0003952442744531832, weights: 0.022474857163615525, elapsed: 114.77587876319885 minutes\n",
      "episode 6820/10000, Eps Reward: -112.73450404586433, Epsilon: 0.00039072241528276844, weights: 5.468992425128818, elapsed: 115.00940670172373 minutes\n",
      "episode 6830/10000, Eps Reward: 772.50093912018, Epsilon: 0.00038625228920927286, weights: 0.0375355239957571, elapsed: 115.4717897216479 minutes\n",
      "episode 6840/10000, Eps Reward: 65.68202941881385, Epsilon: 0.0003818333043714254, weights: 0.003172758559230715, elapsed: 115.75045102834702 minutes\n",
      "episode 6850/10000, Eps Reward: 419.0533908809806, Epsilon: 0.000377464875679244, weights: 0.05301039945334196, elapsed: 116.12147372961044 minutes\n",
      "episode 6860/10000, Eps Reward: 243.50390040072062, Epsilon: 0.0003731464247365679, weights: 0.07504447200335562, elapsed: 116.4490708510081 minutes\n",
      "episode 6870/10000, Eps Reward: 67.06035546491766, Epsilon: 0.0003688773797644758, weights: 0.0042706881649792194, elapsed: 116.73185900052388 minutes\n",
      "episode 6880/10000, Eps Reward: 75.07134082901095, Epsilon: 0.00036465717552558013, weights: 0.04994205851107836, elapsed: 117.01999388535818 minutes\n",
      "episode 6890/10000, Eps Reward: 64.96168481261012, Epsilon: 0.00036048525324918737, weights: 23.79205594956875, elapsed: 117.29931076367696 minutes\n",
      "episode 6900/10000, Eps Reward: 420.5592436516936, Epsilon: 0.0003563610605573152, weights: 6.1512240851297975, elapsed: 117.67068014939626 minutes\n",
      "episode 6910/10000, Eps Reward: 237.88458998376822, Epsilon: 0.00035228405139155504, weights: 0.05888518691062927, elapsed: 118.00013344685236 minutes\n",
      "episode 6920/10000, Eps Reward: -113.65335532428578, Epsilon: 0.0003482536859407724, weights: 15.903018228709698, elapsed: 118.2377439657847 minutes\n",
      "episode 6930/10000, Eps Reward: 242.11186080656654, Epsilon: 0.00034426943056963335, weights: 0.010188574786297977, elapsed: 118.56405957142512 minutes\n",
      "episode 6940/10000, Eps Reward: -289.30265287086536, Epsilon: 0.00034033075774794985, weights: 9.672889925539494, elapsed: 118.7543370048205 minutes\n",
      "episode 6950/10000, Eps Reward: -468.57488452149335, Epsilon: 0.00033643714598083227, weights: 2.9791448321193457, elapsed: 118.89825617074966 minutes\n",
      "episode 6960/10000, Eps Reward: -111.07905755485339, Epsilon: 0.00033258807973964174, weights: 12.314985182136297, elapsed: 119.13520811398824 minutes\n",
      "episode 6970/10000, Eps Reward: 66.92805818129446, Epsilon: 0.00032878304939373213, weights: 21.089830685406923, elapsed: 119.42025264898936 minutes\n",
      "episode 6980/10000, Eps Reward: 475.34760242437096, Epsilon: 0.0003250215511429736, weights: 0.024537914199754596, elapsed: 119.82992295821508 minutes\n",
      "episode 6990/10000, Eps Reward: -643.4622161985312, Epsilon: 0.0003213030869510466, weights: 12.842902053147554, elapsed: 119.92784973780314 minutes\n",
      "episode 7000/10000, Eps Reward: 416.89579455325367, Epsilon: 0.00031762716447950105, weights: 13.71182262711227, elapsed: 120.30009410381317 minutes\n",
      "episode 7010/10000, Eps Reward: 242.47566167329106, Epsilon: 0.00031399329702256815, weights: 0.027047141920775175, elapsed: 120.6275175968806 minutes\n",
      "episode 7020/10000, Eps Reward: 245.9275616090071, Epsilon: 0.00031040100344271906, weights: 0.056743664434179664, elapsed: 120.95988142887751 minutes\n",
      "episode 7030/10000, Eps Reward: 244.02578983189818, Epsilon: 0.0003068498081069605, weights: 0.01858179399278015, elapsed: 121.28897502819697 minutes\n",
      "episode 7040/10000, Eps Reward: 420.5481374763005, Epsilon: 0.00030333924082385924, weights: 0.018747834459645674, elapsed: 121.66148928403854 minutes\n",
      "episode 7050/10000, Eps Reward: 70.67793668354169, Epsilon: 0.0002998688367812865, weights: 9.769408661872149, elapsed: 121.95139176448187 minutes\n",
      "episode 7060/10000, Eps Reward: 598.7477365544537, Epsilon: 0.000296438136484876, weights: 0.0048163809115067124, elapsed: 122.3702279249827 minutes\n",
      "episode 7070/10000, Eps Reward: -109.76167909674977, Epsilon: 0.0002930466856971845, weights: 31.319248132407665, elapsed: 122.6052461306254 minutes\n",
      "episode 7080/10000, Eps Reward: -288.3908807686864, Epsilon: 0.0002896940353775492, weights: 29.847204633057117, elapsed: 122.79367946386337 minutes\n",
      "episode 7090/10000, Eps Reward: 247.82209038574138, Epsilon: 0.00028637974162263333, weights: 16.20579399354756, elapsed: 123.11992852290471 minutes\n",
      "episode 7100/10000, Eps Reward: 781.6324737018025, Epsilon: 0.00028310336560765146, weights: 0.005871202592970803, elapsed: 123.58457202514013 minutes\n",
      "episode 7110/10000, Eps Reward: 69.26974440122773, Epsilon: 0.00027986447352826754, weights: 30.88968500168994, elapsed: 123.86559028625489 minutes\n",
      "episode 7120/10000, Eps Reward: 603.9656438210412, Epsilon: 0.0002766626365431577, weights: 0.0013985306140966713, elapsed: 124.28651829560597 minutes\n",
      "episode 7130/10000, Eps Reward: 69.59866411436147, Epsilon: 0.0002734974307172299, weights: 17.464862495660782, elapsed: 124.56612150669098 minutes\n",
      "episode 7140/10000, Eps Reward: 425.11115657243045, Epsilon: 0.00027036843696549357, weights: 0.005656266468577087, elapsed: 124.9377247095108 minutes\n",
      "episode 7150/10000, Eps Reward: 69.47602840587042, Epsilon: 0.00026727524099757084, weights: 0.041458602994680405, elapsed: 125.21874628861745 minutes\n",
      "episode 7160/10000, Eps Reward: 424.82941256096103, Epsilon: 0.0002642174332628434, weights: 12.081182850524783, elapsed: 125.5923593044281 minutes\n",
      "episode 7170/10000, Eps Reward: 66.3445848584085, Epsilon: 0.00026119460889622616, weights: 0.09812894510105252, elapsed: 125.87239495913188 minutes\n",
      "episode 7180/10000, Eps Reward: 244.8186980369109, Epsilon: 0.00025820636766456175, weights: 21.824402071535587, elapsed: 126.19879102309545 minutes\n",
      "episode 7190/10000, Eps Reward: 780.9990857325943, Epsilon: 0.00025525231391362803, weights: 0.004245123593136668, elapsed: 126.66244388818741 minutes\n",
      "episode 7200/10000, Eps Reward: 247.15183866272227, Epsilon: 0.0002523320565157523, weights: 0.015620238264091313, elapsed: 126.98971730868021 minutes\n",
      "episode 7210/10000, Eps Reward: 425.1934511319795, Epsilon: 0.0002494452088180242, weights: 0.03685726295225322, elapsed: 127.36323508024216 minutes\n",
      "episode 7220/10000, Eps Reward: -98.90360682421736, Epsilon: 0.0002465913885911016, weights: 0.02168247936060652, elapsed: 127.6054157614708 minutes\n",
      "episode 7230/10000, Eps Reward: 420.51198320454625, Epsilon: 0.0002437702179786022, weights: 0.02031567203812301, elapsed: 127.97882945537567 minutes\n",
      "episode 7240/10000, Eps Reward: 239.15624812456957, Epsilon: 0.00024098132344707335, weights: 21.971815794706345, elapsed: 128.30359363158544 minutes\n",
      "episode 7250/10000, Eps Reward: 245.5489694610754, Epsilon: 0.00023822433573653557, weights: 19.57315207272768, elapsed: 128.63197524944943 minutes\n",
      "episode 7260/10000, Eps Reward: 66.50174658597949, Epsilon: 0.00023549888981159065, weights: 12.86015909165144, elapsed: 128.91194862922032 minutes\n",
      "episode 7270/10000, Eps Reward: 245.89959419179308, Epsilon: 0.00023280462481308986, weights: 0.08156410907395184, elapsed: 129.23810431957244 minutes\n",
      "episode 7280/10000, Eps Reward: 68.09131766112075, Epsilon: 0.0002301411840103547, weights: 0.022343266988173127, elapsed: 129.51749631563823 minutes\n",
      "episode 7290/10000, Eps Reward: 418.8732191297693, Epsilon: 0.0002275082147539446, weights: 0.007146249059587717, elapsed: 129.88982543150584 minutes\n",
      "episode 7300/10000, Eps Reward: 604.5495273563979, Epsilon: 0.00022490536842896465, weights: 0.055429760133847594, elapsed: 130.31194365024567 minutes\n",
      "episode 7310/10000, Eps Reward: -289.65700206150836, Epsilon: 0.00022233230040890784, weights: 28.183925092220306, elapsed: 130.5022438923518 minutes\n",
      "episode 7320/10000, Eps Reward: 244.30280773315366, Epsilon: 0.00021978867001002517, weights: 27.80924317985773, elapsed: 130.82957477966946 minutes\n",
      "episode 7330/10000, Eps Reward: 599.0958595438817, Epsilon: 0.00021727414044621783, weights: 6.854941634461284, elapsed: 131.2474562128385 minutes\n",
      "episode 7340/10000, Eps Reward: 416.32063367847786, Epsilon: 0.00021478837878444556, weights: 15.908580619841814, elapsed: 131.61975723107656 minutes\n",
      "episode 7350/10000, Eps Reward: 71.2094205259192, Epsilon: 0.00021233105590064494, weights: 0.027097256563138217, elapsed: 131.90497715473174 minutes\n",
      "episode 7360/10000, Eps Reward: 771.5522766855825, Epsilon: 0.0002099018464361523, weights: 0.005156053477548994, elapsed: 132.36818851629894 minutes\n",
      "episode 7370/10000, Eps Reward: 634.0249129729633, Epsilon: 0.000207500428754625, weights: 0.008587964111939073, elapsed: 132.81477363904318 minutes\n",
      "episode 7380/10000, Eps Reward: 591.2889600668378, Epsilon: 0.0002051264848994554, weights: 0.019295290345326066, elapsed: 133.2314510067304 minutes\n",
      "episode 7390/10000, Eps Reward: 771.6952037825009, Epsilon: 0.0002027797005516724, weights: 0.027935440884903073, elapsed: 133.69817210833233 minutes\n",
      "episode 7400/10000, Eps Reward: 435.57252621269055, Epsilon: 0.00020045976498832456, weights: 19.911012132652104, elapsed: 134.08440827926 minutes\n",
      "episode 7410/10000, Eps Reward: -113.10835139386927, Epsilon: 0.00019816637104133896, weights: 0.015435269800946116, elapsed: 134.32198219299318 minutes\n",
      "episode 7420/10000, Eps Reward: 596.1933250985591, Epsilon: 0.00019589921505685107, weights: 0.01707859366433695, elapsed: 134.7420550028483 minutes\n",
      "episode 7430/10000, Eps Reward: -111.67145191763518, Epsilon: 0.00019365799685500001, weights: 12.584533793851733, elapsed: 134.9773195385933 minutes\n",
      "episode 7440/10000, Eps Reward: 601.0076363327726, Epsilon: 0.0001914424196901835, weights: 0.040037099504843354, elapsed: 135.3955695827802 minutes\n",
      "episode 7450/10000, Eps Reward: -285.5889807067314, Epsilon: 0.00018925219021176767, weights: 26.536204420030117, elapsed: 135.5842135111491 minutes\n",
      "episode 7460/10000, Eps Reward: 66.67424569619322, Epsilon: 0.00018708701842524623, weights: 35.97804445028305, elapsed: 135.86456941366197 minutes\n",
      "episode 7470/10000, Eps Reward: -104.5140941343163, Epsilon: 0.0001849466176538444, weights: 0.03375387564301491, elapsed: 136.10451103448867 minutes\n",
      "episode 7480/10000, Eps Reward: 423.1249982583712, Epsilon: 0.0001828307045005615, weights: 0.002502827293938026, elapsed: 136.47591480414073 minutes\n",
      "episode 7490/10000, Eps Reward: -287.7062566481732, Epsilon: 0.00018073899881064845, weights: 16.878140587359667, elapsed: 136.6636603196462 minutes\n",
      "episode 7500/10000, Eps Reward: 240.41950388967444, Epsilon: 0.00017867122363451408, weights: 1.7585398200899363, elapsed: 136.99037195841473 minutes\n",
      "episode 7510/10000, Eps Reward: 245.56774254933867, Epsilon: 0.000176627105191056, weights: 0.1158344172872603, elapsed: 137.32354545195898 minutes\n",
      "episode 7520/10000, Eps Reward: 420.6802595796262, Epsilon: 0.00017460637283141093, weights: 13.92715074494481, elapsed: 137.69668401877087 minutes\n",
      "episode 7530/10000, Eps Reward: 417.33700892295775, Epsilon: 0.00017260875900311978, weights: 0.008856495725922287, elapsed: 138.06947889725367 minutes\n",
      "episode 7540/10000, Eps Reward: 244.85660737362974, Epsilon: 0.0001706339992147028, weights: 0.026190489006694406, elapsed: 138.3967046380043 minutes\n",
      "episode 7550/10000, Eps Reward: 595.3016865104353, Epsilon: 0.00016868183200063997, weights: 0.009175482322461903, elapsed: 138.8145575086276 minutes\n",
      "episode 7560/10000, Eps Reward: 419.0895684218096, Epsilon: 0.00016675199888675174, weights: 0.02690890763187781, elapsed: 139.18822102149326 minutes\n",
      "episode 7570/10000, Eps Reward: 599.2804312580847, Epsilon: 0.00016484424435597646, weights: 0.017348793800920248, elapsed: 139.60688775380453 minutes\n",
      "episode 7580/10000, Eps Reward: 595.7810636065533, Epsilon: 0.00016295831581453858, weights: 0.009375592053402215, elapsed: 140.02614732186 minutes\n",
      "episode 7590/10000, Eps Reward: -113.04408333478719, Epsilon: 0.00016109396355850456, weights: 0.028228325652889907, elapsed: 140.25916708310444 minutes\n",
      "episode 7600/10000, Eps Reward: 598.2739858552807, Epsilon: 0.00015925094074072116, weights: 0.047464938601478934, elapsed: 140.67750810782115 minutes\n",
      "episode 7610/10000, Eps Reward: -111.33900945189244, Epsilon: 0.0001574290033381316, weights: 16.86120008304715, elapsed: 140.91378298600515 minutes\n",
      "episode 7620/10000, Eps Reward: 67.07821008847841, Epsilon: 0.00015562791011946659, weights: 19.002259839326143, elapsed: 141.19467533429463 minutes\n",
      "episode 7630/10000, Eps Reward: 596.3389067452902, Epsilon: 0.00015384742261330398, weights: 0.021419488359242678, elapsed: 141.61383872826895 minutes\n",
      "episode 7640/10000, Eps Reward: 416.30248397948736, Epsilon: 0.0001520873050764943, weights: 0.03587506915209815, elapsed: 141.9853165904681 minutes\n",
      "episode 7650/10000, Eps Reward: 777.8775652097689, Epsilon: 0.00015034732446294772, weights: 0.010608346143271774, elapsed: 142.44856581290563 minutes\n",
      "episode 7660/10000, Eps Reward: 597.4774385453758, Epsilon: 0.00014862725039277764, weights: 0.04231481347233057, elapsed: 142.86636544466018 minutes\n",
      "episode 7670/10000, Eps Reward: 599.0019591221019, Epsilon: 0.0001469268551217976, weights: 0.10249281069263816, elapsed: 143.2832530061404 minutes\n",
      "episode 7680/10000, Eps Reward: 91.77867590968313, Epsilon: 0.00014524591351136725, weights: 0.004796162655111402, elapsed: 143.57966580788295 minutes\n",
      "episode 7690/10000, Eps Reward: 600.3324818847818, Epsilon: 0.00014358420299858296, weights: 0.012302126095164567, elapsed: 143.9980164329211 minutes\n",
      "episode 7700/10000, Eps Reward: 600.3609160500952, Epsilon: 0.0001419415035668098, weights: 0.03364568582037464, elapsed: 144.41746879816054 minutes\n",
      "episode 7710/10000, Eps Reward: 247.90338159019785, Epsilon: 0.0001403175977165504, weights: 13.203383941203356, elapsed: 144.74573766787847 minutes\n",
      "episode 7720/10000, Eps Reward: 597.6913450443151, Epsilon: 0.0001387122704366474, weights: 38.098706886172295, elapsed: 145.16371961832047 minutes\n",
      "episode 7730/10000, Eps Reward: 418.8907502889101, Epsilon: 0.00013712530917581495, weights: 0.04014381440356374, elapsed: 145.53497452338536 minutes\n",
      "episode 7740/10000, Eps Reward: 595.5165942181201, Epsilon: 0.00013555650381449636, weights: 32.872956313192844, elapsed: 145.95224286317824 minutes\n",
      "episode 7750/10000, Eps Reward: -109.73890113851344, Epsilon: 0.00013400564663704334, weights: 0.016385359689593315, elapsed: 146.18574131329854 minutes\n",
      "episode 7760/10000, Eps Reward: 63.74021187558789, Epsilon: 0.00013247253230421355, weights: 27.684467993676662, elapsed: 146.46480096578597 minutes\n",
      "episode 7770/10000, Eps Reward: 601.1146269476427, Epsilon: 0.00013095695782598327, weights: 0.010118941077962518, elapsed: 146.88720148007076 minutes\n",
      "episode 7780/10000, Eps Reward: 419.58325815661135, Epsilon: 0.00012945872253467057, weights: 0.009457486332394183, elapsed: 147.2590527455012 minutes\n",
      "episode 7790/10000, Eps Reward: 64.85974370855146, Epsilon: 0.00012797762805836612, weights: 0.01555955910589546, elapsed: 147.5383442401886 minutes\n",
      "episode 7800/10000, Eps Reward: 242.99706097443305, Epsilon: 0.000126513478294668, weights: 0.018063681593048386, elapsed: 147.86453533172607 minutes\n",
      "episode 7810/10000, Eps Reward: 596.1412080866712, Epsilon: 0.00012506607938471724, weights: 0.011640639975667, elapsed: 148.28430696328482 minutes\n",
      "episode 7820/10000, Eps Reward: 594.145518885816, Epsilon: 0.00012363523968752995, weights: 0.028427536133676767, elapsed: 148.70272638400397 minutes\n",
      "episode 7830/10000, Eps Reward: 418.17883010457564, Epsilon: 0.00012222076975462344, weights: 25.564412392675877, elapsed: 149.07396286725998 minutes\n",
      "episode 7840/10000, Eps Reward: 240.82878550777454, Epsilon: 0.00012082248230493249, weights: 0.002239477151306346, elapsed: 149.4020800471306 minutes\n",
      "episode 7850/10000, Eps Reward: 242.85945947391187, Epsilon: 0.0001194401922000127, weights: 0.007529428345151246, elapsed: 149.72946736017863 minutes\n",
      "episode 7860/10000, Eps Reward: 68.80327239749836, Epsilon: 0.00011807371641952747, weights: 0.007455302751623094, elapsed: 150.01216727495193 minutes\n",
      "episode 7870/10000, Eps Reward: 420.26961168173057, Epsilon: 0.00011672287403701538, weights: 0.007821303326636553, elapsed: 150.38320154746373 minutes\n",
      "episode 7880/10000, Eps Reward: 243.48842706649185, Epsilon: 0.00011538748619593492, weights: 19.851136945188046, elapsed: 150.70830102364224 minutes\n",
      "episode 7890/10000, Eps Reward: 247.41095624833133, Epsilon: 0.00011406737608598315, weights: 25.036668598651886, elapsed: 151.03438828786213 minutes\n",
      "episode 7900/10000, Eps Reward: 247.73598126601988, Epsilon: 0.0001127623689196854, weights: 0.005045900878030807, elapsed: 151.35920697450638 minutes\n",
      "episode 7910/10000, Eps Reward: -108.50174763799717, Epsilon: 0.00011147229190925277, weights: 0.0061707403510808945, elapsed: 151.59544980923334 minutes\n",
      "episode 7920/10000, Eps Reward: 247.44850359880462, Epsilon: 0.00011019697424370436, weights: 0.04877670796122402, elapsed: 151.9215166012446 minutes\n",
      "episode 7930/10000, Eps Reward: 602.3943819056476, Epsilon: 0.00010893624706625126, weights: 0.004332977783633396, elapsed: 152.33906896511715 minutes\n",
      "episode 7940/10000, Eps Reward: 423.18426161429636, Epsilon: 0.00010768994345193933, weights: 0.011328494845656678, elapsed: 152.71170903046925 minutes\n",
      "episode 7950/10000, Eps Reward: 244.6150465671561, Epsilon: 0.00010645789838554765, weights: 0.051383846323005855, elapsed: 153.03684384028116 minutes\n",
      "episode 7960/10000, Eps Reward: 244.645964958516, Epsilon: 0.00010523994873973997, weights: 17.008672948926687, elapsed: 153.36223810513815 minutes\n",
      "episode 7970/10000, Eps Reward: 247.55323091016663, Epsilon: 0.00010403593325346592, weights: 0.15801823046058416, elapsed: 153.6882130742073 minutes\n",
      "episode 7980/10000, Eps Reward: 602.6878540417628, Epsilon: 0.00010284569251060966, weights: 0.14418603922240436, elapsed: 154.10731577475866 minutes\n",
      "episode 7990/10000, Eps Reward: 603.2953942395441, Epsilon: 0.00010166906891888237, weights: 33.75190783292055, elapsed: 154.52509826024374 minutes\n",
      "episode 8000/10000, Eps Reward: 780.5799333662538, Epsilon: 0.00010050590668895651, weights: 0.00012365530710667372, elapsed: 154.98968590100606 minutes\n",
      "episode 8010/10000, Eps Reward: 69.67396417166644, Epsilon: 0.0001, weights: 0.03770724684000015, elapsed: 155.2714726249377 minutes\n",
      "episode 8020/10000, Eps Reward: 247.4221505634314, Epsilon: 0.0001, weights: 0.033186934189870954, elapsed: 155.59764188925425 minutes\n",
      "episode 8030/10000, Eps Reward: 425.5717755525364, Epsilon: 0.0001, weights: 0.008920472813770175, elapsed: 155.9691117922465 minutes\n",
      "episode 8040/10000, Eps Reward: 247.52933402531244, Epsilon: 0.0001, weights: 0.02194777416298166, elapsed: 156.2954320748647 minutes\n",
      "episode 8050/10000, Eps Reward: 246.91005525032875, Epsilon: 0.0001, weights: 0.04405653406865895, elapsed: 156.62219324509303 minutes\n",
      "episode 8060/10000, Eps Reward: 603.4309197358884, Epsilon: 0.0001, weights: 0.009506983449682593, elapsed: 157.04060976107914 minutes\n",
      "episode 8070/10000, Eps Reward: 781.0913946076174, Epsilon: 0.0001, weights: 0.008934375262469985, elapsed: 157.50485900243123 minutes\n",
      "episode 8080/10000, Eps Reward: 781.3998977003323, Epsilon: 0.0001, weights: 0.0240532181924209, elapsed: 157.97049966653188 minutes\n",
      "episode 8090/10000, Eps Reward: 421.7361193505668, Epsilon: 0.0001, weights: 0.033348435536026955, elapsed: 158.34268932739894 minutes\n",
      "episode 8100/10000, Eps Reward: 423.2026701282597, Epsilon: 0.0001, weights: 26.47708099335432, elapsed: 158.71578818162283 minutes\n",
      "episode 8110/10000, Eps Reward: -110.39496252700008, Epsilon: 0.0001, weights: 0.04063399409642443, elapsed: 158.95348505973817 minutes\n",
      "episode 8120/10000, Eps Reward: 592.1567145750129, Epsilon: 0.0001, weights: 0.04662019107490778, elapsed: 159.3763791402181 minutes\n",
      "episode 8130/10000, Eps Reward: 242.37381859463204, Epsilon: 0.0001, weights: 21.386854894459248, elapsed: 159.70400229295095 minutes\n",
      "episode 8140/10000, Eps Reward: 68.95029622947119, Epsilon: 0.0001, weights: 0.005870165507076308, elapsed: 159.98538085222245 minutes\n",
      "episode 8150/10000, Eps Reward: 424.9037128163851, Epsilon: 0.0001, weights: 0.013528919080272317, elapsed: 160.35904573202134 minutes\n",
      "episode 8160/10000, Eps Reward: 603.9478049034963, Epsilon: 0.0001, weights: 0.027040568471420556, elapsed: 160.77782004674276 minutes\n",
      "episode 8170/10000, Eps Reward: 602.970150164288, Epsilon: 0.0001, weights: 0.011368334293365479, elapsed: 161.19828202724457 minutes\n",
      "episode 8180/10000, Eps Reward: 247.346509975137, Epsilon: 0.0001, weights: 8.46164003945887, elapsed: 161.52563124895096 minutes\n",
      "episode 8190/10000, Eps Reward: 247.21149320103146, Epsilon: 0.0001, weights: 0.005712505313567817, elapsed: 161.8534232656161 minutes\n",
      "episode 8200/10000, Eps Reward: 425.4255313665646, Epsilon: 0.0001, weights: 0.001447226939490065, elapsed: 162.22742492755253 minutes\n",
      "episode 8210/10000, Eps Reward: 246.15258474851697, Epsilon: 0.0001, weights: 0.014494161332549993, elapsed: 162.55635126829148 minutes\n",
      "episode 8220/10000, Eps Reward: 602.1495600809255, Epsilon: 0.0001, weights: 0.01309824618510902, elapsed: 162.9751664161682 minutes\n",
      "episode 8230/10000, Eps Reward: 599.9059249133271, Epsilon: 0.0001, weights: 0.031559804221615195, elapsed: 163.39304120937985 minutes\n",
      "episode 8240/10000, Eps Reward: 779.5658768247683, Epsilon: 0.0001, weights: 0.04495029919780791, elapsed: 163.85787099599838 minutes\n",
      "episode 8250/10000, Eps Reward: 244.93141325797887, Epsilon: 0.0001, weights: 0.01151502865832299, elapsed: 164.18533582290013 minutes\n",
      "episode 8260/10000, Eps Reward: 423.9287230315248, Epsilon: 0.0001, weights: 0.009843686129897833, elapsed: 164.56157651344935 minutes\n",
      "episode 8270/10000, Eps Reward: 245.39621050191982, Epsilon: 0.0001, weights: 41.51237767934799, elapsed: 164.88918976783754 minutes\n",
      "episode 8280/10000, Eps Reward: 422.3954627422284, Epsilon: 0.0001, weights: 0.04659559950232506, elapsed: 165.26229414542516 minutes\n",
      "episode 8290/10000, Eps Reward: 601.8848086446135, Epsilon: 0.0001, weights: 0.0018936680280603468, elapsed: 165.68142209450403 minutes\n",
      "episode 8300/10000, Eps Reward: 602.4781598426852, Epsilon: 0.0001, weights: 26.52934204787016, elapsed: 166.10070900519688 minutes\n",
      "episode 8310/10000, Eps Reward: 602.2087989350366, Epsilon: 0.0001, weights: 0.01609879150055349, elapsed: 166.5215453505516 minutes\n",
      "episode 8320/10000, Eps Reward: 244.4760667413031, Epsilon: 0.0001, weights: 0.013521452550776303, elapsed: 166.84875702460607 minutes\n",
      "episode 8330/10000, Eps Reward: 778.9010040390049, Epsilon: 0.0001, weights: 0.014731886563822627, elapsed: 167.31423801581064 minutes\n",
      "episode 8340/10000, Eps Reward: 421.9864643844946, Epsilon: 0.0001, weights: 0.03251363546587527, elapsed: 167.68749138911565 minutes\n",
      "episode 8350/10000, Eps Reward: 779.3448442378042, Epsilon: 0.0001, weights: 0.029659459949471056, elapsed: 168.15263136227927 minutes\n",
      "episode 8360/10000, Eps Reward: 597.6620468643625, Epsilon: 0.0001, weights: 0.09115239046514034, elapsed: 168.571562564373 minutes\n",
      "episode 8370/10000, Eps Reward: 768.3640319732938, Epsilon: 0.0001, weights: 0.0054223466431722045, elapsed: 169.03540562391282 minutes\n",
      "episode 8380/10000, Eps Reward: 415.877503025161, Epsilon: 0.0001, weights: 0.023985659470781684, elapsed: 169.4104668021202 minutes\n",
      "episode 8390/10000, Eps Reward: 415.6997811509347, Epsilon: 0.0001, weights: 15.717280481010675, elapsed: 169.7831125974655 minutes\n",
      "episode 8400/10000, Eps Reward: 770.4485712008634, Epsilon: 0.0001, weights: 0.06548789679072797, elapsed: 170.2486178000768 minutes\n",
      "episode 8410/10000, Eps Reward: 773.6786910754388, Epsilon: 0.0001, weights: 0.007124887430109084, elapsed: 170.71702445745467 minutes\n",
      "episode 8420/10000, Eps Reward: 770.1270849607039, Epsilon: 0.0001, weights: 0.0026115194195881486, elapsed: 171.18478968143464 minutes\n",
      "episode 8430/10000, Eps Reward: 766.0562732607729, Epsilon: 0.0001, weights: 0.023027210729196668, elapsed: 171.65135653416317 minutes\n",
      "episode 8440/10000, Eps Reward: 769.2330234456304, Epsilon: 0.0001, weights: 0.027371554635465145, elapsed: 172.11882016658782 minutes\n",
      "episode 8450/10000, Eps Reward: 767.8922035444908, Epsilon: 0.0001, weights: 0.003590495209209621, elapsed: 172.5854821006457 minutes\n",
      "episode 8460/10000, Eps Reward: 769.618339999756, Epsilon: 0.0001, weights: 0.03912941366434097, elapsed: 173.0522206266721 minutes\n",
      "episode 8470/10000, Eps Reward: 599.6019536803449, Epsilon: 0.0001, weights: 28.906937208026648, elapsed: 173.47613584200542 minutes\n",
      "episode 8480/10000, Eps Reward: 421.4889825448502, Epsilon: 0.0001, weights: 0.026550228998530656, elapsed: 173.85366915464402 minutes\n",
      "episode 8490/10000, Eps Reward: 593.3876887463053, Epsilon: 0.0001, weights: 0.004371663584606722, elapsed: 174.27444808085758 minutes\n",
      "episode 8500/10000, Eps Reward: 770.6950601473249, Epsilon: 0.0001, weights: 0.008020070847123861, elapsed: 174.74130199750263 minutes\n",
      "episode 8510/10000, Eps Reward: 769.9138691003785, Epsilon: 0.0001, weights: 0.03335447073914111, elapsed: 175.20852468411127 minutes\n",
      "episode 8520/10000, Eps Reward: 595.1832720392224, Epsilon: 0.0001, weights: 0.06272327317856252, elapsed: 175.6280519326528 minutes\n",
      "episode 8530/10000, Eps Reward: 597.7006951470114, Epsilon: 0.0001, weights: 0.14525857102125883, elapsed: 176.04758281707763 minutes\n",
      "episode 8540/10000, Eps Reward: 243.99895929171498, Epsilon: 0.0001, weights: 0.0035895554174203426, elapsed: 176.37417360544205 minutes\n",
      "episode 8550/10000, Eps Reward: 420.8354030915422, Epsilon: 0.0001, weights: 0.002142489713151008, elapsed: 176.74779147307078 minutes\n",
      "episode 8560/10000, Eps Reward: 420.7592643435878, Epsilon: 0.0001, weights: 0.008160092867910862, elapsed: 177.12149186929068 minutes\n",
      "episode 8570/10000, Eps Reward: 244.23710567001595, Epsilon: 0.0001, weights: 0.01057016673439648, elapsed: 177.44932316939037 minutes\n",
      "episode 8580/10000, Eps Reward: 243.34492788861635, Epsilon: 0.0001, weights: 15.151776652783155, elapsed: 177.77715598344804 minutes\n",
      "episode 8590/10000, Eps Reward: 600.233207310565, Epsilon: 0.0001, weights: 0.03411703370511532, elapsed: 178.19801756540934 minutes\n",
      "episode 8600/10000, Eps Reward: 776.0234724680372, Epsilon: 0.0001, weights: 0.03154049953445792, elapsed: 178.66609534025193 minutes\n",
      "episode 8610/10000, Eps Reward: 592.695157280586, Epsilon: 0.0001, weights: 0.006066494155675173, elapsed: 179.08866689999897 minutes\n",
      "episode 8620/10000, Eps Reward: 598.3632890398212, Epsilon: 0.0001, weights: 0.012621068628504872, elapsed: 179.5114285548528 minutes\n",
      "episode 8630/10000, Eps Reward: 418.9586639934602, Epsilon: 0.0001, weights: 0.04903126321732998, elapsed: 179.88408166964848 minutes\n",
      "episode 8640/10000, Eps Reward: 419.46057357034186, Epsilon: 0.0001, weights: 0.3968028575181961, elapsed: 180.2568853656451 minutes\n",
      "episode 8650/10000, Eps Reward: 779.507984748016, Epsilon: 0.0001, weights: 0.017245176364667714, elapsed: 180.7241369644801 minutes\n",
      "episode 8660/10000, Eps Reward: 244.37077542497656, Epsilon: 0.0001, weights: 0.0165970764355734, elapsed: 181.05138539473216 minutes\n",
      "episode 8670/10000, Eps Reward: 419.87782442930285, Epsilon: 0.0001, weights: 0.08542991749709472, elapsed: 181.42667061487833 minutes\n",
      "episode 8680/10000, Eps Reward: 423.1872905409924, Epsilon: 0.0001, weights: 0.010015658452175558, elapsed: 181.80040203730266 minutes\n",
      "episode 8690/10000, Eps Reward: 421.8458318572606, Epsilon: 0.0001, weights: 20.13232273608446, elapsed: 182.17359374364216 minutes\n",
      "episode 8700/10000, Eps Reward: 598.5977833303996, Epsilon: 0.0001, weights: 24.42897603660822, elapsed: 182.59279798666637 minutes\n",
      "episode 8710/10000, Eps Reward: 420.442078702872, Epsilon: 0.0001, weights: 0.017170547042042017, elapsed: 182.96748692591984 minutes\n",
      "episode 8720/10000, Eps Reward: 240.35943493336762, Epsilon: 0.0001, weights: 26.321929410099983, elapsed: 183.29386744101842 minutes\n",
      "episode 8730/10000, Eps Reward: 421.4091250209773, Epsilon: 0.0001, weights: 0.010365148831624538, elapsed: 183.66895403464636 minutes\n",
      "episode 8740/10000, Eps Reward: 595.3050964126973, Epsilon: 0.0001, weights: 0.023025064263492823, elapsed: 184.09237964550655 minutes\n",
      "episode 8750/10000, Eps Reward: 242.4159664810439, Epsilon: 0.0001, weights: 33.854273080825806, elapsed: 184.42012922763826 minutes\n",
      "episode 8760/10000, Eps Reward: 422.1582154594752, Epsilon: 0.0001, weights: 0.0003953665727749467, elapsed: 184.79386575222014 minutes\n",
      "episode 8770/10000, Eps Reward: 421.48896490950136, Epsilon: 0.0001, weights: 0.006297598476521671, elapsed: 185.16806783278784 minutes\n",
      "episode 8780/10000, Eps Reward: -286.1492325401257, Epsilon: 0.0001, weights: 0.018428815295919776, elapsed: 185.35707147518795 minutes\n",
      "episode 8790/10000, Eps Reward: -464.5590721884946, Epsilon: 0.0001, weights: 26.75725469738245, elapsed: 185.49901292324066 minutes\n",
      "episode 8800/10000, Eps Reward: 424.037249722535, Epsilon: 0.0001, weights: 0.013383258774410933, elapsed: 185.87273335854212 minutes\n",
      "episode 8810/10000, Eps Reward: 239.55473382429986, Epsilon: 0.0001, weights: 26.38667979836464, elapsed: 186.2035692214966 minutes\n",
      "episode 8820/10000, Eps Reward: 419.89913036598165, Epsilon: 0.0001, weights: 0.026067964849062264, elapsed: 186.57599381605783 minutes\n",
      "episode 8830/10000, Eps Reward: -111.95266680323326, Epsilon: 0.0001, weights: 27.08192114159465, elapsed: 186.8113535483678 minutes\n",
      "episode 8840/10000, Eps Reward: 598.2134491517041, Epsilon: 0.0001, weights: 12.902933791279793, elapsed: 187.22982654571533 minutes\n",
      "episode 8850/10000, Eps Reward: 419.5685151950955, Epsilon: 0.0001, weights: 0.03644099039956927, elapsed: 187.60348043441772 minutes\n",
      "episode 8860/10000, Eps Reward: 419.8736066898299, Epsilon: 0.0001, weights: 0.022383753675967455, elapsed: 187.97833261092504 minutes\n",
      "episode 8870/10000, Eps Reward: 416.4756073152674, Epsilon: 0.0001, weights: 26.76603102684021, elapsed: 188.35081477959952 minutes\n",
      "episode 8880/10000, Eps Reward: 418.30490204691415, Epsilon: 0.0001, weights: 0.040343403816223145, elapsed: 188.72435717582704 minutes\n",
      "episode 8890/10000, Eps Reward: 419.21361189806066, Epsilon: 0.0001, weights: 0.05607783701270819, elapsed: 189.09714421431224 minutes\n",
      "episode 8900/10000, Eps Reward: 418.32933882874806, Epsilon: 0.0001, weights: 0.03242412384133786, elapsed: 189.4707930445671 minutes\n",
      "episode 8910/10000, Eps Reward: -95.8662619746249, Epsilon: 0.0001, weights: 0.026035213144496083, elapsed: 189.71990938981375 minutes\n",
      "episode 8920/10000, Eps Reward: 596.5986237453606, Epsilon: 0.0001, weights: 0.013154435437172651, elapsed: 190.13944789568583 minutes\n",
      "episode 8930/10000, Eps Reward: 602.5343072617887, Epsilon: 0.0001, weights: 0.0020022307871840894, elapsed: 190.563277276357 minutes\n",
      "episode 8940/10000, Eps Reward: 421.0423412224368, Epsilon: 0.0001, weights: 0.12707635771948844, elapsed: 190.93588363726934 minutes\n",
      "episode 8950/10000, Eps Reward: 418.77170210931735, Epsilon: 0.0001, weights: 0.5649194810539484, elapsed: 191.3099711338679 minutes\n",
      "episode 8960/10000, Eps Reward: 772.7851557467093, Epsilon: 0.0001, weights: 0.020240962330717593, elapsed: 191.77575989166897 minutes\n",
      "episode 8970/10000, Eps Reward: 67.63401713943648, Epsilon: 0.0001, weights: 0.014169896952807903, elapsed: 192.05861501693727 minutes\n",
      "episode 8980/10000, Eps Reward: -108.04601578379034, Epsilon: 0.0001, weights: 5.963681116700172, elapsed: 192.29572264353433 minutes\n",
      "episode 8990/10000, Eps Reward: 65.43266379448538, Epsilon: 0.0001, weights: 3.41668088757433, elapsed: 192.57685700654983 minutes\n",
      "episode 9000/10000, Eps Reward: -111.11396058300815, Epsilon: 0.0001, weights: 9.100965272635221, elapsed: 192.81090995868047 minutes\n",
      "episode 9010/10000, Eps Reward: -113.02814896700895, Epsilon: 0.0001, weights: 13.639698300510645, elapsed: 193.0476444919904 minutes\n",
      "episode 9020/10000, Eps Reward: -287.4866894404778, Epsilon: 0.0001, weights: 0.061891230987384915, elapsed: 193.23861570358275 minutes\n",
      "episode 9030/10000, Eps Reward: 67.49834346706308, Epsilon: 0.0001, weights: 7.7943567130714655, elapsed: 193.52286362250646 minutes\n",
      "episode 9040/10000, Eps Reward: 597.0789770162984, Epsilon: 0.0001, weights: 0.08109123120084405, elapsed: 193.94323443571727 minutes\n",
      "episode 9050/10000, Eps Reward: 72.38559798102273, Epsilon: 0.0001, weights: 7.496195092797279, elapsed: 194.22947255770364 minutes\n",
      "episode 9060/10000, Eps Reward: 419.92079561081226, Epsilon: 0.0001, weights: 4.318918393924832, elapsed: 194.6036491950353 minutes\n",
      "episode 9070/10000, Eps Reward: 69.77805553976734, Epsilon: 0.0001, weights: 7.693713756278157, elapsed: 194.8904400229454 minutes\n",
      "episode 9080/10000, Eps Reward: 775.1408458778182, Epsilon: 0.0001, weights: 0.03289765422232449, elapsed: 195.3570547501246 minutes\n",
      "episode 9090/10000, Eps Reward: 421.7631708664929, Epsilon: 0.0001, weights: 18.340274937450886, elapsed: 195.73065329790114 minutes\n",
      "episode 9100/10000, Eps Reward: 422.04392314212134, Epsilon: 0.0001, weights: 0.10855252225883305, elapsed: 196.10316379467648 minutes\n",
      "episode 9110/10000, Eps Reward: 599.2975928698846, Epsilon: 0.0001, weights: 0.014882117859087884, elapsed: 196.52739539941152 minutes\n",
      "episode 9120/10000, Eps Reward: 242.83952177380326, Epsilon: 0.0001, weights: 0.03017112100496888, elapsed: 196.85543922185897 minutes\n",
      "episode 9130/10000, Eps Reward: 245.18476295856613, Epsilon: 0.0001, weights: 12.586011163890362, elapsed: 197.1839284936587 minutes\n",
      "episode 9140/10000, Eps Reward: 774.8881018590785, Epsilon: 0.0001, weights: 0.020713350852020085, elapsed: 197.65061472256977 minutes\n",
      "episode 9150/10000, Eps Reward: 419.5583633801369, Epsilon: 0.0001, weights: 14.589559685438871, elapsed: 198.02425611813862 minutes\n",
      "episode 9160/10000, Eps Reward: 422.65920149112327, Epsilon: 0.0001, weights: 0.018032468389719725, elapsed: 198.39815189441046 minutes\n",
      "episode 9170/10000, Eps Reward: -104.9157559787016, Epsilon: 0.0001, weights: 8.83784276433289, elapsed: 198.6393645485242 minutes\n",
      "episode 9180/10000, Eps Reward: 243.1195569488018, Epsilon: 0.0001, weights: 11.481497317552567, elapsed: 198.96732098261515 minutes\n",
      "episode 9190/10000, Eps Reward: 66.72032745725556, Epsilon: 0.0001, weights: 21.02555920276791, elapsed: 199.24958602190017 minutes\n",
      "episode 9200/10000, Eps Reward: 79.93193194112848, Epsilon: 0.0001, weights: 0.09170919470489025, elapsed: 199.5425475994746 minutes\n",
      "episode 9210/10000, Eps Reward: 597.3454342849816, Epsilon: 0.0001, weights: 26.77040857076645, elapsed: 199.96491086483002 minutes\n",
      "episode 9220/10000, Eps Reward: -463.3768672547065, Epsilon: 0.0001, weights: 21.259869173169136, elapsed: 200.11021063725153 minutes\n",
      "episode 9230/10000, Eps Reward: 422.7555509211417, Epsilon: 0.0001, weights: 0.015589923539664596, elapsed: 200.48363623221715 minutes\n",
      "episode 9240/10000, Eps Reward: 598.3520797127414, Epsilon: 0.0001, weights: 0.00616157436161302, elapsed: 200.90181634426116 minutes\n",
      "episode 9250/10000, Eps Reward: 603.0815659579137, Epsilon: 0.0001, weights: 0.020377910928800702, elapsed: 201.32088093360264 minutes\n",
      "episode 9260/10000, Eps Reward: 244.63382818020173, Epsilon: 0.0001, weights: 3.8182980604469776, elapsed: 201.64692420562108 minutes\n",
      "episode 9270/10000, Eps Reward: 313.7045691965601, Epsilon: 0.0001, weights: 0.06538734631612897, elapsed: 202.0158069173495 minutes\n",
      "episode 9280/10000, Eps Reward: 777.8952617523065, Epsilon: 0.0001, weights: 0.023486205260269344, elapsed: 202.4813184539477 minutes\n",
      "episode 9290/10000, Eps Reward: 250.95644992350935, Epsilon: 0.0001, weights: 13.887600291520357, elapsed: 202.81548785765966 minutes\n",
      "episode 9300/10000, Eps Reward: -111.23374160303149, Epsilon: 0.0001, weights: 29.32543547451496, elapsed: 203.0519871711731 minutes\n",
      "episode 9310/10000, Eps Reward: 422.0097951389748, Epsilon: 0.0001, weights: 0.03623718908056617, elapsed: 203.4296621600787 minutes\n",
      "episode 9320/10000, Eps Reward: 602.5800697714637, Epsilon: 0.0001, weights: 32.92615097947419, elapsed: 203.84872158765793 minutes\n",
      "episode 9330/10000, Eps Reward: 430.4570316434953, Epsilon: 0.0001, weights: 0.04321913467720151, elapsed: 204.2288013100624 minutes\n",
      "episode 9340/10000, Eps Reward: 600.7283460130714, Epsilon: 0.0001, weights: 0.02911438065348193, elapsed: 204.6514765381813 minutes\n",
      "episode 9350/10000, Eps Reward: 775.9344006127506, Epsilon: 0.0001, weights: 0.007323328754864633, elapsed: 205.1168229262034 minutes\n",
      "episode 9360/10000, Eps Reward: 242.42981721531186, Epsilon: 0.0001, weights: 18.266797425225377, elapsed: 205.44412978887559 minutes\n",
      "episode 9370/10000, Eps Reward: 595.5550926059547, Epsilon: 0.0001, weights: 0.051534006495785434, elapsed: 205.86401296854018 minutes\n",
      "episode 9380/10000, Eps Reward: 256.18594601852004, Epsilon: 0.0001, weights: 0.015258764964528382, elapsed: 206.2012393116951 minutes\n",
      "episode 9390/10000, Eps Reward: 424.5294934620846, Epsilon: 0.0001, weights: 0.04975580843165517, elapsed: 206.57465465466183 minutes\n",
      "episode 9400/10000, Eps Reward: -109.52518707543473, Epsilon: 0.0001, weights: 7.176502536050975, elapsed: 206.80885963439943 minutes\n",
      "episode 9410/10000, Eps Reward: 66.2837580596206, Epsilon: 0.0001, weights: 7.543271431699395, elapsed: 207.09173390865325 minutes\n",
      "episode 9420/10000, Eps Reward: 242.29667064055076, Epsilon: 0.0001, weights: 0.1573028340935707, elapsed: 207.4195651491483 minutes\n",
      "episode 9430/10000, Eps Reward: -106.82426354588071, Epsilon: 0.0001, weights: 7.415889915078878, elapsed: 207.65660314559938 minutes\n",
      "episode 9440/10000, Eps Reward: 241.58694215481682, Epsilon: 0.0001, weights: 26.665695630013943, elapsed: 207.98700513839722 minutes\n",
      "episode 9450/10000, Eps Reward: -291.1186499422278, Epsilon: 0.0001, weights: 0.011382978758774698, elapsed: 208.17741204102833 minutes\n",
      "episode 9460/10000, Eps Reward: -288.6097325278853, Epsilon: 0.0001, weights: 15.022730119526386, elapsed: 208.3696544766426 minutes\n",
      "episode 9470/10000, Eps Reward: 68.80865668102597, Epsilon: 0.0001, weights: 0.013733701081946492, elapsed: 208.65129274129868 minutes\n",
      "episode 9480/10000, Eps Reward: -109.06747415184482, Epsilon: 0.0001, weights: 0.016758503043092787, elapsed: 208.8873419682185 minutes\n",
      "episode 9490/10000, Eps Reward: 777.746397947694, Epsilon: 0.0001, weights: 0.02250069729052484, elapsed: 209.3558048804601 minutes\n",
      "episode 9500/10000, Eps Reward: -108.65380839853326, Epsilon: 0.0001, weights: 0.036683011858258396, elapsed: 209.59031561215718 minutes\n",
      "episode 9510/10000, Eps Reward: 71.38579926497542, Epsilon: 0.0001, weights: 9.919933304190636, elapsed: 209.87813472747803 minutes\n",
      "episode 9520/10000, Eps Reward: 68.42288165001555, Epsilon: 0.0001, weights: 11.063767943531275, elapsed: 210.16050582726797 minutes\n",
      "episode 9530/10000, Eps Reward: 779.4842560597285, Epsilon: 0.0001, weights: 0.04978260560892522, elapsed: 210.62751733064653 minutes\n",
      "episode 9540/10000, Eps Reward: 68.480670976222, Epsilon: 0.0001, weights: 33.4083441272378, elapsed: 210.90856999556223 minutes\n",
      "episode 9550/10000, Eps Reward: -640.1729941030425, Epsilon: 0.0001, weights: 21.750799916684628, elapsed: 211.00818494558334 minutes\n",
      "episode 9560/10000, Eps Reward: 243.72714044157186, Epsilon: 0.0001, weights: 0.0020180615392746404, elapsed: 211.33498694499335 minutes\n",
      "episode 9570/10000, Eps Reward: 245.3627599855874, Epsilon: 0.0001, weights: 0.01887321361573413, elapsed: 211.660806453228 minutes\n",
      "episode 9580/10000, Eps Reward: 776.0530508858399, Epsilon: 0.0001, weights: 0.0033367019495926797, elapsed: 212.12678813139598 minutes\n",
      "episode 9590/10000, Eps Reward: 422.40650528055767, Epsilon: 0.0001, weights: 0.003777690464630723, elapsed: 212.49993519385654 minutes\n",
      "episode 9600/10000, Eps Reward: 69.41653005448998, Epsilon: 0.0001, weights: 20.03831624914892, elapsed: 212.7831947684288 minutes\n",
      "episode 9610/10000, Eps Reward: -109.26515565647449, Epsilon: 0.0001, weights: 8.654420603066683, elapsed: 213.01960192124048 minutes\n",
      "episode 9620/10000, Eps Reward: 425.3052444493739, Epsilon: 0.0001, weights: 0.018704626243561506, elapsed: 213.39472191731136 minutes\n",
      "episode 9630/10000, Eps Reward: 248.1384266673008, Epsilon: 0.0001, weights: 2.5816582147963345, elapsed: 213.72392785549164 minutes\n",
      "episode 9640/10000, Eps Reward: -286.11680996708236, Epsilon: 0.0001, weights: 21.80581983923912, elapsed: 213.9143383026123 minutes\n",
      "episode 9650/10000, Eps Reward: 68.13497519094419, Epsilon: 0.0001, weights: 3.5232248036190867, elapsed: 214.19966325362523 minutes\n",
      "episode 9660/10000, Eps Reward: 65.81334953796072, Epsilon: 0.0001, weights: 17.520144097507, elapsed: 214.48291097482044 minutes\n",
      "episode 9670/10000, Eps Reward: 67.33652388274696, Epsilon: 0.0001, weights: 13.78684838116169, elapsed: 214.76589627663296 minutes\n",
      "episode 9680/10000, Eps Reward: 597.1927340892732, Epsilon: 0.0001, weights: 0.0009748337179189548, elapsed: 215.18774937788646 minutes\n",
      "episode 9690/10000, Eps Reward: 781.2932944791755, Epsilon: 0.0001, weights: 0.11301465728320181, elapsed: 215.6549869855245 minutes\n",
      "episode 9700/10000, Eps Reward: 423.3682967491366, Epsilon: 0.0001, weights: 0.0627132635563612, elapsed: 216.03096163272858 minutes\n",
      "episode 9710/10000, Eps Reward: 246.06324777490076, Epsilon: 0.0001, weights: 11.517502311617136, elapsed: 216.36214839220048 minutes\n",
      "episode 9720/10000, Eps Reward: 425.8229524425411, Epsilon: 0.0001, weights: 0.011096259404439479, elapsed: 216.74005063772202 minutes\n",
      "episode 9730/10000, Eps Reward: 423.2205829839759, Epsilon: 0.0001, weights: 0.011959956493228674, elapsed: 217.11539790232976 minutes\n",
      "episode 9740/10000, Eps Reward: 775.6724647230282, Epsilon: 0.0001, weights: 0.00840561997028999, elapsed: 217.5808231274287 minutes\n",
      "episode 9750/10000, Eps Reward: 419.9990297381561, Epsilon: 0.0001, weights: 0.0057498358364682645, elapsed: 217.95395483970643 minutes\n",
      "episode 9760/10000, Eps Reward: 599.1080689493884, Epsilon: 0.0001, weights: 0.0049009781796485186, elapsed: 218.3740192572276 minutes\n",
      "episode 9770/10000, Eps Reward: 455.45695651370386, Epsilon: 0.0001, weights: 0.03914765425724909, elapsed: 218.76834068695703 minutes\n",
      "episode 9780/10000, Eps Reward: 245.03524826172892, Epsilon: 0.0001, weights: 0.056665997952222824, elapsed: 219.09527630408604 minutes\n",
      "episode 9790/10000, Eps Reward: 595.7260792442875, Epsilon: 0.0001, weights: 0.09293067129328847, elapsed: 219.5172998825709 minutes\n",
      "episode 9800/10000, Eps Reward: 601.3652533704486, Epsilon: 0.0001, weights: 0.027444398036095663, elapsed: 219.93903602759045 minutes\n",
      "episode 9810/10000, Eps Reward: 67.93901173846416, Epsilon: 0.0001, weights: 0.03856613114476204, elapsed: 220.22271432479224 minutes\n",
      "episode 9820/10000, Eps Reward: 424.8253546485163, Epsilon: 0.0001, weights: 0.0011252560070715845, elapsed: 220.5977469921112 minutes\n",
      "episode 9830/10000, Eps Reward: 779.4352722516986, Epsilon: 0.0001, weights: 0.0025788123020902276, elapsed: 221.06564021905263 minutes\n",
      "episode 9840/10000, Eps Reward: 68.77471587580901, Epsilon: 0.0001, weights: 0.008742324775084853, elapsed: 221.34713073968888 minutes\n",
      "episode 9850/10000, Eps Reward: -286.9872431221123, Epsilon: 0.0001, weights: 0.010460636462084949, elapsed: 221.53518468141556 minutes\n",
      "episode 9860/10000, Eps Reward: 422.006703396927, Epsilon: 0.0001, weights: 0.009053106419742107, elapsed: 221.90915050506592 minutes\n",
      "episode 9870/10000, Eps Reward: 602.6345265924421, Epsilon: 0.0001, weights: 0.01957159862286062, elapsed: 222.32934562365213 minutes\n",
      "episode 9880/10000, Eps Reward: 425.45152267879837, Epsilon: 0.0001, weights: 22.177132677286863, elapsed: 222.7028399348259 minutes\n",
      "episode 9890/10000, Eps Reward: 67.5726583892316, Epsilon: 0.0001, weights: 0.002737820672336966, elapsed: 222.98424155314763 minutes\n",
      "episode 9900/10000, Eps Reward: 775.5776576796029, Epsilon: 0.0001, weights: 0.03383948211558163, elapsed: 223.44975387652715 minutes\n",
      "episode 9910/10000, Eps Reward: 774.4777989532648, Epsilon: 0.0001, weights: 0.005312302731908858, elapsed: 223.91798806587855 minutes\n",
      "episode 9920/10000, Eps Reward: 773.2706026410864, Epsilon: 0.0001, weights: 0.02138601640763227, elapsed: 224.38619554837544 minutes\n",
      "episode 9930/10000, Eps Reward: 242.8235930055195, Epsilon: 0.0001, weights: 38.91758741438389, elapsed: 224.71454838116964 minutes\n",
      "episode 9940/10000, Eps Reward: 417.9158901036071, Epsilon: 0.0001, weights: 34.69790752977133, elapsed: 225.08852903048196 minutes\n",
      "episode 9950/10000, Eps Reward: 602.2710031222983, Epsilon: 0.0001, weights: 0.043956347755738534, elapsed: 225.50985796451567 minutes\n",
      "episode 9960/10000, Eps Reward: 601.8779152413124, Epsilon: 0.0001, weights: 0.014792335336096585, elapsed: 225.9305605093638 minutes\n",
      "episode 9970/10000, Eps Reward: 421.6874495699728, Epsilon: 0.0001, weights: 41.34853592514992, elapsed: 226.30506924788156 minutes\n",
      "episode 9980/10000, Eps Reward: 424.83081262706673, Epsilon: 0.0001, weights: 0.031115325749851763, elapsed: 226.6796897649765 minutes\n",
      "episode 9990/10000, Eps Reward: 423.27577207096067, Epsilon: 0.0001, weights: 11.137007964774966, elapsed: 227.05389941533406 minutes\n",
      "episode 10000/10000, Eps Reward: 602.74854058819, Epsilon: 0.0001, weights: 0.018530002154875547, elapsed: 227.4752390742302 minutes\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "ALPHA = 0.001  # Learning rate\n",
    "GAMMA = 0.99  # Discount factor\n",
    "EPSILON = 1.0  # Exploration rate\n",
    "EPSILON_DECAY = 0.99885  # Decay rate for epsilon\n",
    "MIN_EPSILON = 0.0001  # Minimum epsilon value\n",
    "BATCH_SIZE = 1  # Batch size for experience replay\n",
    "MEMORY_SIZE = 5000  # Size of experience replay memory\n",
    "NUM_EPS = 10000  # Number of training episodes\n",
    "TARG_RATE = 20 # Update rate of target_net\n",
    "EPS_LEN = 200\n",
    "TAU_POLYAK = 0.005\n",
    "\n",
    "#total_reward = 0\n",
    "\n",
    "#reward_acul = np.empty(0)\n",
    "\n",
    "\n",
    "#state = quad_env.init_state()\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "reward_acul = np.empty(0)\n",
    "\n",
    "# Train the agent\n",
    "for i in range(1,NUM_EPS+1):\n",
    "    done = False\n",
    "\n",
    "\n",
    "    state = quad_env.init_state()\n",
    "    total_reward = 0\n",
    "\n",
    "    \n",
    "    for j in range(1,EPS_LEN+1):\n",
    "        if done :\n",
    "            break\n",
    "\n",
    "        uav_loc = np.reshape(state[:-quad_env.user_number], (2,-1))\n",
    "        user_profile = state[-quad_env.user_number:]\n",
    "    \n",
    "        action = select_action(state, EPSILON)\n",
    "    \n",
    "        scheduling = schedule(user_profile,quad_env.user_loc,uav_loc,quad_env.transmit_pow,quad_env.noise,quad_env.height)\n",
    "    \n",
    "        next_state = quad_env.next_state(action,uav_loc,user_profile,scheduling)\n",
    "    \n",
    "        uav_loc = np.reshape(next_state[:-quad_env.user_number], (2,-1))\n",
    "    \n",
    "        \n",
    "        reward , done = quad_env.my_reward(uav_loc, scheduling, user_profile)\n",
    "    \n",
    "\n",
    "        store_experience(state, action, reward, next_state ,done )\n",
    "    \n",
    "    \n",
    "        #########################################################################################################################\n",
    "        prev_model = copy.deepcopy(q_net)\n",
    "    \n",
    "        update_q_network(BATCH_SIZE)\n",
    "    \n",
    "        #break ###################################################\n",
    "    \n",
    "        ### polyak averaging for updating target_net    \n",
    "        # for target_param, main_param in zip(target_net.parameters(), q_net.parameters()):\n",
    "        #     target_param.data.copy_(TAU_POLYAK * main_param.data + (1 - TAU_POLYAK) * target_param.data)\n",
    "        \n",
    "\n",
    "        state = next_state\n",
    "        \n",
    "        total_reward += reward\n",
    "\n",
    "\n",
    "    reward_acul = np.append(reward_acul,total_reward)\n",
    "\n",
    "    # Decay epsilon to reduce exploration\n",
    "    EPSILON = max(MIN_EPSILON, EPSILON * EPSILON_DECAY)\n",
    "\n",
    "    # Print progress every episodes\n",
    "\n",
    "    if i%10 == 0:\n",
    "        toc = time.time()\n",
    "        print(f\"episode {i}/{NUM_EPS}, Eps Reward: {np.mean(reward_acul[-10:])}, Epsilon: {EPSILON}, weights: {weight_change(q_net,prev_model)}, elapsed: {(toc-tic)/60} minutes\")\n",
    "\n",
    "    if i%100 == 0:\n",
    "    \n",
    "        check_point = {\n",
    "        'epoch':i,\n",
    "        'model_state':q_net.state_dict(),\n",
    "        'optimizer_state': optimizer.state_dict()\n",
    "        }\n",
    "    \n",
    "        torch.save(check_point,\"checkpoint_eps.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a109b184-4631-452f-9230-84bcf8860750",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"rewards.npy\",reward_acul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67f7e1a-637e-4cd8-b8fb-f6a43c0d6934",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
